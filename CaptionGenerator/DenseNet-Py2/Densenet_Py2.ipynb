{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Densenet_Py2.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[]},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"}},"cells":[{"metadata":{"id":"mXGOjVCDn8jn","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"948a5e25-4ea3-47de-fa84-702137464997"},"cell_type":"code","source":["from __future__ import print_function\n","from __future__ import absolute_import\n","from __future__ import division\n","\n","import warnings\n","\n","from keras.models import Model\n","from keras.layers.core import Dense, Dropout, Activation, Reshape\n","from keras.layers.convolutional import Conv2D, Conv2DTranspose, UpSampling2D\n","from keras.layers.pooling import AveragePooling2D, MaxPooling2D\n","from keras.layers.pooling import GlobalAveragePooling2D\n","from keras.layers import Input\n","from keras.layers.merge import concatenate\n","from keras.layers.normalization import BatchNormalization\n","from keras.regularizers import l2\n","from keras.utils.layer_utils import convert_all_kernels_in_model, convert_dense_weights_data_format\n","from keras.utils.data_utils import get_file\n","from keras.engine.topology import get_source_inputs\n","from keras.applications.imagenet_utils import _obtain_input_shape\n","from keras.applications.imagenet_utils import decode_predictions\n","import keras.backend as K\n","\n","# from subpixel import SubPixelUpscaling\n","\n","DENSENET_121_WEIGHTS_PATH = r'https://github.com/titu1994/DenseNet/releases/download/v3.0/DenseNet-BC-121-32.h5'\n","DENSENET_161_WEIGHTS_PATH = r'https://github.com/titu1994/DenseNet/releases/download/v3.0/DenseNet-BC-161-48.h5'\n","DENSENET_169_WEIGHTS_PATH = r'https://github.com/titu1994/DenseNet/releases/download/v3.0/DenseNet-BC-169-32.h5'\n","DENSENET_121_WEIGHTS_PATH_NO_TOP = r'https://github.com/titu1994/DenseNet/releases/download/v3.0/DenseNet-BC-121-32-no-top.h5'\n","DENSENET_161_WEIGHTS_PATH_NO_TOP = r'https://github.com/titu1994/DenseNet/releases/download/v3.0/DenseNet-BC-161-48-no-top.h5'\n","DENSENET_169_WEIGHTS_PATH_NO_TOP = r'https://github.com/titu1994/DenseNet/releases/download/v3.0/DenseNet-BC-169-32-no-top.h5'\n","\n","def preprocess_input(x, data_format=None):\n","    \"\"\"Preprocesses a tensor encoding a batch of images.\n","    # Arguments\n","        x: input Numpy tensor, 4D.\n","        data_format: data format of the image tensor.\n","    # Returns\n","        Preprocessed tensor.\n","    \"\"\"\n","    if data_format is None:\n","        data_format = K.image_data_format()\n","    assert data_format in {'channels_last', 'channels_first'}\n","\n","    if data_format == 'channels_first':\n","        if x.ndim == 3:\n","            # 'RGB'->'BGR'\n","            x = x[::-1, ...]\n","            # Zero-center by mean pixel\n","            x[0, :, :] -= 103.939\n","            x[1, :, :] -= 116.779\n","            x[2, :, :] -= 123.68\n","        else:\n","            x = x[:, ::-1, ...]\n","            x[:, 0, :, :] -= 103.939\n","            x[:, 1, :, :] -= 116.779\n","            x[:, 2, :, :] -= 123.68\n","    else:\n","        # 'RGB'->'BGR'\n","        x = x[..., ::-1]\n","        # Zero-center by mean pixel\n","        x[..., 0] -= 103.939\n","        x[..., 1] -= 116.779\n","        x[..., 2] -= 123.68\n","\n","    x *= 0.017 # scale values\n","\n","    return x\n","\n","def __create_dense_net(nb_classes, img_input, include_top, depth=40, nb_dense_block=3, growth_rate=12, nb_filter=-1,\n","                       nb_layers_per_block=-1, bottleneck=False, reduction=0.0, dropout_rate=None, weight_decay=1e-4,\n","                       subsample_initial_block=False, activation='softmax'):\n","    ''' Build the DenseNet model\n","    Args:\n","        nb_classes: number of classes\n","        img_input: tuple of shape (channels, rows, columns) or (rows, columns, channels)\n","        include_top: flag to include the final Dense layer\n","        depth: number or layers\n","        nb_dense_block: number of dense blocks to add to end (generally = 3)\n","        growth_rate: number of filters to add per dense block\n","        nb_filter: initial number of filters. Default -1 indicates initial number of filters is 2 * growth_rate\n","        nb_layers_per_block: number of layers in each dense block.\n","                Can be a -1, positive integer or a list.\n","                If -1, calculates nb_layer_per_block from the depth of the network.\n","                If positive integer, a set number of layers per dense block.\n","                If list, nb_layer is used as provided. Note that list size must\n","                be (nb_dense_block + 1)\n","        bottleneck: add bottleneck blocks\n","        reduction: reduction factor of transition blocks. Note : reduction value is inverted to compute compression\n","        dropout_rate: dropout rate\n","        weight_decay: weight decay rate\n","        subsample_initial_block: Set to True to subsample the initial convolution and\n","                add a MaxPool2D before the dense blocks are added.\n","        subsample_initial:\n","        activation: Type of activation at the top layer. Can be one of 'softmax' or 'sigmoid'.\n","                Note that if sigmoid is used, classes must be 1.\n","    Returns: keras tensor with nb_layers of conv_block appended\n","    '''\n","\n","    concat_axis = 1 if K.image_data_format() == 'channels_first' else -1\n","\n","    if reduction != 0.0:\n","        assert reduction <= 1.0 and reduction > 0.0, 'reduction value must lie between 0.0 and 1.0'\n","\n","    # layers in each dense block\n","    if type(nb_layers_per_block) is list or type(nb_layers_per_block) is tuple:\n","        nb_layers = list(nb_layers_per_block)  # Convert tuple to list\n","\n","        assert len(nb_layers) == (nb_dense_block), 'If list, nb_layer is used as provided. ' \\\n","                                                   'Note that list size must be (nb_dense_block)'\n","        final_nb_layer = nb_layers[-1]\n","        nb_layers = nb_layers[:-1]\n","    else:\n","        if nb_layers_per_block == -1:\n","            assert (depth - 4) % 3 == 0, 'Depth must be 3 N + 4 if nb_layers_per_block == -1'\n","            count = int((depth - 4) / 3)\n","\n","            if bottleneck:\n","                count = count // 2\n","\n","            nb_layers = [count for _ in range(nb_dense_block)]\n","            final_nb_layer = count\n","        else:\n","            final_nb_layer = nb_layers_per_block\n","            nb_layers = [nb_layers_per_block] * nb_dense_block\n","\n","    # compute initial nb_filter if -1, else accept users initial nb_filter\n","    if nb_filter <= 0:\n","        nb_filter = 2 * growth_rate\n","\n","    # compute compression factor\n","    compression = 1.0 - reduction\n","\n","    # Initial convolution\n","    if subsample_initial_block:\n","        initial_kernel = (7, 7)\n","        initial_strides = (2, 2)\n","    else:\n","        initial_kernel = (3, 3)\n","        initial_strides = (1, 1)\n","\n","    x = Conv2D(nb_filter, initial_kernel, kernel_initializer='he_normal', padding='same',\n","               strides=initial_strides, use_bias=False, kernel_regularizer=l2(weight_decay))(img_input)\n","\n","    if subsample_initial_block:\n","        x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(x)\n","        x = Activation('relu')(x)\n","        x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n","\n","    # Add dense blocks\n","    for block_idx in range(nb_dense_block - 1):\n","        x, nb_filter = __dense_block(x, nb_layers[block_idx], nb_filter, growth_rate, bottleneck=bottleneck,\n","                                     dropout_rate=dropout_rate, weight_decay=weight_decay)\n","        # add transition_block\n","        x = __transition_block(x, nb_filter, compression=compression, weight_decay=weight_decay)\n","        nb_filter = int(nb_filter * compression)\n","\n","    # The last dense_block does not have a transition_block\n","    x, nb_filter = __dense_block(x, final_nb_layer, nb_filter, growth_rate, bottleneck=bottleneck,\n","                                 dropout_rate=dropout_rate, weight_decay=weight_decay)\n","\n","    x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(x)\n","    x = Activation('relu')(x)\n","    x = GlobalAveragePooling2D()(x)\n","\n","    if include_top:\n","        x = Dense(nb_classes, activation=activation)(x)\n","\n","    return x\n","  \n","\n","def __transition_block(ip, nb_filter, compression=1.0, weight_decay=1e-4):\n","    ''' Apply BatchNorm, Relu 1x1, Conv2D, optional compression, dropout and Maxpooling2D\n","    Args:\n","        ip: keras tensor\n","        nb_filter: number of filters\n","        compression: calculated as 1 - reduction. Reduces the number of feature maps\n","                    in the transition block.\n","        dropout_rate: dropout rate\n","        weight_decay: weight decay factor\n","    Returns: keras tensor, after applying batch_norm, relu-conv, dropout, maxpool\n","    '''\n","    concat_axis = 1 if K.image_data_format() == 'channels_first' else -1\n","\n","    x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(ip)\n","    x = Activation('relu')(x)\n","    x = Conv2D(int(nb_filter * compression), (1, 1), kernel_initializer='he_normal', padding='same', use_bias=False,\n","               kernel_regularizer=l2(weight_decay))(x)\n","    x = AveragePooling2D((2, 2), strides=(2, 2))(x)\n","\n","    return x\n","\n","def __dense_block(x, nb_layers, nb_filter, growth_rate, bottleneck=False, dropout_rate=None, weight_decay=1e-4,\n","                  grow_nb_filters=True, return_concat_list=False):\n","    ''' Build a dense_block where the output of each conv_block is fed to subsequent ones\n","    Args:\n","        x: keras tensor\n","        nb_layers: the number of layers of conv_block to append to the model.\n","        nb_filter: number of filters\n","        growth_rate: growth rate\n","        bottleneck: bottleneck block\n","        dropout_rate: dropout rate\n","        weight_decay: weight decay factor\n","        grow_nb_filters: flag to decide to allow number of filters to grow\n","        return_concat_list: return the list of feature maps along with the actual output\n","    Returns: keras tensor with nb_layers of conv_block appended\n","    '''\n","    concat_axis = 1 if K.image_data_format() == 'channels_first' else -1\n","\n","    x_list = [x]\n","\n","    for i in range(nb_layers):\n","        cb = __conv_block(x, growth_rate, bottleneck, dropout_rate, weight_decay)\n","        x_list.append(cb)\n","\n","        x = concatenate([x, cb], axis=concat_axis)\n","\n","        if grow_nb_filters:\n","            nb_filter += growth_rate\n","\n","    if return_concat_list:\n","        return x, nb_filter, x_list\n","    else:\n","        return x, nb_filter\n","\n","def __conv_block(ip, nb_filter, bottleneck=False, dropout_rate=None, weight_decay=1e-4):\n","  ''' Apply BatchNorm, Relu, 3x3 Conv2D, optional bottleneck block and dropout\n","  Args:\n","      ip: Input keras tensor\n","      nb_filter: number of filters\n","      bottleneck: add bottleneck block\n","      dropout_rate: dropout rate\n","      weight_decay: weight decay factor\n","  Returns: keras tensor with batch_norm, relu and convolution2d added (optional bottleneck)\n","  '''\n","  concat_axis = 1 if K.image_data_format() == 'channels_first' else -1\n","\n","  x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(ip)\n","  x = Activation('relu')(x)\n","\n","  if bottleneck:\n","      inter_channel = nb_filter * 4  # Obtained from https://github.com/liuzhuang13/DenseNet/blob/master/densenet.lua\n","\n","      x = Conv2D(inter_channel, (1, 1), kernel_initializer='he_normal', padding='same', use_bias=False,\n","                 kernel_regularizer=l2(weight_decay))(x)\n","      x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(x)\n","      x = Activation('relu')(x)\n","\n","  x = Conv2D(nb_filter, (3, 3), kernel_initializer='he_normal', padding='same', use_bias=False)(x)\n","  if dropout_rate:\n","      x = Dropout(dropout_rate)(x)\n","\n","  return x\n","\n","def DenseNet(input_shape=None, depth=40, nb_dense_block=3, growth_rate=12, nb_filter=-1, nb_layers_per_block=-1,\n","             bottleneck=False, reduction=0.0, dropout_rate=0.0, weight_decay=1e-4, subsample_initial_block=False,\n","             include_top=True, weights=None, input_tensor=None,\n","             classes=10, activation='softmax'):\n","    '''Instantiate the DenseNet architecture,\n","        optionally loading weights pre-trained\n","        on CIFAR-10. Note that when using TensorFlow,\n","        for best performance you should set\n","        `image_data_format='channels_last'` in your Keras config\n","        at ~/.keras/keras.json.\n","        The model and the weights are compatible with both\n","        TensorFlow and Theano. The dimension ordering\n","        convention used by the model is the one\n","        specified in your Keras config file.\n","        # Arguments\n","            input_shape: optional shape tuple, only to be specified\n","                if `include_top` is False (otherwise the input shape\n","                has to be `(32, 32, 3)` (with `channels_last` dim ordering)\n","                or `(3, 32, 32)` (with `channels_first` dim ordering).\n","                It should have exactly 3 inputs channels,\n","                and width and height should be no smaller than 8.\n","                E.g. `(200, 200, 3)` would be one valid value.\n","            depth: number or layers in the DenseNet\n","            nb_dense_block: number of dense blocks to add to end (generally = 3)\n","            growth_rate: number of filters to add per dense block\n","            nb_filter: initial number of filters. -1 indicates initial\n","                number of filters is 2 * growth_rate\n","            nb_layers_per_block: number of layers in each dense block.\n","                Can be a -1, positive integer or a list.\n","                If -1, calculates nb_layer_per_block from the network depth.\n","                If positive integer, a set number of layers per dense block.\n","                If list, nb_layer is used as provided. Note that list size must\n","                be (nb_dense_block + 1)\n","            bottleneck: flag to add bottleneck blocks in between dense blocks\n","            reduction: reduction factor of transition blocks.\n","                Note : reduction value is inverted to compute compression.\n","            dropout_rate: dropout rate\n","            weight_decay: weight decay rate\n","            subsample_initial_block: Set to True to subsample the initial convolution and\n","                add a MaxPool2D before the dense blocks are added.\n","            include_top: whether to include the fully-connected\n","                layer at the top of the network.\n","            weights: one of `None` (random initialization) or\n","                'imagenet' (pre-training on ImageNet)..\n","            input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n","                to use as image input for the model.\n","            classes: optional number of classes to classify images\n","                into, only to be specified if `include_top` is True, and\n","                if no `weights` argument is specified.\n","            activation: Type of activation at the top layer. Can be one of 'softmax' or 'sigmoid'.\n","                Note that if sigmoid is used, classes must be 1.\n","        # Returns\n","            A Keras model instance.\n","        '''\n","\n","    if weights not in {'imagenet', None}:\n","        raise ValueError('The `weights` argument should be either '\n","                         '`None` (random initialization) or `cifar10` '\n","                         '(pre-training on CIFAR-10).')\n","\n","    if weights == 'imagenet' and include_top and classes != 1000:\n","        raise ValueError('If using `weights` as ImageNet with `include_top`'\n","                         ' as true, `classes` should be 1000')\n","\n","    if activation not in ['softmax', 'sigmoid']:\n","        raise ValueError('activation must be one of \"softmax\" or \"sigmoid\"')\n","\n","    if activation == 'sigmoid' and classes != 1:\n","        raise ValueError('sigmoid activation can only be used when classes = 1')\n","\n","    # Determine proper input shape\n","    input_shape = _obtain_input_shape(input_shape,\n","                                      default_size=32,\n","                                      min_size=8,\n","                                      data_format=K.image_data_format(),\n","                                      require_flatten=include_top)\n","\n","    if input_tensor is None:\n","        img_input = Input(shape=input_shape)\n","    else:\n","        if not K.is_keras_tensor(input_tensor):\n","            img_input = Input(tensor=input_tensor, shape=input_shape)\n","        else:\n","            img_input = input_tensor\n","\n","    x = __create_dense_net(classes, img_input, include_top, depth, nb_dense_block,\n","                           growth_rate, nb_filter, nb_layers_per_block, bottleneck, reduction,\n","                           dropout_rate, weight_decay, subsample_initial_block, activation)\n","\n","    # Ensure that the model takes into account\n","    # any potential predecessors of `input_tensor`.\n","    if input_tensor is not None:\n","        inputs = get_source_inputs(input_tensor)\n","    else:\n","        inputs = img_input\n","    # Create model.\n","    model = Model(inputs, x, name='densenet')\n","\n","    # load weights\n","    if weights == 'imagenet':\n","        weights_loaded = False\n","\n","        if (depth == 121) and (nb_dense_block == 4) and (growth_rate == 32) and (nb_filter == 64) and \\\n","                (bottleneck is True) and (reduction == 0.5) and (dropout_rate == 0.0) and (subsample_initial_block):\n","            if include_top:\n","                weights_path = get_file('DenseNet-BC-121-32.h5',\n","                                        DENSENET_121_WEIGHTS_PATH,\n","                                        cache_subdir='models',\n","                                        md5_hash='a439dd41aa672aef6daba4ee1fd54abd')\n","            else:\n","                weights_path = get_file('DenseNet-BC-121-32-no-top.h5',\n","                                        DENSENET_121_WEIGHTS_PATH_NO_TOP,\n","                                        cache_subdir='models',\n","                                        md5_hash='55e62a6358af8a0af0eedf399b5aea99')\n","            model.load_weights(weights_path)\n","            weights_loaded = True\n","\n","        if (depth == 161) and (nb_dense_block == 4) and (growth_rate == 48) and (nb_filter == 96) and \\\n","                (bottleneck is True) and (reduction == 0.5) and (dropout_rate == 0.0) and (subsample_initial_block):\n","            if include_top:\n","                weights_path = get_file('DenseNet-BC-161-48.h5',\n","                                        DENSENET_161_WEIGHTS_PATH,\n","                                        cache_subdir='models',\n","                                        md5_hash='6c326cf4fbdb57d31eff04333a23fcca')\n","            else:\n","                weights_path = get_file('DenseNet-BC-161-48-no-top.h5',\n","                                        DENSENET_161_WEIGHTS_PATH_NO_TOP,\n","                                        cache_subdir='models',\n","                                        md5_hash='1a9476b79f6b7673acaa2769e6427b92')\n","            model.load_weights(weights_path)\n","            weights_loaded = True\n","\n","        if (depth == 169) and (nb_dense_block == 4) and (growth_rate == 32) and (nb_filter == 64) and \\\n","                (bottleneck is True) and (reduction == 0.5) and (dropout_rate == 0.0) and (subsample_initial_block):\n","            if include_top:\n","                weights_path = get_file('DenseNet-BC-169-32.h5',\n","                                        DENSENET_169_WEIGHTS_PATH,\n","                                        cache_subdir='models',\n","                                        md5_hash='914869c361303d2e39dec640b4e606a6')\n","            else:\n","                weights_path = get_file('DenseNet-BC-169-32-no-top.h5',\n","                                        DENSENET_169_WEIGHTS_PATH_NO_TOP,\n","                                        cache_subdir='models',\n","                                        md5_hash='89c19e8276cfd10585d5fadc1df6859e')\n","            model.load_weights(weights_path)\n","            weights_loaded = True\n","\n","        if weights_loaded:\n","            if K.backend() == 'theano':\n","                convert_all_kernels_in_model(model)\n","\n","            if K.image_data_format() == 'channels_first' and K.backend() == 'tensorflow':\n","                warnings.warn('You are using the TensorFlow backend, yet you '\n","                              'are using the Theano '\n","                              'image data format convention '\n","                              '(`image_data_format=\"channels_first\"`). '\n","                              'For best performance, set '\n","                              '`image_data_format=\"channels_last\"` in '\n","                              'your Keras config '\n","                              'at ~/.keras/keras.json.')\n","\n","            print(\"Weights for the model were loaded successfully\")\n","\n","    return model\n","\n","\n","def DenseNetImageNet121(input_shape=None,\n","                        bottleneck=True,\n","                        reduction=0.5,\n","                        dropout_rate=0.0,\n","                        weight_decay=1e-4,\n","                        include_top=True,\n","                        weights='imagenet',\n","                        input_tensor=None,\n","                        classes=1000,\n","                        activation='softmax'):\n","    return DenseNet(input_shape, depth=121, nb_dense_block=4, growth_rate=32, nb_filter=64,\n","                    nb_layers_per_block=[6, 12, 24, 16], bottleneck=bottleneck, reduction=reduction,\n","                    dropout_rate=dropout_rate, weight_decay=weight_decay, subsample_initial_block=True,\n","                    include_top=include_top, weights=weights, input_tensor=input_tensor,\n","                    classes=classes, activation=activation)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n","  from ._conv import register_converters as _register_converters\n","Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"4a8_8WFHn8jz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"297d4ebe-93a5-4375-9b0b-50dbc351aac9"},"cell_type":"code","source":["import keras\n","import numpy as np\n","from keras.preprocessing import image\n","from keras.applications.imagenet_utils import decode_predictions\n","\n","model = keras.applications.densenet.DenseNet121(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n","\n","img_path = 'elephant.jpg'\n","img = image.load_img(img_path, target_size=(224, 224))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","\n","#x = preprocess_input(x)\n","\n","preds = model.predict(x)\n","\n","print('Predicted:', decode_predictions(preds))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["('Predicted:', [[(u'n03180011', u'desktop_computer', 0.3106413), (u'n06359193', u'web_site', 0.23376717), (u'n03249569', u'drum', 0.1802558), (u'n04380533', u'table_lamp', 0.16848156), (u'n02105251', u'briard', 0.042605225)]])\n"],"name":"stdout"}]},{"metadata":{"id":"u76ERPMun8j6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"95cf6649-0976-4919-a45d-a762a0173ef4"},"cell_type":"code","source":["import numpy as np\n","from keras.preprocessing import image\n","from keras.applications.imagenet_utils import decode_predictions\n","size = 224\n","\n","model = DenseNetImageNet121(input_shape=(size, size, 3))\n","model.summary()\n","\n","\n","img_path = 'elephant.jpg'\n","img = image.load_img(img_path, target_size=(size, size))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","\n","x = preprocess_input(x)\n","\n","preds = model.predict(x)\n","\n","print('Predicted:', decode_predictions(preds))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Weights for the model were loaded successfully\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n","__________________________________________________________________________________________________\n","conv2d_121 (Conv2D)             (None, 112, 112, 64) 9408        input_2[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_122 (BatchN (None, 112, 112, 64) 256         conv2d_121[0][0]                 \n","__________________________________________________________________________________________________\n","activation_122 (Activation)     (None, 112, 112, 64) 0           batch_normalization_122[0][0]    \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 56, 56, 64)   0           activation_122[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_123 (BatchN (None, 56, 56, 64)   256         max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","activation_123 (Activation)     (None, 56, 56, 64)   0           batch_normalization_123[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_122 (Conv2D)             (None, 56, 56, 128)  8192        activation_123[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_124 (BatchN (None, 56, 56, 128)  512         conv2d_122[0][0]                 \n","__________________________________________________________________________________________________\n","activation_124 (Activation)     (None, 56, 56, 128)  0           batch_normalization_124[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_123 (Conv2D)             (None, 56, 56, 32)   36864       activation_124[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_59 (Concatenate)    (None, 56, 56, 96)   0           max_pooling2d_2[0][0]            \n","                                                                 conv2d_123[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_125 (BatchN (None, 56, 56, 96)   384         concatenate_59[0][0]             \n","__________________________________________________________________________________________________\n","activation_125 (Activation)     (None, 56, 56, 96)   0           batch_normalization_125[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_124 (Conv2D)             (None, 56, 56, 128)  12288       activation_125[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_126 (BatchN (None, 56, 56, 128)  512         conv2d_124[0][0]                 \n","__________________________________________________________________________________________________\n","activation_126 (Activation)     (None, 56, 56, 128)  0           batch_normalization_126[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_125 (Conv2D)             (None, 56, 56, 32)   36864       activation_126[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_60 (Concatenate)    (None, 56, 56, 128)  0           concatenate_59[0][0]             \n","                                                                 conv2d_125[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_127 (BatchN (None, 56, 56, 128)  512         concatenate_60[0][0]             \n","__________________________________________________________________________________________________\n","activation_127 (Activation)     (None, 56, 56, 128)  0           batch_normalization_127[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_126 (Conv2D)             (None, 56, 56, 128)  16384       activation_127[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_128 (BatchN (None, 56, 56, 128)  512         conv2d_126[0][0]                 \n","__________________________________________________________________________________________________\n","activation_128 (Activation)     (None, 56, 56, 128)  0           batch_normalization_128[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_127 (Conv2D)             (None, 56, 56, 32)   36864       activation_128[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_61 (Concatenate)    (None, 56, 56, 160)  0           concatenate_60[0][0]             \n","                                                                 conv2d_127[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_129 (BatchN (None, 56, 56, 160)  640         concatenate_61[0][0]             \n","__________________________________________________________________________________________________\n","activation_129 (Activation)     (None, 56, 56, 160)  0           batch_normalization_129[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_128 (Conv2D)             (None, 56, 56, 128)  20480       activation_129[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_130 (BatchN (None, 56, 56, 128)  512         conv2d_128[0][0]                 \n","__________________________________________________________________________________________________\n","activation_130 (Activation)     (None, 56, 56, 128)  0           batch_normalization_130[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_129 (Conv2D)             (None, 56, 56, 32)   36864       activation_130[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_62 (Concatenate)    (None, 56, 56, 192)  0           concatenate_61[0][0]             \n","                                                                 conv2d_129[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_131 (BatchN (None, 56, 56, 192)  768         concatenate_62[0][0]             \n","__________________________________________________________________________________________________\n","activation_131 (Activation)     (None, 56, 56, 192)  0           batch_normalization_131[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_130 (Conv2D)             (None, 56, 56, 128)  24576       activation_131[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_132 (BatchN (None, 56, 56, 128)  512         conv2d_130[0][0]                 \n","__________________________________________________________________________________________________\n","activation_132 (Activation)     (None, 56, 56, 128)  0           batch_normalization_132[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_131 (Conv2D)             (None, 56, 56, 32)   36864       activation_132[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_63 (Concatenate)    (None, 56, 56, 224)  0           concatenate_62[0][0]             \n","                                                                 conv2d_131[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_133 (BatchN (None, 56, 56, 224)  896         concatenate_63[0][0]             \n","__________________________________________________________________________________________________\n","activation_133 (Activation)     (None, 56, 56, 224)  0           batch_normalization_133[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_132 (Conv2D)             (None, 56, 56, 128)  28672       activation_133[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_134 (BatchN (None, 56, 56, 128)  512         conv2d_132[0][0]                 \n","__________________________________________________________________________________________________\n","activation_134 (Activation)     (None, 56, 56, 128)  0           batch_normalization_134[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_133 (Conv2D)             (None, 56, 56, 32)   36864       activation_134[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_64 (Concatenate)    (None, 56, 56, 256)  0           concatenate_63[0][0]             \n","                                                                 conv2d_133[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_135 (BatchN (None, 56, 56, 256)  1024        concatenate_64[0][0]             \n","__________________________________________________________________________________________________\n","activation_135 (Activation)     (None, 56, 56, 256)  0           batch_normalization_135[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_134 (Conv2D)             (None, 56, 56, 128)  32768       activation_135[0][0]             \n","__________________________________________________________________________________________________\n","average_pooling2d_4 (AveragePoo (None, 28, 28, 128)  0           conv2d_134[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_136 (BatchN (None, 28, 28, 128)  512         average_pooling2d_4[0][0]        \n","__________________________________________________________________________________________________\n","activation_136 (Activation)     (None, 28, 28, 128)  0           batch_normalization_136[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_135 (Conv2D)             (None, 28, 28, 128)  16384       activation_136[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_137 (BatchN (None, 28, 28, 128)  512         conv2d_135[0][0]                 \n","__________________________________________________________________________________________________\n","activation_137 (Activation)     (None, 28, 28, 128)  0           batch_normalization_137[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_136 (Conv2D)             (None, 28, 28, 32)   36864       activation_137[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_65 (Concatenate)    (None, 28, 28, 160)  0           average_pooling2d_4[0][0]        \n","                                                                 conv2d_136[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_138 (BatchN (None, 28, 28, 160)  640         concatenate_65[0][0]             \n","__________________________________________________________________________________________________\n","activation_138 (Activation)     (None, 28, 28, 160)  0           batch_normalization_138[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_137 (Conv2D)             (None, 28, 28, 128)  20480       activation_138[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_139 (BatchN (None, 28, 28, 128)  512         conv2d_137[0][0]                 \n","__________________________________________________________________________________________________\n","activation_139 (Activation)     (None, 28, 28, 128)  0           batch_normalization_139[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_138 (Conv2D)             (None, 28, 28, 32)   36864       activation_139[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_66 (Concatenate)    (None, 28, 28, 192)  0           concatenate_65[0][0]             \n","                                                                 conv2d_138[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_140 (BatchN (None, 28, 28, 192)  768         concatenate_66[0][0]             \n","__________________________________________________________________________________________________\n","activation_140 (Activation)     (None, 28, 28, 192)  0           batch_normalization_140[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_139 (Conv2D)             (None, 28, 28, 128)  24576       activation_140[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_141 (BatchN (None, 28, 28, 128)  512         conv2d_139[0][0]                 \n","__________________________________________________________________________________________________\n","activation_141 (Activation)     (None, 28, 28, 128)  0           batch_normalization_141[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_140 (Conv2D)             (None, 28, 28, 32)   36864       activation_141[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_67 (Concatenate)    (None, 28, 28, 224)  0           concatenate_66[0][0]             \n","                                                                 conv2d_140[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_142 (BatchN (None, 28, 28, 224)  896         concatenate_67[0][0]             \n","__________________________________________________________________________________________________\n","activation_142 (Activation)     (None, 28, 28, 224)  0           batch_normalization_142[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_141 (Conv2D)             (None, 28, 28, 128)  28672       activation_142[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_143 (BatchN (None, 28, 28, 128)  512         conv2d_141[0][0]                 \n","__________________________________________________________________________________________________\n","activation_143 (Activation)     (None, 28, 28, 128)  0           batch_normalization_143[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_142 (Conv2D)             (None, 28, 28, 32)   36864       activation_143[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_68 (Concatenate)    (None, 28, 28, 256)  0           concatenate_67[0][0]             \n","                                                                 conv2d_142[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_144 (BatchN (None, 28, 28, 256)  1024        concatenate_68[0][0]             \n","__________________________________________________________________________________________________\n","activation_144 (Activation)     (None, 28, 28, 256)  0           batch_normalization_144[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_143 (Conv2D)             (None, 28, 28, 128)  32768       activation_144[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_145 (BatchN (None, 28, 28, 128)  512         conv2d_143[0][0]                 \n","__________________________________________________________________________________________________\n","activation_145 (Activation)     (None, 28, 28, 128)  0           batch_normalization_145[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_144 (Conv2D)             (None, 28, 28, 32)   36864       activation_145[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_69 (Concatenate)    (None, 28, 28, 288)  0           concatenate_68[0][0]             \n","                                                                 conv2d_144[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_146 (BatchN (None, 28, 28, 288)  1152        concatenate_69[0][0]             \n","__________________________________________________________________________________________________\n","activation_146 (Activation)     (None, 28, 28, 288)  0           batch_normalization_146[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_145 (Conv2D)             (None, 28, 28, 128)  36864       activation_146[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_147 (BatchN (None, 28, 28, 128)  512         conv2d_145[0][0]                 \n","__________________________________________________________________________________________________\n","activation_147 (Activation)     (None, 28, 28, 128)  0           batch_normalization_147[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_146 (Conv2D)             (None, 28, 28, 32)   36864       activation_147[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_70 (Concatenate)    (None, 28, 28, 320)  0           concatenate_69[0][0]             \n","                                                                 conv2d_146[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_148 (BatchN (None, 28, 28, 320)  1280        concatenate_70[0][0]             \n","__________________________________________________________________________________________________\n","activation_148 (Activation)     (None, 28, 28, 320)  0           batch_normalization_148[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_147 (Conv2D)             (None, 28, 28, 128)  40960       activation_148[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_149 (BatchN (None, 28, 28, 128)  512         conv2d_147[0][0]                 \n","__________________________________________________________________________________________________\n","activation_149 (Activation)     (None, 28, 28, 128)  0           batch_normalization_149[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_148 (Conv2D)             (None, 28, 28, 32)   36864       activation_149[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_71 (Concatenate)    (None, 28, 28, 352)  0           concatenate_70[0][0]             \n","                                                                 conv2d_148[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_150 (BatchN (None, 28, 28, 352)  1408        concatenate_71[0][0]             \n","__________________________________________________________________________________________________\n","activation_150 (Activation)     (None, 28, 28, 352)  0           batch_normalization_150[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_149 (Conv2D)             (None, 28, 28, 128)  45056       activation_150[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_151 (BatchN (None, 28, 28, 128)  512         conv2d_149[0][0]                 \n","__________________________________________________________________________________________________\n","activation_151 (Activation)     (None, 28, 28, 128)  0           batch_normalization_151[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_150 (Conv2D)             (None, 28, 28, 32)   36864       activation_151[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_72 (Concatenate)    (None, 28, 28, 384)  0           concatenate_71[0][0]             \n","                                                                 conv2d_150[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_152 (BatchN (None, 28, 28, 384)  1536        concatenate_72[0][0]             \n","__________________________________________________________________________________________________\n","activation_152 (Activation)     (None, 28, 28, 384)  0           batch_normalization_152[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_151 (Conv2D)             (None, 28, 28, 128)  49152       activation_152[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_153 (BatchN (None, 28, 28, 128)  512         conv2d_151[0][0]                 \n","__________________________________________________________________________________________________\n","activation_153 (Activation)     (None, 28, 28, 128)  0           batch_normalization_153[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_152 (Conv2D)             (None, 28, 28, 32)   36864       activation_153[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_73 (Concatenate)    (None, 28, 28, 416)  0           concatenate_72[0][0]             \n","                                                                 conv2d_152[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_154 (BatchN (None, 28, 28, 416)  1664        concatenate_73[0][0]             \n","__________________________________________________________________________________________________\n","activation_154 (Activation)     (None, 28, 28, 416)  0           batch_normalization_154[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_153 (Conv2D)             (None, 28, 28, 128)  53248       activation_154[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_155 (BatchN (None, 28, 28, 128)  512         conv2d_153[0][0]                 \n","__________________________________________________________________________________________________\n","activation_155 (Activation)     (None, 28, 28, 128)  0           batch_normalization_155[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_154 (Conv2D)             (None, 28, 28, 32)   36864       activation_155[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_74 (Concatenate)    (None, 28, 28, 448)  0           concatenate_73[0][0]             \n","                                                                 conv2d_154[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_156 (BatchN (None, 28, 28, 448)  1792        concatenate_74[0][0]             \n","__________________________________________________________________________________________________\n","activation_156 (Activation)     (None, 28, 28, 448)  0           batch_normalization_156[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_155 (Conv2D)             (None, 28, 28, 128)  57344       activation_156[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_157 (BatchN (None, 28, 28, 128)  512         conv2d_155[0][0]                 \n","__________________________________________________________________________________________________\n","activation_157 (Activation)     (None, 28, 28, 128)  0           batch_normalization_157[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_156 (Conv2D)             (None, 28, 28, 32)   36864       activation_157[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_75 (Concatenate)    (None, 28, 28, 480)  0           concatenate_74[0][0]             \n","                                                                 conv2d_156[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_158 (BatchN (None, 28, 28, 480)  1920        concatenate_75[0][0]             \n","__________________________________________________________________________________________________\n","activation_158 (Activation)     (None, 28, 28, 480)  0           batch_normalization_158[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_157 (Conv2D)             (None, 28, 28, 128)  61440       activation_158[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_159 (BatchN (None, 28, 28, 128)  512         conv2d_157[0][0]                 \n","__________________________________________________________________________________________________\n","activation_159 (Activation)     (None, 28, 28, 128)  0           batch_normalization_159[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_158 (Conv2D)             (None, 28, 28, 32)   36864       activation_159[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_76 (Concatenate)    (None, 28, 28, 512)  0           concatenate_75[0][0]             \n","                                                                 conv2d_158[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_160 (BatchN (None, 28, 28, 512)  2048        concatenate_76[0][0]             \n","__________________________________________________________________________________________________\n","activation_160 (Activation)     (None, 28, 28, 512)  0           batch_normalization_160[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_159 (Conv2D)             (None, 28, 28, 256)  131072      activation_160[0][0]             \n","__________________________________________________________________________________________________\n","average_pooling2d_5 (AveragePoo (None, 14, 14, 256)  0           conv2d_159[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_161 (BatchN (None, 14, 14, 256)  1024        average_pooling2d_5[0][0]        \n","__________________________________________________________________________________________________\n","activation_161 (Activation)     (None, 14, 14, 256)  0           batch_normalization_161[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_160 (Conv2D)             (None, 14, 14, 128)  32768       activation_161[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_162 (BatchN (None, 14, 14, 128)  512         conv2d_160[0][0]                 \n","__________________________________________________________________________________________________\n","activation_162 (Activation)     (None, 14, 14, 128)  0           batch_normalization_162[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_161 (Conv2D)             (None, 14, 14, 32)   36864       activation_162[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_77 (Concatenate)    (None, 14, 14, 288)  0           average_pooling2d_5[0][0]        \n","                                                                 conv2d_161[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_163 (BatchN (None, 14, 14, 288)  1152        concatenate_77[0][0]             \n","__________________________________________________________________________________________________\n","activation_163 (Activation)     (None, 14, 14, 288)  0           batch_normalization_163[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_162 (Conv2D)             (None, 14, 14, 128)  36864       activation_163[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_164 (BatchN (None, 14, 14, 128)  512         conv2d_162[0][0]                 \n","__________________________________________________________________________________________________\n","activation_164 (Activation)     (None, 14, 14, 128)  0           batch_normalization_164[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_163 (Conv2D)             (None, 14, 14, 32)   36864       activation_164[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_78 (Concatenate)    (None, 14, 14, 320)  0           concatenate_77[0][0]             \n","                                                                 conv2d_163[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_165 (BatchN (None, 14, 14, 320)  1280        concatenate_78[0][0]             \n","__________________________________________________________________________________________________\n","activation_165 (Activation)     (None, 14, 14, 320)  0           batch_normalization_165[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_164 (Conv2D)             (None, 14, 14, 128)  40960       activation_165[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_166 (BatchN (None, 14, 14, 128)  512         conv2d_164[0][0]                 \n","__________________________________________________________________________________________________\n","activation_166 (Activation)     (None, 14, 14, 128)  0           batch_normalization_166[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_165 (Conv2D)             (None, 14, 14, 32)   36864       activation_166[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_79 (Concatenate)    (None, 14, 14, 352)  0           concatenate_78[0][0]             \n","                                                                 conv2d_165[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_167 (BatchN (None, 14, 14, 352)  1408        concatenate_79[0][0]             \n","__________________________________________________________________________________________________\n","activation_167 (Activation)     (None, 14, 14, 352)  0           batch_normalization_167[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_166 (Conv2D)             (None, 14, 14, 128)  45056       activation_167[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_168 (BatchN (None, 14, 14, 128)  512         conv2d_166[0][0]                 \n","__________________________________________________________________________________________________\n","activation_168 (Activation)     (None, 14, 14, 128)  0           batch_normalization_168[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_167 (Conv2D)             (None, 14, 14, 32)   36864       activation_168[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_80 (Concatenate)    (None, 14, 14, 384)  0           concatenate_79[0][0]             \n","                                                                 conv2d_167[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_169 (BatchN (None, 14, 14, 384)  1536        concatenate_80[0][0]             \n"],"name":"stdout"},{"output_type":"stream","text":["__________________________________________________________________________________________________\n","activation_169 (Activation)     (None, 14, 14, 384)  0           batch_normalization_169[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_168 (Conv2D)             (None, 14, 14, 128)  49152       activation_169[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_170 (BatchN (None, 14, 14, 128)  512         conv2d_168[0][0]                 \n","__________________________________________________________________________________________________\n","activation_170 (Activation)     (None, 14, 14, 128)  0           batch_normalization_170[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_169 (Conv2D)             (None, 14, 14, 32)   36864       activation_170[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_81 (Concatenate)    (None, 14, 14, 416)  0           concatenate_80[0][0]             \n","                                                                 conv2d_169[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_171 (BatchN (None, 14, 14, 416)  1664        concatenate_81[0][0]             \n","__________________________________________________________________________________________________\n","activation_171 (Activation)     (None, 14, 14, 416)  0           batch_normalization_171[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_170 (Conv2D)             (None, 14, 14, 128)  53248       activation_171[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_172 (BatchN (None, 14, 14, 128)  512         conv2d_170[0][0]                 \n","__________________________________________________________________________________________________\n","activation_172 (Activation)     (None, 14, 14, 128)  0           batch_normalization_172[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_171 (Conv2D)             (None, 14, 14, 32)   36864       activation_172[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_82 (Concatenate)    (None, 14, 14, 448)  0           concatenate_81[0][0]             \n","                                                                 conv2d_171[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_173 (BatchN (None, 14, 14, 448)  1792        concatenate_82[0][0]             \n","__________________________________________________________________________________________________\n","activation_173 (Activation)     (None, 14, 14, 448)  0           batch_normalization_173[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_172 (Conv2D)             (None, 14, 14, 128)  57344       activation_173[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_174 (BatchN (None, 14, 14, 128)  512         conv2d_172[0][0]                 \n","__________________________________________________________________________________________________\n","activation_174 (Activation)     (None, 14, 14, 128)  0           batch_normalization_174[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_173 (Conv2D)             (None, 14, 14, 32)   36864       activation_174[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_83 (Concatenate)    (None, 14, 14, 480)  0           concatenate_82[0][0]             \n","                                                                 conv2d_173[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_175 (BatchN (None, 14, 14, 480)  1920        concatenate_83[0][0]             \n","__________________________________________________________________________________________________\n","activation_175 (Activation)     (None, 14, 14, 480)  0           batch_normalization_175[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_174 (Conv2D)             (None, 14, 14, 128)  61440       activation_175[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_176 (BatchN (None, 14, 14, 128)  512         conv2d_174[0][0]                 \n","__________________________________________________________________________________________________\n","activation_176 (Activation)     (None, 14, 14, 128)  0           batch_normalization_176[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_175 (Conv2D)             (None, 14, 14, 32)   36864       activation_176[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_84 (Concatenate)    (None, 14, 14, 512)  0           concatenate_83[0][0]             \n","                                                                 conv2d_175[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_177 (BatchN (None, 14, 14, 512)  2048        concatenate_84[0][0]             \n","__________________________________________________________________________________________________\n","activation_177 (Activation)     (None, 14, 14, 512)  0           batch_normalization_177[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_176 (Conv2D)             (None, 14, 14, 128)  65536       activation_177[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_178 (BatchN (None, 14, 14, 128)  512         conv2d_176[0][0]                 \n","__________________________________________________________________________________________________\n","activation_178 (Activation)     (None, 14, 14, 128)  0           batch_normalization_178[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_177 (Conv2D)             (None, 14, 14, 32)   36864       activation_178[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_85 (Concatenate)    (None, 14, 14, 544)  0           concatenate_84[0][0]             \n","                                                                 conv2d_177[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_179 (BatchN (None, 14, 14, 544)  2176        concatenate_85[0][0]             \n","__________________________________________________________________________________________________\n","activation_179 (Activation)     (None, 14, 14, 544)  0           batch_normalization_179[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_178 (Conv2D)             (None, 14, 14, 128)  69632       activation_179[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_180 (BatchN (None, 14, 14, 128)  512         conv2d_178[0][0]                 \n","__________________________________________________________________________________________________\n","activation_180 (Activation)     (None, 14, 14, 128)  0           batch_normalization_180[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_179 (Conv2D)             (None, 14, 14, 32)   36864       activation_180[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_86 (Concatenate)    (None, 14, 14, 576)  0           concatenate_85[0][0]             \n","                                                                 conv2d_179[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_181 (BatchN (None, 14, 14, 576)  2304        concatenate_86[0][0]             \n","__________________________________________________________________________________________________\n","activation_181 (Activation)     (None, 14, 14, 576)  0           batch_normalization_181[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_180 (Conv2D)             (None, 14, 14, 128)  73728       activation_181[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_182 (BatchN (None, 14, 14, 128)  512         conv2d_180[0][0]                 \n","__________________________________________________________________________________________________\n","activation_182 (Activation)     (None, 14, 14, 128)  0           batch_normalization_182[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_181 (Conv2D)             (None, 14, 14, 32)   36864       activation_182[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_87 (Concatenate)    (None, 14, 14, 608)  0           concatenate_86[0][0]             \n","                                                                 conv2d_181[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_183 (BatchN (None, 14, 14, 608)  2432        concatenate_87[0][0]             \n","__________________________________________________________________________________________________\n","activation_183 (Activation)     (None, 14, 14, 608)  0           batch_normalization_183[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_182 (Conv2D)             (None, 14, 14, 128)  77824       activation_183[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_184 (BatchN (None, 14, 14, 128)  512         conv2d_182[0][0]                 \n","__________________________________________________________________________________________________\n","activation_184 (Activation)     (None, 14, 14, 128)  0           batch_normalization_184[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_183 (Conv2D)             (None, 14, 14, 32)   36864       activation_184[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_88 (Concatenate)    (None, 14, 14, 640)  0           concatenate_87[0][0]             \n","                                                                 conv2d_183[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_185 (BatchN (None, 14, 14, 640)  2560        concatenate_88[0][0]             \n","__________________________________________________________________________________________________\n","activation_185 (Activation)     (None, 14, 14, 640)  0           batch_normalization_185[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_184 (Conv2D)             (None, 14, 14, 128)  81920       activation_185[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_186 (BatchN (None, 14, 14, 128)  512         conv2d_184[0][0]                 \n","__________________________________________________________________________________________________\n","activation_186 (Activation)     (None, 14, 14, 128)  0           batch_normalization_186[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_185 (Conv2D)             (None, 14, 14, 32)   36864       activation_186[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_89 (Concatenate)    (None, 14, 14, 672)  0           concatenate_88[0][0]             \n","                                                                 conv2d_185[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_187 (BatchN (None, 14, 14, 672)  2688        concatenate_89[0][0]             \n","__________________________________________________________________________________________________\n","activation_187 (Activation)     (None, 14, 14, 672)  0           batch_normalization_187[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_186 (Conv2D)             (None, 14, 14, 128)  86016       activation_187[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_188 (BatchN (None, 14, 14, 128)  512         conv2d_186[0][0]                 \n","__________________________________________________________________________________________________\n","activation_188 (Activation)     (None, 14, 14, 128)  0           batch_normalization_188[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_187 (Conv2D)             (None, 14, 14, 32)   36864       activation_188[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_90 (Concatenate)    (None, 14, 14, 704)  0           concatenate_89[0][0]             \n","                                                                 conv2d_187[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_189 (BatchN (None, 14, 14, 704)  2816        concatenate_90[0][0]             \n","__________________________________________________________________________________________________\n","activation_189 (Activation)     (None, 14, 14, 704)  0           batch_normalization_189[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_188 (Conv2D)             (None, 14, 14, 128)  90112       activation_189[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_190 (BatchN (None, 14, 14, 128)  512         conv2d_188[0][0]                 \n","__________________________________________________________________________________________________\n","activation_190 (Activation)     (None, 14, 14, 128)  0           batch_normalization_190[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_189 (Conv2D)             (None, 14, 14, 32)   36864       activation_190[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_91 (Concatenate)    (None, 14, 14, 736)  0           concatenate_90[0][0]             \n","                                                                 conv2d_189[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_191 (BatchN (None, 14, 14, 736)  2944        concatenate_91[0][0]             \n","__________________________________________________________________________________________________\n","activation_191 (Activation)     (None, 14, 14, 736)  0           batch_normalization_191[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_190 (Conv2D)             (None, 14, 14, 128)  94208       activation_191[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_192 (BatchN (None, 14, 14, 128)  512         conv2d_190[0][0]                 \n","__________________________________________________________________________________________________\n","activation_192 (Activation)     (None, 14, 14, 128)  0           batch_normalization_192[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_191 (Conv2D)             (None, 14, 14, 32)   36864       activation_192[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_92 (Concatenate)    (None, 14, 14, 768)  0           concatenate_91[0][0]             \n","                                                                 conv2d_191[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_193 (BatchN (None, 14, 14, 768)  3072        concatenate_92[0][0]             \n","__________________________________________________________________________________________________\n","activation_193 (Activation)     (None, 14, 14, 768)  0           batch_normalization_193[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_192 (Conv2D)             (None, 14, 14, 128)  98304       activation_193[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_194 (BatchN (None, 14, 14, 128)  512         conv2d_192[0][0]                 \n","__________________________________________________________________________________________________\n","activation_194 (Activation)     (None, 14, 14, 128)  0           batch_normalization_194[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_193 (Conv2D)             (None, 14, 14, 32)   36864       activation_194[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_93 (Concatenate)    (None, 14, 14, 800)  0           concatenate_92[0][0]             \n","                                                                 conv2d_193[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_195 (BatchN (None, 14, 14, 800)  3200        concatenate_93[0][0]             \n","__________________________________________________________________________________________________\n","activation_195 (Activation)     (None, 14, 14, 800)  0           batch_normalization_195[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_194 (Conv2D)             (None, 14, 14, 128)  102400      activation_195[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_196 (BatchN (None, 14, 14, 128)  512         conv2d_194[0][0]                 \n","__________________________________________________________________________________________________\n","activation_196 (Activation)     (None, 14, 14, 128)  0           batch_normalization_196[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_195 (Conv2D)             (None, 14, 14, 32)   36864       activation_196[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_94 (Concatenate)    (None, 14, 14, 832)  0           concatenate_93[0][0]             \n","                                                                 conv2d_195[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_197 (BatchN (None, 14, 14, 832)  3328        concatenate_94[0][0]             \n","__________________________________________________________________________________________________\n","activation_197 (Activation)     (None, 14, 14, 832)  0           batch_normalization_197[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_196 (Conv2D)             (None, 14, 14, 128)  106496      activation_197[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_198 (BatchN (None, 14, 14, 128)  512         conv2d_196[0][0]                 \n","__________________________________________________________________________________________________\n","activation_198 (Activation)     (None, 14, 14, 128)  0           batch_normalization_198[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_197 (Conv2D)             (None, 14, 14, 32)   36864       activation_198[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_95 (Concatenate)    (None, 14, 14, 864)  0           concatenate_94[0][0]             \n","                                                                 conv2d_197[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_199 (BatchN (None, 14, 14, 864)  3456        concatenate_95[0][0]             \n","__________________________________________________________________________________________________\n","activation_199 (Activation)     (None, 14, 14, 864)  0           batch_normalization_199[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_198 (Conv2D)             (None, 14, 14, 128)  110592      activation_199[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_200 (BatchN (None, 14, 14, 128)  512         conv2d_198[0][0]                 \n","__________________________________________________________________________________________________\n","activation_200 (Activation)     (None, 14, 14, 128)  0           batch_normalization_200[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_199 (Conv2D)             (None, 14, 14, 32)   36864       activation_200[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_96 (Concatenate)    (None, 14, 14, 896)  0           concatenate_95[0][0]             \n","                                                                 conv2d_199[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_201 (BatchN (None, 14, 14, 896)  3584        concatenate_96[0][0]             \n","__________________________________________________________________________________________________\n","activation_201 (Activation)     (None, 14, 14, 896)  0           batch_normalization_201[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_200 (Conv2D)             (None, 14, 14, 128)  114688      activation_201[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_202 (BatchN (None, 14, 14, 128)  512         conv2d_200[0][0]                 \n","__________________________________________________________________________________________________\n","activation_202 (Activation)     (None, 14, 14, 128)  0           batch_normalization_202[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_201 (Conv2D)             (None, 14, 14, 32)   36864       activation_202[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_97 (Concatenate)    (None, 14, 14, 928)  0           concatenate_96[0][0]             \n","                                                                 conv2d_201[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_203 (BatchN (None, 14, 14, 928)  3712        concatenate_97[0][0]             \n","__________________________________________________________________________________________________\n","activation_203 (Activation)     (None, 14, 14, 928)  0           batch_normalization_203[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_202 (Conv2D)             (None, 14, 14, 128)  118784      activation_203[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_204 (BatchN (None, 14, 14, 128)  512         conv2d_202[0][0]                 \n","__________________________________________________________________________________________________\n","activation_204 (Activation)     (None, 14, 14, 128)  0           batch_normalization_204[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_203 (Conv2D)             (None, 14, 14, 32)   36864       activation_204[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_98 (Concatenate)    (None, 14, 14, 960)  0           concatenate_97[0][0]             \n","                                                                 conv2d_203[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_205 (BatchN (None, 14, 14, 960)  3840        concatenate_98[0][0]             \n","__________________________________________________________________________________________________\n","activation_205 (Activation)     (None, 14, 14, 960)  0           batch_normalization_205[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_204 (Conv2D)             (None, 14, 14, 128)  122880      activation_205[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_206 (BatchN (None, 14, 14, 128)  512         conv2d_204[0][0]                 \n","__________________________________________________________________________________________________\n","activation_206 (Activation)     (None, 14, 14, 128)  0           batch_normalization_206[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_205 (Conv2D)             (None, 14, 14, 32)   36864       activation_206[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_99 (Concatenate)    (None, 14, 14, 992)  0           concatenate_98[0][0]             \n","                                                                 conv2d_205[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_207 (BatchN (None, 14, 14, 992)  3968        concatenate_99[0][0]             \n","__________________________________________________________________________________________________\n","activation_207 (Activation)     (None, 14, 14, 992)  0           batch_normalization_207[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_206 (Conv2D)             (None, 14, 14, 128)  126976      activation_207[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_208 (BatchN (None, 14, 14, 128)  512         conv2d_206[0][0]                 \n","__________________________________________________________________________________________________\n","activation_208 (Activation)     (None, 14, 14, 128)  0           batch_normalization_208[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_207 (Conv2D)             (None, 14, 14, 32)   36864       activation_208[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_100 (Concatenate)   (None, 14, 14, 1024) 0           concatenate_99[0][0]             \n","                                                                 conv2d_207[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_209 (BatchN (None, 14, 14, 1024) 4096        concatenate_100[0][0]            \n","__________________________________________________________________________________________________\n","activation_209 (Activation)     (None, 14, 14, 1024) 0           batch_normalization_209[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_208 (Conv2D)             (None, 14, 14, 512)  524288      activation_209[0][0]             \n","__________________________________________________________________________________________________\n","average_pooling2d_6 (AveragePoo (None, 7, 7, 512)    0           conv2d_208[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_210 (BatchN (None, 7, 7, 512)    2048        average_pooling2d_6[0][0]        \n","__________________________________________________________________________________________________\n","activation_210 (Activation)     (None, 7, 7, 512)    0           batch_normalization_210[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_209 (Conv2D)             (None, 7, 7, 128)    65536       activation_210[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_211 (BatchN (None, 7, 7, 128)    512         conv2d_209[0][0]                 \n","__________________________________________________________________________________________________\n","activation_211 (Activation)     (None, 7, 7, 128)    0           batch_normalization_211[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_210 (Conv2D)             (None, 7, 7, 32)     36864       activation_211[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_101 (Concatenate)   (None, 7, 7, 544)    0           average_pooling2d_6[0][0]        \n","                                                                 conv2d_210[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_212 (BatchN (None, 7, 7, 544)    2176        concatenate_101[0][0]            \n","__________________________________________________________________________________________________\n","activation_212 (Activation)     (None, 7, 7, 544)    0           batch_normalization_212[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_211 (Conv2D)             (None, 7, 7, 128)    69632       activation_212[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_213 (BatchN (None, 7, 7, 128)    512         conv2d_211[0][0]                 \n","__________________________________________________________________________________________________\n","activation_213 (Activation)     (None, 7, 7, 128)    0           batch_normalization_213[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_212 (Conv2D)             (None, 7, 7, 32)     36864       activation_213[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_102 (Concatenate)   (None, 7, 7, 576)    0           concatenate_101[0][0]            \n","                                                                 conv2d_212[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_214 (BatchN (None, 7, 7, 576)    2304        concatenate_102[0][0]            \n","__________________________________________________________________________________________________\n","activation_214 (Activation)     (None, 7, 7, 576)    0           batch_normalization_214[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_213 (Conv2D)             (None, 7, 7, 128)    73728       activation_214[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_215 (BatchN (None, 7, 7, 128)    512         conv2d_213[0][0]                 \n","__________________________________________________________________________________________________\n","activation_215 (Activation)     (None, 7, 7, 128)    0           batch_normalization_215[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_214 (Conv2D)             (None, 7, 7, 32)     36864       activation_215[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_103 (Concatenate)   (None, 7, 7, 608)    0           concatenate_102[0][0]            \n","                                                                 conv2d_214[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_216 (BatchN (None, 7, 7, 608)    2432        concatenate_103[0][0]            \n","__________________________________________________________________________________________________\n","activation_216 (Activation)     (None, 7, 7, 608)    0           batch_normalization_216[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_215 (Conv2D)             (None, 7, 7, 128)    77824       activation_216[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_217 (BatchN (None, 7, 7, 128)    512         conv2d_215[0][0]                 \n","__________________________________________________________________________________________________\n","activation_217 (Activation)     (None, 7, 7, 128)    0           batch_normalization_217[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_216 (Conv2D)             (None, 7, 7, 32)     36864       activation_217[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_104 (Concatenate)   (None, 7, 7, 640)    0           concatenate_103[0][0]            \n","                                                                 conv2d_216[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_218 (BatchN (None, 7, 7, 640)    2560        concatenate_104[0][0]            \n","__________________________________________________________________________________________________\n","activation_218 (Activation)     (None, 7, 7, 640)    0           batch_normalization_218[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_217 (Conv2D)             (None, 7, 7, 128)    81920       activation_218[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_219 (BatchN (None, 7, 7, 128)    512         conv2d_217[0][0]                 \n","__________________________________________________________________________________________________\n","activation_219 (Activation)     (None, 7, 7, 128)    0           batch_normalization_219[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_218 (Conv2D)             (None, 7, 7, 32)     36864       activation_219[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_105 (Concatenate)   (None, 7, 7, 672)    0           concatenate_104[0][0]            \n","                                                                 conv2d_218[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_220 (BatchN (None, 7, 7, 672)    2688        concatenate_105[0][0]            \n","__________________________________________________________________________________________________\n","activation_220 (Activation)     (None, 7, 7, 672)    0           batch_normalization_220[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_219 (Conv2D)             (None, 7, 7, 128)    86016       activation_220[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_221 (BatchN (None, 7, 7, 128)    512         conv2d_219[0][0]                 \n","__________________________________________________________________________________________________\n","activation_221 (Activation)     (None, 7, 7, 128)    0           batch_normalization_221[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_220 (Conv2D)             (None, 7, 7, 32)     36864       activation_221[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_106 (Concatenate)   (None, 7, 7, 704)    0           concatenate_105[0][0]            \n","                                                                 conv2d_220[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_222 (BatchN (None, 7, 7, 704)    2816        concatenate_106[0][0]            \n","__________________________________________________________________________________________________\n","activation_222 (Activation)     (None, 7, 7, 704)    0           batch_normalization_222[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_221 (Conv2D)             (None, 7, 7, 128)    90112       activation_222[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_223 (BatchN (None, 7, 7, 128)    512         conv2d_221[0][0]                 \n","__________________________________________________________________________________________________\n","activation_223 (Activation)     (None, 7, 7, 128)    0           batch_normalization_223[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_222 (Conv2D)             (None, 7, 7, 32)     36864       activation_223[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_107 (Concatenate)   (None, 7, 7, 736)    0           concatenate_106[0][0]            \n","                                                                 conv2d_222[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_224 (BatchN (None, 7, 7, 736)    2944        concatenate_107[0][0]            \n","__________________________________________________________________________________________________\n","activation_224 (Activation)     (None, 7, 7, 736)    0           batch_normalization_224[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_223 (Conv2D)             (None, 7, 7, 128)    94208       activation_224[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_225 (BatchN (None, 7, 7, 128)    512         conv2d_223[0][0]                 \n","__________________________________________________________________________________________________\n","activation_225 (Activation)     (None, 7, 7, 128)    0           batch_normalization_225[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_224 (Conv2D)             (None, 7, 7, 32)     36864       activation_225[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_108 (Concatenate)   (None, 7, 7, 768)    0           concatenate_107[0][0]            \n","                                                                 conv2d_224[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_226 (BatchN (None, 7, 7, 768)    3072        concatenate_108[0][0]            \n","__________________________________________________________________________________________________\n","activation_226 (Activation)     (None, 7, 7, 768)    0           batch_normalization_226[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_225 (Conv2D)             (None, 7, 7, 128)    98304       activation_226[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_227 (BatchN (None, 7, 7, 128)    512         conv2d_225[0][0]                 \n","__________________________________________________________________________________________________\n","activation_227 (Activation)     (None, 7, 7, 128)    0           batch_normalization_227[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_226 (Conv2D)             (None, 7, 7, 32)     36864       activation_227[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_109 (Concatenate)   (None, 7, 7, 800)    0           concatenate_108[0][0]            \n","                                                                 conv2d_226[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_228 (BatchN (None, 7, 7, 800)    3200        concatenate_109[0][0]            \n","__________________________________________________________________________________________________\n","activation_228 (Activation)     (None, 7, 7, 800)    0           batch_normalization_228[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_227 (Conv2D)             (None, 7, 7, 128)    102400      activation_228[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_229 (BatchN (None, 7, 7, 128)    512         conv2d_227[0][0]                 \n","__________________________________________________________________________________________________\n","activation_229 (Activation)     (None, 7, 7, 128)    0           batch_normalization_229[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_228 (Conv2D)             (None, 7, 7, 32)     36864       activation_229[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_110 (Concatenate)   (None, 7, 7, 832)    0           concatenate_109[0][0]            \n","                                                                 conv2d_228[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_230 (BatchN (None, 7, 7, 832)    3328        concatenate_110[0][0]            \n","__________________________________________________________________________________________________\n","activation_230 (Activation)     (None, 7, 7, 832)    0           batch_normalization_230[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_229 (Conv2D)             (None, 7, 7, 128)    106496      activation_230[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_231 (BatchN (None, 7, 7, 128)    512         conv2d_229[0][0]                 \n","__________________________________________________________________________________________________\n","activation_231 (Activation)     (None, 7, 7, 128)    0           batch_normalization_231[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_230 (Conv2D)             (None, 7, 7, 32)     36864       activation_231[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_111 (Concatenate)   (None, 7, 7, 864)    0           concatenate_110[0][0]            \n","                                                                 conv2d_230[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_232 (BatchN (None, 7, 7, 864)    3456        concatenate_111[0][0]            \n","__________________________________________________________________________________________________\n","activation_232 (Activation)     (None, 7, 7, 864)    0           batch_normalization_232[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_231 (Conv2D)             (None, 7, 7, 128)    110592      activation_232[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_233 (BatchN (None, 7, 7, 128)    512         conv2d_231[0][0]                 \n","__________________________________________________________________________________________________\n","activation_233 (Activation)     (None, 7, 7, 128)    0           batch_normalization_233[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_232 (Conv2D)             (None, 7, 7, 32)     36864       activation_233[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_112 (Concatenate)   (None, 7, 7, 896)    0           concatenate_111[0][0]            \n","                                                                 conv2d_232[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_234 (BatchN (None, 7, 7, 896)    3584        concatenate_112[0][0]            \n","__________________________________________________________________________________________________\n","activation_234 (Activation)     (None, 7, 7, 896)    0           batch_normalization_234[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_233 (Conv2D)             (None, 7, 7, 128)    114688      activation_234[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_235 (BatchN (None, 7, 7, 128)    512         conv2d_233[0][0]                 \n","__________________________________________________________________________________________________\n","activation_235 (Activation)     (None, 7, 7, 128)    0           batch_normalization_235[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_234 (Conv2D)             (None, 7, 7, 32)     36864       activation_235[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_113 (Concatenate)   (None, 7, 7, 928)    0           concatenate_112[0][0]            \n","                                                                 conv2d_234[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_236 (BatchN (None, 7, 7, 928)    3712        concatenate_113[0][0]            \n","__________________________________________________________________________________________________\n","activation_236 (Activation)     (None, 7, 7, 928)    0           batch_normalization_236[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_235 (Conv2D)             (None, 7, 7, 128)    118784      activation_236[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_237 (BatchN (None, 7, 7, 128)    512         conv2d_235[0][0]                 \n","__________________________________________________________________________________________________\n","activation_237 (Activation)     (None, 7, 7, 128)    0           batch_normalization_237[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_236 (Conv2D)             (None, 7, 7, 32)     36864       activation_237[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_114 (Concatenate)   (None, 7, 7, 960)    0           concatenate_113[0][0]            \n","                                                                 conv2d_236[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_238 (BatchN (None, 7, 7, 960)    3840        concatenate_114[0][0]            \n","__________________________________________________________________________________________________\n","activation_238 (Activation)     (None, 7, 7, 960)    0           batch_normalization_238[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_237 (Conv2D)             (None, 7, 7, 128)    122880      activation_238[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_239 (BatchN (None, 7, 7, 128)    512         conv2d_237[0][0]                 \n","__________________________________________________________________________________________________\n","activation_239 (Activation)     (None, 7, 7, 128)    0           batch_normalization_239[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_238 (Conv2D)             (None, 7, 7, 32)     36864       activation_239[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_115 (Concatenate)   (None, 7, 7, 992)    0           concatenate_114[0][0]            \n","                                                                 conv2d_238[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_240 (BatchN (None, 7, 7, 992)    3968        concatenate_115[0][0]            \n","__________________________________________________________________________________________________\n","activation_240 (Activation)     (None, 7, 7, 992)    0           batch_normalization_240[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_239 (Conv2D)             (None, 7, 7, 128)    126976      activation_240[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_241 (BatchN (None, 7, 7, 128)    512         conv2d_239[0][0]                 \n","__________________________________________________________________________________________________\n","activation_241 (Activation)     (None, 7, 7, 128)    0           batch_normalization_241[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_240 (Conv2D)             (None, 7, 7, 32)     36864       activation_241[0][0]             \n","__________________________________________________________________________________________________\n","concatenate_116 (Concatenate)   (None, 7, 7, 1024)   0           concatenate_115[0][0]            \n","                                                                 conv2d_240[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_242 (BatchN (None, 7, 7, 1024)   4096        concatenate_116[0][0]            \n","__________________________________________________________________________________________________\n","activation_242 (Activation)     (None, 7, 7, 1024)   0           batch_normalization_242[0][0]    \n","__________________________________________________________________________________________________\n","global_average_pooling2d_2 (Glo (None, 1024)         0           activation_242[0][0]             \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 1000)         1025000     global_average_pooling2d_2[0][0] \n","==================================================================================================\n","Total params: 8,062,504\n","Trainable params: 7,978,856\n","Non-trainable params: 83,648\n","__________________________________________________________________________________________________\n","Predicted: [[(u'n02504013', u'Indian_elephant', 0.66329026), (u'n01871265', u'tusker', 0.28634223), (u'n02504458', u'African_elephant', 0.050195783), (u'n02397096', u'warthog', 5.2023577e-05), (u'n02109047', u'Great_Dane', 1.5670445e-05)]]\n"],"name":"stdout"}]},{"metadata":{"id":"vjepSQnIn8j-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import pickle as pickle\n","import numpy as np\n","from keras.preprocessing import image\n","from keras.applications.imagenet_utils import preprocess_input\n","\n","counter = 0\n","\n","def load_doc(filename):\n","    file = open(filename, 'r')\n","    text = file.read()\n","    file.close()\n","    return text\n","\n","def load_set(filename):\n","    doc = load_doc(filename)\n","    dataset = list()\n","    for line in doc.split('\\n'):\n","        if len(line) < 1:\n","            continue\n","        #identifier = line.split('.')[0]\n","        dataset.append(line)\n","    return set(dataset)\n","    \n","def load_image(path):\n","\timg = image.load_img(path, target_size=(224,224))\n","\tx = image.img_to_array(img)\n","\t# I commented the below line and added the one below that\n","\tx = np.expand_dims(x, axis=0)\n","\t# x = x.reshape((1, x.shape[0], x.shape[1], x.shape[2]))\n","\tx = preprocess_input(x)\n","\treturn np.asarray(x)\n","\n","def load_encoding_model():\n","    size = 224\n","    #model = DenseNetImageNet121(input_shape=(size, size, 3), include_top=False)\n","    model = DenseNetImageNet121(input_shape=(size, size, 3))\n","    model.layers.pop()\n","    model = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n","    for layer in model.layers:\n","        layer.trainable = False\n","    return model\n","\n","def get_encoding(model, img):\n","\tglobal counter\n","\tcounter += 1\n","\timage = load_image('Flickr8k_Dataset/'+str(img))\n","\tpred = model.predict(image)\n","\t# This should be done only if include_top is True\n","\tpred = np.reshape(pred, pred.shape[1])\n","\tif counter%1000 ==0: \n","\t\tprint (\"Encoding image: \"+str(counter))\n","\t\tprint (pred.shape)\n","\treturn pred\n","\n","def prepare_dataset(no_imgs = -1):\n","\tf_train_images = open('Flickr8k_text/Flickr_8k.trainImages.txt','rb')\n","\ttrain_imgs = f_train_images.read().strip().split('\\n') if no_imgs == -1 else f_train_images.read().strip().split('\\n')[:no_imgs]\n","\tf_train_images.close()\n","\n","\t#train_imgs = load_set('Flickr8k_text/Flickr_8k.trainImages.txt')\n","    \n","\tf_test_images = open('Flickr8k_text/Flickr_8k.testImages.txt','rb')\n","\ttest_imgs = f_test_images.read().strip().split('\\n') if no_imgs == -1 else f_test_images.read().strip().split('\\n')[:no_imgs]\n","\tf_test_images.close()\n","\n","\tf_train_dataset = open('Flickr8k_text/flickr_8k_train_dataset.txt','wb')\n","\tf_train_dataset.write(\"image_id\\tcaptions\\n\")\n","\n","\tf_test_dataset = open('Flickr8k_text/flickr_8k_test_dataset.txt','wb')\n","\tf_test_dataset.write(\"image_id\\tcaptions\\n\")\n","\n","\tf_captions = open('Flickr8k_text/Flickr8k.token.txt', 'rb')\n","\tcaptions = f_captions.read().strip().split('\\n')\n","\tdata = {}\n","\tfor row in captions:\n","\t\trow = row.split(\"\\t\")\n","\t\trow[0] = row[0][:len(row[0])-2]\n","\t\ttry:\n","\t\t\tdata[row[0]].append(row[1])\n","\t\texcept:\n","\t\t\tdata[row[0]] = [row[1]]\n","\tf_captions.close()\n","\n","\tencoded_images = {}\n","\tencoding_model = load_encoding_model()\n","\n","\tc_train = 0\n","\tfor img in train_imgs:\n","\t\t#print (\"Encoding image: \"+str(img))\n","\t\tencoded_images[img] = get_encoding(encoding_model, img)\n","\t\tfor capt in data[img]:\n","\t\t\tcaption = \"<start> \"+capt+\" <end>\"\n","\t\t\tf_train_dataset.write(img+\"\\t\"+caption+\"\\n\")\n","\t\t\tf_train_dataset.flush()\n","\t\t\tc_train += 1\n","\tf_train_dataset.close()\n","\n","\tc_test = 0\n","\tfor img in test_imgs:\n","\t\tencoded_images[img] = get_encoding(encoding_model, img)\n","\t\tfor capt in data[img]:\n","\t\t\tcaption = \"<start> \"+capt+\" <end>\"\n","\t\t\tf_test_dataset.write(img+\"\\t\"+caption+\"\\n\")\n","\t\t\tf_test_dataset.flush()\n","\t\t\tc_test += 1\n","\tf_test_dataset.close()\n","\twith open( \"encoded_images.p\", \"wb\" ) as pickle_f:\n","\t\tpickle.dump( encoded_images, pickle_f )\n","\treturn [c_train, c_test]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7EbuYGycn8kC","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"1ff1aea9-e7c5-4428-d5d8-2244a01c9049"},"cell_type":"code","source":["c_train, c_test = prepare_dataset()\n","print (\"Training samples = \"+str(c_train))\n","print (\"Test samples = \"+str(c_test))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Weights for the model were loaded successfully\n","Encoding image: 1000\n","(1024,)\n","Encoding image: 2000\n","(1024,)\n","Encoding image: 3000\n","(1024,)\n","Encoding image: 4000\n","(1024,)\n","Encoding image: 5000\n","(1024,)\n","Encoding image: 6000\n","(1024,)\n","Encoding image: 7000\n","(1024,)\n","Training samples = 30000\n","Test samples = 5000\n"],"name":"stdout"}]},{"metadata":{"id":"yahX_UKkn8kJ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"f1ceef89-b9a7-4911-b8de-bd0745c778b7"},"cell_type":"code","source":["from keras.applications import inception_v3\n","import numpy as np\n","import pandas as pd\n","from keras.models import Sequential\n","from keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector, Merge, Activation, Flatten\n","from keras.preprocessing import image, sequence\n","from keras.callbacks import ModelCheckpoint\n","import cPickle as pickle\n","\n","EMBEDDING_DIM = 128\n","\n","\n","class CaptionGenerator():\n","\n","    def __init__(self):\n","        self.max_cap_len = None\n","        self.vocab_size = None\n","        self.index_word = None\n","        self.word_index = None\n","        self.total_samples = None\n","        self.encoded_images = pickle.load( open( \"encoded_images.p\", \"rb\" ) )\n","        self.variable_initializer()\n","\n","    def variable_initializer(self):\n","        df = pd.read_csv('Flickr8k_text/flickr_8k_train_dataset.txt', delimiter='\\t')\n","        nb_samples = df.shape[0]\n","        iter = df.iterrows()\n","        caps = []\n","        for i in range(nb_samples):\n","            x = iter.next()\n","            caps.append(x[1][1])\n","\n","        self.total_samples=0\n","        for text in caps:\n","            self.total_samples+=len(text.split())-1\n","        print (\"Total samples : \" + str(self.total_samples))\n","        \n","        words = [txt.split() for txt in caps]\n","        unique = []\n","        for word in words:\n","            unique.extend(word)\n","\n","        unique = list(set(unique))\n","        self.vocab_size = len(unique)\n","        self.word_index = {}\n","        self.index_word = {}\n","        for i, word in enumerate(unique):\n","            self.word_index[word]=i\n","            self.index_word[i]=word\n","\n","        max_len = 0\n","        for caption in caps:\n","            if(len(caption.split()) > max_len):\n","                max_len = len(caption.split())\n","        self.max_cap_len = max_len\n","        print (\"Vocabulary size: \"+str(self.vocab_size))\n","        print (\"Maximum caption length: \"+str(self.max_cap_len))\n","        print (\"Variables initialization done!\")\n","\n","\n","    def data_generator(self, batch_size = 32):\n","        partial_caps = []\n","        next_words = []\n","        images = []\n","        print (\"Generating data...\")\n","        gen_count = 0\n","        df = pd.read_csv('Flickr8k_text/flickr_8k_train_dataset.txt', delimiter='\\t')\n","        nb_samples = df.shape[0]\n","        iter = df.iterrows()\n","        caps = []\n","        imgs = []\n","        for i in range(nb_samples):\n","            x = iter.next()\n","            caps.append(x[1][1])\n","            imgs.append(x[1][0])\n","\n","\n","        total_count = 0\n","        while 1:\n","            image_counter = -1\n","            for text in caps:\n","                image_counter+=1\n","                current_image = self.encoded_images[imgs[image_counter]]\n","                for i in range(len(text.split())-1):\n","                    total_count+=1\n","                    partial = [self.word_index[txt] for txt in text.split()[:i+1]]\n","                    partial_caps.append(partial)\n","                    next = np.zeros(self.vocab_size)\n","                    next[self.word_index[text.split()[i+1]]] = 1\n","                    next_words.append(next)\n","                    images.append(current_image)\n","\n","                    if total_count>=batch_size:\n","                        next_words = np.asarray(next_words)\n","                        images = np.asarray(images)\n","                        partial_caps = sequence.pad_sequences(partial_caps, maxlen=self.max_cap_len, padding='post')\n","                        total_count = 0\n","                        gen_count+=1\n","                        if gen_count%1000 ==0: print (\"yielding count: \"+str(gen_count))\n","                        yield [[images, partial_caps], next_words]\n","                        partial_caps = []\n","                        next_words = []\n","                        images = []\n","        \n","    def load_image(self, path):\n","        img = image.load_img(path, target_size=(224,224))\n","        x = image.img_to_array(img)\n","        return np.asarray(x)\n","\n","\n","    def create_model(self, ret_model = False):\n","        #base_model = VGG16(weights='imagenet', include_top=False, input_shape = (224, 224, 3))\n","        #base_model.trainable=False\n","        image_model = Sequential()\n","        #image_model.add(base_model)\n","        #image_model.add(Flatten())\n","        image_model.add(Dense(EMBEDDING_DIM, input_dim = 1024, activation='relu'))\n","\n","        image_model.add(RepeatVector(self.max_cap_len))\n","\n","        lang_model = Sequential()\n","        lang_model.add(Embedding(self.vocab_size, 256, input_length=self.max_cap_len))\n","        lang_model.add(LSTM(256,return_sequences=True))\n","        lang_model.add(TimeDistributed(Dense(EMBEDDING_DIM)))\n","\n","        model = Sequential()\n","        model.add(Merge([image_model, lang_model], mode='concat'))\n","        model.add(LSTM(1000,return_sequences=False))\n","        model.add(Dense(self.vocab_size))\n","        model.add(Activation('softmax'))\n","\n","        print (\"Model created!\")\n","\n","        if(ret_model==True):\n","            return model\n","\n","        model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n","        return model\n","\n","    def get_word(self,index):\n","        return self.index_word[index]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n","  from ._conv import register_converters as _register_converters\n","Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"8eqGJN6_n8kW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import keras\n","from keras.callbacks import ModelCheckpoint\n","\n","def train_model(weight = None, batch_size=32, epochs = 10, initial_epoch = 0):\n","\n","    cg = CaptionGenerator()\n","    model = cg.create_model()\n","\n","    if weight != None:\n","        model.load_weights(weight)\n","\n","    #counter = 0\n","    #file_name = 'weights-improvement-{epoch:02d}.hdf5'\n","    #checkpoint = ModelCheckpoint(file_name, monitor='loss', verbose=1, save_best_only=True, mode='min')\n","    #callbacks_list = [checkpoint]\n","    #model.fit_generator(cg.data_generator(batch_size=batch_size), steps_per_epoch=cg.total_samples/batch_size, epochs=epochs, verbose=2, callbacks=callbacks_list)\n","    \n","       \n","    counter = 0\n","    fileid='RMSProp'\n","    logfilename = fileid + \"-log.csv\"\n","    csv_logger = keras.callbacks.CSVLogger(logfilename, separator=',', append=True)\n","\n","    file_name = 'weights-improvement-{epoch:02d}.hdf5'\n","    checkpoint = ModelCheckpoint(file_name, monitor='loss', verbose=1, save_best_only=True, mode='min')\n","    callbacks_list = [checkpoint, csv_logger]\n","    model.fit_generator(cg.data_generator(batch_size=batch_size), initial_epoch=initial_epoch, steps_per_epoch=cg.total_samples/batch_size, epochs=epochs, verbose=1, callbacks=callbacks_list)\n","    \n","    \n","    try:\n","        model.save('Models/WholeModel.h5', overwrite=True)\n","        model.save_weights('Models/Weights.h5',overwrite=True)\n","    except:\n","        print (\"Error in saving model.\")\n","    print (\"Training complete...\\n\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wzTHWMVxn8kf","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"102c1816-7d1e-440f-f725-3afd202befff"},"cell_type":"code","source":["import time\n","tic = time.clock()\n","train_model(initial_epoch = 0, epochs=1, batch_size=2176)\n","toc = time.clock()\n","print('Time taken to train with 50 epochs is ', ((toc - tic)/60))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Total samples : 383454\n","Vocabulary size: 8256\n","Maximum caption length: 40\n","Variables initialization done!\n"],"name":"stdout"},{"output_type":"stream","text":["/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:127: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"],"name":"stderr"},{"output_type":"stream","text":["Model created!\n","Generating data...\n","Epoch 1/1\n","177/176 [==============================] - 292s 2s/step - loss: 5.3625 - acc: 0.1029\n","\n","Epoch 00001: loss improved from inf to 5.36252, saving model to weights-improvement-01.hdf5\n","Error in saving model.\n","Training complete...\n","\n","Time taken to train with 50 epochs is  3.8095816\n"],"name":"stdout"}]},{"metadata":{"id":"YdCGgaCnn8ku","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"bcfd516a-4dd5-489c-9492-a39366b86ecc"},"cell_type":"code","source":["import time\n","tic = time.clock()\n","train_model(initial_epoch = 1, epochs=5, batch_size=2176, weight='weights-improvement-01.hdf5')\n","toc = time.clock()\n","print('Time taken to train with 50 epochs is ', ((toc - tic)/60))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Total samples : 383454\n","Vocabulary size: 8256\n","Maximum caption length: 40\n","Variables initialization done!\n"],"name":"stdout"},{"output_type":"stream","text":["/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:127: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"],"name":"stderr"},{"output_type":"stream","text":["Model created!\n","Epoch 2/5\n","Generating data...\n","177/176 [==============================] - 294s 2s/step - loss: 5.1209 - acc: 0.1311\n","\n","Epoch 00002: loss improved from inf to 5.12086, saving model to weights-improvement-02.hdf5\n","Epoch 3/5\n","177/176 [==============================] - 275s 2s/step - loss: 4.6336 - acc: 0.2213\n","\n","Epoch 00003: loss improved from 5.12086 to 4.63364, saving model to weights-improvement-03.hdf5\n","Epoch 4/5\n","177/176 [==============================] - 275s 2s/step - loss: 4.4040 - acc: 0.2446\n","\n","Epoch 00004: loss improved from 4.63364 to 4.40397, saving model to weights-improvement-04.hdf5\n","Epoch 5/5\n","177/176 [==============================] - 275s 2s/step - loss: 4.2418 - acc: 0.2611\n","\n","Epoch 00005: loss improved from 4.40397 to 4.24180, saving model to weights-improvement-05.hdf5\n","Error in saving model.\n","Training complete...\n","\n","Time taken to train with 50 epochs is  13.41220605\n"],"name":"stdout"}]},{"metadata":{"id":"CUpfB8q0n8k6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"88292804-3aed-4ac0-991d-c1f7b55b57d3"},"cell_type":"code","source":["import time\n","tic = time.clock()\n","train_model(initial_epoch = 5, epochs=10, batch_size=2176, weight='weights-improvement-05.hdf5')\n","toc = time.clock()\n","print('Time taken to train with 5 epochs is ', ((toc - tic)/60))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Total samples : 383454\n","Vocabulary size: 8256\n","Maximum caption length: 40\n","Variables initialization done!\n"],"name":"stdout"},{"output_type":"stream","text":["/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:127: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"],"name":"stderr"},{"output_type":"stream","text":["Model created!\n","Epoch 6/10Generating data...\n","\n","176/176 [==============================] - 248s 1s/step - loss: 4.0713 - acc: 0.2789\n","\n","Epoch 00006: loss improved from inf to 4.07130, saving model to weights-improvement-06.hdf5\n","Epoch 7/10\n","176/176 [==============================] - 238s 1s/step - loss: 3.7055 - acc: 0.3165\n","\n","Epoch 00007: loss improved from 4.07130 to 3.70549, saving model to weights-improvement-07.hdf5\n","Epoch 8/10\n","176/176 [==============================] - 239s 1s/step - loss: 3.4561 - acc: 0.3393\n","\n","Epoch 00008: loss improved from 3.70549 to 3.45613, saving model to weights-improvement-08.hdf5\n","Epoch 9/10\n","176/176 [==============================] - 239s 1s/step - loss: 3.2773 - acc: 0.3552\n","\n","Epoch 00009: loss improved from 3.45613 to 3.27727, saving model to weights-improvement-09.hdf5\n","Epoch 10/10\n","176/176 [==============================] - 239s 1s/step - loss: 3.1361 - acc: 0.3682\n","\n","Epoch 00010: loss improved from 3.27727 to 3.13608, saving model to weights-improvement-10.hdf5\n","Error in saving model.\n","Training complete...\n","\n","('Time taken to train with 5 epochs is ', 16.578323066666666)\n"],"name":"stdout"}]},{"metadata":{"id":"u3ZuVNovn8lC","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"295a2301-2542-4581-e55d-c33ca94c43d4"},"cell_type":"code","source":["import time\n","tic = time.clock()\n","train_model(initial_epoch = 10, epochs=15, batch_size=2176, weight='weights-improvement-10.hdf5')\n","toc = time.clock()\n","print(\"Time taken to train with 5 epochs is \" + str(((toc - tic)/60)) + \" minutes\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Total samples : 383454\n","Vocabulary size: 8256\n","Maximum caption length: 40\n","Variables initialization done!\n"],"name":"stdout"},{"output_type":"stream","text":["/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:127: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"],"name":"stderr"},{"output_type":"stream","text":["Model created!\n","Generating data...\n","Epoch 11/15\n","176/176 [==============================] - 249s 1s/step - loss: 3.0628 - acc: 0.3770\n","\n","Epoch 00011: loss improved from inf to 3.06276, saving model to weights-improvement-11.hdf5\n","Epoch 12/15\n","176/176 [==============================] - 241s 1s/step - loss: 2.9291 - acc: 0.3869\n","\n","Epoch 00012: loss improved from 3.06276 to 2.92912, saving model to weights-improvement-12.hdf5\n","Epoch 13/15\n","176/176 [==============================] - 241s 1s/step - loss: 2.8296 - acc: 0.3958\n","\n","Epoch 00013: loss improved from 2.92912 to 2.82963, saving model to weights-improvement-13.hdf5\n","Epoch 14/15\n","176/176 [==============================] - 241s 1s/step - loss: 2.7429 - acc: 0.4036\n","\n","Epoch 00014: loss improved from 2.82963 to 2.74286, saving model to weights-improvement-14.hdf5\n","Epoch 15/15\n","176/176 [==============================] - 241s 1s/step - loss: 2.6607 - acc: 0.4110\n","\n","Epoch 00015: loss improved from 2.74286 to 2.66072, saving model to weights-improvement-15.hdf5\n","Error in saving model.\n","Training complete...\n","\n","Time taken to train with 5 epochs is 15.5013992833 minutes\n"],"name":"stdout"}]},{"metadata":{"id":"CZS5jZ8hn8lJ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"473dc3f7-e212-4f49-f794-43fa8729cddb"},"cell_type":"code","source":["import time\n","tic = time.clock()\n","train_model(initial_epoch = 15, epochs=20, batch_size=2176, weight='weights-improvement-15.hdf5')\n","toc = time.clock()\n","print(\"Time taken to train with 5 epochs is \" + str(((toc - tic)/60)) + \" minutes\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Total samples : 383454\n","Vocabulary size: 8256\n","Maximum caption length: 40\n","Variables initialization done!\n"],"name":"stdout"},{"output_type":"stream","text":["/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:127: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"],"name":"stderr"},{"output_type":"stream","text":["Model created!\n","Epoch 16/20\n","Generating data...\n","176/176 [==============================] - 254s 1s/step - loss: 2.6336 - acc: 0.4155\n","\n","Epoch 00016: loss improved from inf to 2.63358, saving model to weights-improvement-16.hdf5\n","Epoch 17/20\n","176/176 [==============================] - 246s 1s/step - loss: 2.5241 - acc: 0.4260\n","\n","Epoch 00017: loss improved from 2.63358 to 2.52411, saving model to weights-improvement-17.hdf5\n","Epoch 18/20\n","176/176 [==============================] - 247s 1s/step - loss: 2.4518 - acc: 0.4333\n","\n","Epoch 00018: loss improved from 2.52411 to 2.45180, saving model to weights-improvement-18.hdf5\n","Epoch 19/20\n","176/176 [==============================] - 246s 1s/step - loss: 2.3836 - acc: 0.4422\n","\n","Epoch 00019: loss improved from 2.45180 to 2.38357, saving model to weights-improvement-19.hdf5\n","Epoch 20/20\n","176/176 [==============================] - 246s 1s/step - loss: 2.3059 - acc: 0.4518\n","\n","Epoch 00020: loss improved from 2.38357 to 2.30587, saving model to weights-improvement-20.hdf5\n","Error in saving model.\n","Training complete...\n","\n","Time taken to train with 5 epochs is 15.4640314167 minutes\n"],"name":"stdout"}]},{"metadata":{"id":"hEDCmt9Bn8lS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"22bfe824-16f0-4558-fbe0-5ed332c5984d"},"cell_type":"code","source":["tic = time.clock()\n","train_model(initial_epoch = 20, epochs=25, batch_size=2176, weight='weights-improvement-20.hdf5')\n","toc = time.clock()\n","print(\"Time taken to train with 5 epochs is \" + str(((toc - tic)/60)) + \" minutes\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Total samples : 383454\n","Vocabulary size: 8256\n","Maximum caption length: 40\n","Variables initialization done!\n"],"name":"stdout"},{"output_type":"stream","text":["/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:127: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"],"name":"stderr"},{"output_type":"stream","text":["Model created!\n","Generating data...\n","Epoch 21/25\n","176/176 [==============================] - 262s 1s/step - loss: 2.3078 - acc: 0.4529\n","\n","Epoch 00021: loss improved from inf to 2.30783, saving model to weights-improvement-21.hdf5\n","Epoch 22/25\n","176/176 [==============================] - 253s 1s/step - loss: 2.2081 - acc: 0.4667\n","\n","Epoch 00022: loss improved from 2.30783 to 2.20812, saving model to weights-improvement-22.hdf5\n","Epoch 23/25\n","101/176 [================>.............] - ETA: 1:47 - loss: 2.1444 - acc: 0.4743"],"name":"stdout"}]},{"metadata":{"id":"fKEzHzRwn8lb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"e53eb6ab-8684-4846-f04c-2ce8ba881044"},"cell_type":"code","source":["import time\n","tic = time.clock()\n","train_model(initial_epoch = 22, epochs=25, batch_size=2176, weight='weights-improvement-22.hdf5')\n","toc = time.clock()\n","print(\"Time taken to train with 3 epochs is \" + str(((toc - tic)/60)) + \" minutes\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Total samples : 383454\n","Vocabulary size: 8256\n","Maximum caption length: 40\n","Variables initialization done!\n"],"name":"stdout"},{"output_type":"stream","text":["/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:127: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"],"name":"stderr"},{"output_type":"stream","text":["Model created!\n","Generating data...\n","Epoch 23/25\n","176/176 [==============================] - 245s 1s/step - loss: 2.2045 - acc: 0.4679\n","\n","Epoch 00023: loss improved from inf to 2.20453, saving model to weights-improvement-23.hdf5\n","Epoch 24/25\n","176/176 [==============================] - 240s 1s/step - loss: 2.1105 - acc: 0.4809\n","\n","Epoch 00024: loss improved from 2.20453 to 2.11053, saving model to weights-improvement-24.hdf5\n","Epoch 25/25\n","176/176 [==============================] - 241s 1s/step - loss: 2.0498 - acc: 0.4892\n","\n","Epoch 00025: loss improved from 2.11053 to 2.04985, saving model to weights-improvement-25.hdf5\n","Error in saving model.\n","Training complete...\n","\n","Time taken to train with 3 epochs is 9.67986563333 minutes\n"],"name":"stdout"}]},{"metadata":{"id":"FHhc-AvPn8li","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"89006221-dfe6-4077-957b-1955b51728a7"},"cell_type":"code","source":["import time\n","tic = time.clock()\n","initial_epoch = 25\n","epochs=30\n","\n","train_model(initial_epoch = initial_epoch, epochs=epochs, batch_size=2176, weight='weights-improvement-25.hdf5')\n","\n","toc = time.clock()\n","print(\"Time taken to train with \" + str(epochs - initial_epoch) + \" epochs is \" + str(((toc - tic)/60)) + \" minutes\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Total samples : 383454\n","Vocabulary size: 8256\n","Maximum caption length: 40\n","Variables initialization done!\n"],"name":"stdout"},{"output_type":"stream","text":["/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:127: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"],"name":"stderr"},{"output_type":"stream","text":["Model created!\n","Generating data...\n","Epoch 26/30\n","176/176 [==============================] - 254s 1s/step - loss: 2.0434 - acc: 0.4924\n","\n","Epoch 00026: loss improved from inf to 2.04342, saving model to weights-improvement-26.hdf5\n","Epoch 27/30\n","176/176 [==============================] - 251s 1s/step - loss: 1.9533 - acc: 0.5062\n","\n","Epoch 00027: loss improved from 2.04342 to 1.95334, saving model to weights-improvement-27.hdf5\n","Epoch 28/30\n","176/176 [==============================] - 251s 1s/step - loss: 1.9042 - acc: 0.5140\n","\n","Epoch 00028: loss improved from 1.95334 to 1.90417, saving model to weights-improvement-28.hdf5\n","Epoch 29/30\n","176/176 [==============================] - 251s 1s/step - loss: 1.8523 - acc: 0.5226\n","\n","Epoch 00029: loss improved from 1.90417 to 1.85231, saving model to weights-improvement-29.hdf5\n","Epoch 30/30\n","176/176 [==============================] - 251s 1s/step - loss: 1.8054 - acc: 0.5310\n","\n","Epoch 00030: loss improved from 1.85231 to 1.80538, saving model to weights-improvement-30.hdf5\n","Error in saving model.\n","Training complete...\n","\n","Time taken to train with 5 epochs is 15.4129204167 minutes\n"],"name":"stdout"}]},{"metadata":{"id":"tgBAxg6on8lp","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"abc69daa-4126-445c-97c9-f602f358087f"},"cell_type":"code","source":["import time\n","tic = time.clock()\n","initial_epoch = 30\n","epochs=35\n","weight = 'weights-improvement-30.hdf5'\n","\n","train_model(initial_epoch = initial_epoch, epochs=epochs, batch_size=2176, weight=weight)\n","\n","toc = time.clock()\n","print(\"Time taken to train with \" + str(epochs - initial_epoch) + \" epochs is \" + str(((toc - tic)/60)) + \" minutes\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Total samples : 383454\n","Vocabulary size: 8256\n","Maximum caption length: 40\n","Variables initialization done!\n"],"name":"stdout"},{"output_type":"stream","text":["/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:127: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"],"name":"stderr"},{"output_type":"stream","text":["Model created!\n","Generating data...\n","Epoch 31/35\n","176/176 [==============================] - 256s 1s/step - loss: 1.8103 - acc: 0.5309\n","\n","Epoch 00031: loss improved from inf to 1.81031, saving model to weights-improvement-31.hdf5\n","Epoch 32/35\n","176/176 [==============================] - 253s 1s/step - loss: 1.7219 - acc: 0.5460\n","\n","Epoch 00032: loss improved from 1.81031 to 1.72194, saving model to weights-improvement-32.hdf5\n","Epoch 33/35\n","176/176 [==============================] - 252s 1s/step - loss: 1.6755 - acc: 0.5547\n","\n","Epoch 00033: loss improved from 1.72194 to 1.67546, saving model to weights-improvement-33.hdf5\n","Epoch 34/35\n","176/176 [==============================] - 252s 1s/step - loss: 1.6288 - acc: 0.5640\n","\n","Epoch 00034: loss improved from 1.67546 to 1.62877, saving model to weights-improvement-34.hdf5\n","Epoch 35/35\n","176/176 [==============================] - 254s 1s/step - loss: 1.5853 - acc: 0.5731\n","\n","Epoch 00035: loss improved from 1.62877 to 1.58527, saving model to weights-improvement-35.hdf5\n","Error in saving model.\n","Training complete...\n","\n","Time taken to train with 5 epochs is 15.4249252167 minutes\n"],"name":"stdout"}]},{"metadata":{"id":"Vddebnq5n8ls","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"1162ddcc-831b-4c3f-82ab-28b483ef2145"},"cell_type":"code","source":["import time\n","tic = time.clock()\n","initial_epoch = 35\n","epochs=40\n","weight = 'weights-improvement-35.hdf5'\n","\n","train_model(initial_epoch = initial_epoch, epochs=epochs, batch_size=2176, weight=weight)\n","\n","toc = time.clock()\n","print(\"Time taken to train with \" + str(epochs - initial_epoch) + \" epochs is \" + str(((toc - tic)/60)) + \" minutes\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Total samples : 383454\n","Vocabulary size: 8256\n","Maximum caption length: 40\n","Variables initialization done!\n"],"name":"stdout"},{"output_type":"stream","text":["/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:127: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"],"name":"stderr"},{"output_type":"stream","text":["Model created!\n","Epoch 36/40Generating data...\n","\n","176/176 [==============================] - 260s 1s/step - loss: 1.5983 - acc: 0.5708\n","\n","Epoch 00036: loss improved from inf to 1.59833, saving model to weights-improvement-36.hdf5\n","Epoch 37/40\n","176/176 [==============================] - 256s 1s/step - loss: 1.5178 - acc: 0.5865\n","\n","Epoch 00037: loss improved from 1.59833 to 1.51777, saving model to weights-improvement-37.hdf5\n","Epoch 38/40\n","176/176 [==============================] - 256s 1s/step - loss: 1.4757 - acc: 0.5945\n","\n","Epoch 00038: loss improved from 1.51777 to 1.47569, saving model to weights-improvement-38.hdf5\n","Epoch 39/40\n","176/176 [==============================] - 257s 1s/step - loss: 1.4404 - acc: 0.6028\n","\n","Epoch 00039: loss improved from 1.47569 to 1.44039, saving model to weights-improvement-39.hdf5\n","Epoch 40/40\n","176/176 [==============================] - 258s 1s/step - loss: 1.3984 - acc: 0.6112\n","\n","Epoch 00040: loss improved from 1.44039 to 1.39839, saving model to weights-improvement-40.hdf5\n","Error in saving model.\n","Training complete...\n","\n","Time taken to train with 5 epochs is 15.3098503833 minutes\n"],"name":"stdout"}]},{"metadata":{"id":"dSj4anyvn8lx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"2579acd0-2626-4c76-fbe8-fcb4058486b5"},"cell_type":"code","source":["import time\n","tic = time.clock()\n","initial_epoch = 40\n","epochs=45\n","weight = 'weights-improvement-40.hdf5'\n","\n","train_model(initial_epoch = initial_epoch, epochs=epochs, batch_size=2176, weight=weight)\n","\n","toc = time.clock()\n","print(\"Time taken to train with \" + str(epochs - initial_epoch) + \" epochs is \" + str(((toc - tic)/60)) + \" minutes\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Total samples : 383454\n","Vocabulary size: 8256\n","Maximum caption length: 40\n","Variables initialization done!\n"],"name":"stdout"},{"output_type":"stream","text":["/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:127: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"],"name":"stderr"},{"output_type":"stream","text":["Model created!\n","Epoch 41/45Generating data...\n","\n","176/176 [==============================] - 266s 2s/step - loss: 1.4208 - acc: 0.6071\n","\n","Epoch 00041: loss improved from inf to 1.42083, saving model to weights-improvement-41.hdf5\n","Epoch 42/45\n","176/176 [==============================] - 260s 1s/step - loss: 1.3411 - acc: 0.6227\n","\n","Epoch 00042: loss improved from 1.42083 to 1.34113, saving model to weights-improvement-42.hdf5\n","Epoch 43/45\n","176/176 [==============================] - 259s 1s/step - loss: 1.3093 - acc: 0.6303\n","\n","Epoch 00043: loss improved from 1.34113 to 1.30933, saving model to weights-improvement-43.hdf5\n","Epoch 44/45\n","176/176 [==============================] - 259s 1s/step - loss: 1.2747 - acc: 0.6378\n","\n","Epoch 00044: loss improved from 1.30933 to 1.27467, saving model to weights-improvement-44.hdf5\n","Epoch 45/45\n","176/176 [==============================] - 259s 1s/step - loss: 1.2463 - acc: 0.6442\n","\n","Epoch 00045: loss improved from 1.27467 to 1.24628, saving model to weights-improvement-45.hdf5\n","Error in saving model.\n","Training complete...\n","\n","Time taken to train with 5 epochs is 15.6085048167 minutes\n"],"name":"stdout"}]},{"metadata":{"id":"iGtH7QEqn8l1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"027df465-e860-4b66-95e4-720da89f1f28"},"cell_type":"code","source":["import time\n","tic = time.clock()\n","initial_epoch = 45\n","epochs=50\n","weight = 'weights-improvement-45.hdf5'\n","\n","train_model(initial_epoch = initial_epoch, epochs=epochs, batch_size=2176, weight=weight)\n","\n","toc = time.clock()\n","print(\"Time taken to train with \" + str(epochs - initial_epoch) + \" epochs is \" + str(((toc - tic)/60)) + \" minutes\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Total samples : 383454\n","Vocabulary size: 8256\n","Maximum caption length: 40\n","Variables initialization done!\n"],"name":"stdout"},{"output_type":"stream","text":["/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:127: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"],"name":"stderr"},{"output_type":"stream","text":["Model created!\n","Generating data...Epoch 46/50\n","\n","176/176 [==============================] - 244s 1s/step - loss: 1.2672 - acc: 0.6395\n","\n","Epoch 00046: loss improved from inf to 1.26718, saving model to weights-improvement-46.hdf5\n","Epoch 47/50\n","176/176 [==============================] - 241s 1s/step - loss: 1.1975 - acc: 0.6545\n","\n","Epoch 00047: loss improved from 1.26718 to 1.19751, saving model to weights-improvement-47.hdf5\n","Epoch 48/50\n","176/176 [==============================] - 241s 1s/step - loss: 1.1685 - acc: 0.6620\n","\n","Epoch 00048: loss improved from 1.19751 to 1.16852, saving model to weights-improvement-48.hdf5\n","Epoch 49/50\n","176/176 [==============================] - 243s 1s/step - loss: 1.1356 - acc: 0.6688\n","\n","Epoch 00049: loss improved from 1.16852 to 1.13556, saving model to weights-improvement-49.hdf5\n","Epoch 50/50\n","176/176 [==============================] - 244s 1s/step - loss: 1.1090 - acc: 0.6755\n","\n","Epoch 00050: loss improved from 1.13556 to 1.10903, saving model to weights-improvement-50.hdf5\n","Error in saving model.\n","Training complete...\n","\n","Time taken to train with 5 epochs is 16.14801535 minutes\n"],"name":"stdout"}]},{"metadata":{"id":"ilPFiLK_n8l4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"208492ea-8283-4583-d4da-a45e1e5272e1"},"cell_type":"code","source":["import pickle as pickle\n","import numpy as np\n","from keras.preprocessing import sequence\n","import nltk\n","\n","cg = CaptionGenerator()\n","\n","def process_caption(caption):\n","\tcaption_split = caption.split()\n","\tprocessed_caption = caption_split[1:]\n","\ttry:\n","\t\tend_index = processed_caption.index('<end>')\n","\t\tprocessed_caption = processed_caption[:end_index]\n","\texcept:\n","\t\tpass\n","\treturn \" \".join([word for word in processed_caption])\n","\n","def get_best_caption(captions):\n","    captions.sort(key = lambda l:l[1])\n","    best_caption = captions[-1][0]\n","    return \" \".join([cg.index_word[index] for index in best_caption])\n","\n","def get_all_captions(captions):\n","    final_captions = []\n","    captions.sort(key = lambda l:l[1])\n","    for caption in captions:\n","        text_caption = \" \".join([cg.index_word[index] for index in caption[0]])\n","        final_captions.append([text_caption, caption[1]])\n","    return final_captions\n","\n","def generate_captions(model, image, beam_size):\n","\tstart = [cg.word_index['<start>']]\n","\tcaptions = [[start,0.0]]\n","\twhile(len(captions[0][0]) < cg.max_cap_len):\n","\t\ttemp_captions = []\n","\t\tfor caption in captions:\n","\t\t\tpartial_caption = sequence.pad_sequences([caption[0]], maxlen=cg.max_cap_len, padding='post')\n","\t\t\tnext_words_pred = model.predict([np.asarray([image]), np.asarray(partial_caption)])[0]\n","\t\t\tnext_words = np.argsort(next_words_pred)[-beam_size:]\n","\t\t\tfor word in next_words:\n","\t\t\t\tnew_partial_caption, new_partial_caption_prob = caption[0][:], caption[1]\n","\t\t\t\tnew_partial_caption.append(word)\n","\t\t\t\tnew_partial_caption_prob+=next_words_pred[word]\n","\t\t\t\ttemp_captions.append([new_partial_caption,new_partial_caption_prob])\n","\t\tcaptions = temp_captions\n","\t\tcaptions.sort(key = lambda l:l[1])\n","\t\tcaptions = captions[-beam_size:]\n","\n","\treturn captions\n","\n","def test_model(weight, img_name, beam_size = 3):\n","\tencoded_images = pickle.load( open( \"encoded_images.p\", \"rb\" ) )\n","\tmodel = cg.create_model(ret_model = True)\n","\tmodel.load_weights(weight)\n","\n","\timage = encoded_images[img_name]\n","\tcaptions = generate_captions(model, image, beam_size)\n","\treturn process_caption(get_best_caption(captions))\n","\t#return [process_caption(caption[0]) for caption in get_all_captions(captions)] \n","\n","def bleu_score(hypotheses, references):\n","\treturn nltk.translate.bleu_score.corpus_bleu(references, hypotheses)\n","\n","def test_model_on_images(weight, img_dir, beam_size = 3):\n","\timgs = []\n","\tcaptions = {}\n","\twith open(img_dir, 'rb') as f_images:\n","\t\timgs = f_images.read().strip().split('\\n')\n","\tencoded_images = pickle.load( open( \"encoded_images.p\", \"rb\" ) )\n","\tmodel = cg.create_model(ret_model = True)\n","\tmodel.load_weights(weight)\n","\n","\tf_pred_caption = open('predicted_captions.txt', 'wb')\n","\n","\tfor count, img_name in enumerate(imgs):\n","\t\tprint (\"Predicting for image: \"+str(count))\n","\t\timage = encoded_images[img_name]\n","\t\timage_captions = generate_captions(model, image, beam_size)\n","\t\tbest_caption = process_caption(get_best_caption(image_captions))\n","\t\tcaptions[img_name] = best_caption\n","\t\tprint (img_name+\" : \"+str(best_caption))\n","\t\tf_pred_caption.write(img_name+\"\\t\"+str(best_caption))\n","\t\tf_pred_caption.flush()\n","\tf_pred_caption.close()\n","\n","\tf_captions = open('Flickr8k_text/Flickr8k.token.txt', 'rb')\n","\tcaptions_text = f_captions.read().strip().split('\\n')\n","\timage_captions_pair = {}\n","\tfor row in captions_text:\n","\t\trow = row.split(\"\\t\")\n","\t\trow[0] = row[0][:len(row[0])-2]\n","\t\ttry:\n","\t\t\timage_captions_pair[row[0]].append(row[1])\n","\t\texcept:\n","\t\t\timage_captions_pair[row[0]] = [row[1]]\n","\tf_captions.close()\n","\t\n","\thypotheses=[]\n","\treferences = []\n","\tfor img_name in imgs:\n","\t\thypothesis = captions[img_name]\n","\t\treference = image_captions_pair[img_name]\n","\t\thypotheses.append(hypothesis)\n","\t\treferences.append(reference)\n","\n","\treturn bleu_score(hypotheses, references)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Total samples : 383454\n","Vocabulary size: 8256\n","Maximum caption length: 40\n","Variables initialization done!\n"],"name":"stdout"}]},{"metadata":{"id":"tLgoo3Eon8l7","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}},"outputId":"c5c536c3-519b-40c0-af71-d913a038b122"},"cell_type":"code","source":["weight = 'weights-improvement-50.hdf5'\n","#test_image = '3155451946_c0862c70cb.jpg'\n","test_img_dir = 'Flickr8k_text/Flickr_8k.testImages.txt'\n","#print test_model(weight, test_image)\n","print (test_model_on_images(weight, test_img_dir, beam_size=3))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:127: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"],"name":"stderr"},{"output_type":"stream","text":["Model created!\n","Predicting for image: 0\n","3385593926_d3e9c21170.jpg : A black dog with the black snow covered background .\n","Predicting for image: 1\n","2677656448_6b7e7702af.jpg : A boy in a orange shirt is standing in a swimming pool .\n","Predicting for image: 2\n","311146855_0b65fdb169.jpg : A girl in a blue shirt is sitting on a blue slide .\n","Predicting for image: 3\n","1258913059_07c613f7ff.jpg : A man in a striped shirt and a striped shirt is holding a camera .\n","Predicting for image: 4\n","241347760_d44c8d3a01.jpg : A football player is wearing a red jersey .\n","Predicting for image: 5\n","2654514044_a70a6e2c21.jpg : A brown dog carries a tennis ball in its mouth .\n","Predicting for image: 6\n","2339106348_2df90aa6a9.jpg : Two young women are staring at the camera .\n","Predicting for image: 7\n","256085101_2c2617c5d0.jpg : A dog with a red collar in the snow .\n","Predicting for image: 8\n","280706862_14c30d734a.jpg : Two young white dogs are on a dirt path .\n","Predicting for image: 9\n","3072172967_630e9c69d0.jpg : A group of members and a group of playing in front of a white rock .\n","Predicting for image: 10\n","3482062809_3b694322c4.jpg : A man and a man on a bench .\n","Predicting for image: 11\n","1167669558_87a8a467d6.jpg : Young african-american haired child holds all hands .\n","Predicting for image: 12\n","2847615962_c330bded6e.jpg : A dog jumps over a hurdle .\n","Predicting for image: 13\n","3344233740_c010378da7.jpg : A group of people are standing in front of a building .\n","Predicting for image: 14\n","2435685480_a79d42e564.jpg : A person in a red cap is jumping off a large rock .\n","Predicting for image: 15\n","3110649716_c17e14670e.jpg : A man in a green shirt is playing guitar .\n","Predicting for image: 16\n","2511019188_ca71775f2d.jpg : A white dog and a brown dog playing in the grass .\n","Predicting for image: 17\n","2521770311_3086ca90de.jpg : A man in a white dress carries hands .\n","Predicting for image: 18\n","2723477522_d89f5ac62b.jpg : A brown dog and a brown dog are running through a grassy field .\n","Predicting for image: 19\n","2218609886_892dcd6915.jpg : A little girl with her hair .\n","Predicting for image: 20\n","3745451546_fc8ec70cbd.jpg : a .\n","Predicting for image: 21\n","2844018783_524b08e5aa.jpg : a boy wearing a green coat and yellow scarf surrounded by hands .\n","Predicting for image: 22\n","3100251515_c68027cc22.jpg : A group of people are playing the camera .\n","Predicting for image: 23\n","2207244634_1db1a1890b.jpg : A man in a green shirt and black shorts is standing in front of a crowd .\n","Predicting for image: 24\n","2943023421_e297f05e11.jpg : A little boy in a red shirt is playing on a park .\n","Predicting for image: 25\n","3286822339_5535af6b93.jpg : A group of people are walking down the street .\n","Predicting for image: 26\n","2479652566_8f9fac8af5.jpg : A motorcycle racer driving his hand is looking at the track .\n","Predicting for image: 27\n","1394368714_3bc7c19969.jpg : A group of people are standing near a street .\n","Predicting for image: 28\n","872622575_ba1d3632cc.jpg : A woman and a dog are sitting on the edge of a hill .\n","Predicting for image: 29\n","2309860995_c2e2a0feeb.jpg : A man in a white shirt sits in a line of costumes .\n","Predicting for image: 30\n","241347204_007d83e252.jpg : A man is jumping onto a red rope .\n","Predicting for image: 31\n","3502343542_f9b46688e5.jpg : A man is walking down a mountain path .\n","Predicting for image: 32\n","757332692_6866ae545c.jpg : A closeup of a couple posing for a picture .\n","Predicting for image: 33\n","2748729903_3c7c920c4d.jpg : A man and a woman in a forest .\n","Predicting for image: 34\n","494792770_2c5f767ac0.jpg : A white dog in the tall grass .\n","Predicting for image: 35\n","3213992947_3f3f967a9f.jpg : A small brown dog jumps up in the air .\n","Predicting for image: 36\n","2295750198_6d152d7ceb.jpg : A group of dogs playing in a park .\n","Predicting for image: 37\n","2358898017_24496b80e8.jpg : A dog leaps to catch a Frisbee .\n","Predicting for image: 38\n","3222055946_45f7293bb2.jpg : A group of men in front of a line of water .\n","Predicting for image: 39\n","444481722_690d0cadcf.jpg : A small child is standing in the snow .\n","Predicting for image: 40\n","2647049174_0fb47cee2e.jpg : A small child wearing a black shirt is jumping over a woman in the snow .\n","Predicting for image: 41\n","1174629344_a2e1a2bdbf.jpg : A group of people and a group is rollerskating .\n","Predicting for image: 42\n","2921094201_2ed70a7963.jpg : A girl in a red shirt is making a woman on a crowded hospital .\n","Predicting for image: 43\n","2553550034_5901aa9d6c.jpg : A young boy in a red shirt is outdoors .\n","Predicting for image: 44\n","3045613316_4e88862836.jpg : A young boy and a boy jumping on a green and white field .\n","Predicting for image: 45\n","2706766641_a9df81969d.jpg : A man in a red shirt is sitting on a red slide .\n","Predicting for image: 46\n","510531976_90bbee22a2.jpg : There is a person in a cap and white cap and white swings .\n","Predicting for image: 47\n","485245061_5a5de43e20.jpg : A man in a blue shirt is standing in the snow .\n","Predicting for image: 48\n","3070011270_390e597783.jpg : A dog jumps through the snow .\n","Predicting for image: 49\n","1352410176_af6b139734.jpg : A girl in a red shirt is running on the beach .\n","Predicting for image: 50\n","1131932671_c8d17751b3.jpg : A dog is playing in the water with a ball .\n","Predicting for image: 51\n","3155451946_c0862c70cb.jpg : A group of people are posing for the camera .\n","Predicting for image: 52\n","2762301555_48a0d0aa24.jpg : A man and a dog are on the beach .\n","Predicting for image: 53\n","3442242092_e579538d82.jpg : A group of people are standing together .\n","Predicting for image: 54\n","2415803492_56a673dc25.jpg : A young boy swings a red rail .\n","Predicting for image: 55\n","2884301336_dc8e974431.jpg : A little boy in an orange cap is riding a ball .\n","Predicting for image: 56\n","3453259666_9ecaa8bb4b.jpg : A young boy plays with a slide .\n","Predicting for image: 57\n","3016606751_0e8be20abd.jpg : A man wearing a helmet and red shirt is sitting on the ground .\n","Predicting for image: 58\n","3642220260_3aa8a52670.jpg : A team of seagulls is on a beach .\n","Predicting for image: 59\n","2612488996_9450de0e54.jpg : A group of kids are standing in front of a store .\n","Predicting for image: 60\n","1499581619_a5f65a882c.jpg : A little girl and a brown dog are sitting on a rock wall .\n","Predicting for image: 61\n","1427391496_ea512cbe7f.jpg : A young boy jumps onto a slide .\n","Predicting for image: 62\n","3601843201_4809e66909.jpg : A man rolls down a track .\n","Predicting for image: 63\n","3584561689_b6eb24dd70.jpg : A boy in the air .\n","Predicting for image: 64\n","138718600_f430ebca17.jpg : A girl in a green shirt sitting on a path .\n","Predicting for image: 65\n","3220126881_b0a4f7cccb.jpg : A little girl in a striped striped striped outfit is airborne .\n","Predicting for image: 66\n","300314926_0b2e4b64f5.jpg : A brown and white dog jumps into the water . .\n","Predicting for image: 67\n","3128164023_ebe8da4c32.jpg : A white and white dog and a white and white dog wearing black .\n","Predicting for image: 68\n","324208502_674488bcea.jpg : A group of men are standing in a stadium .\n","Predicting for image: 69\n","3647750811_395fbd397e.jpg : A black and white dog runs through the grass .\n","Predicting for image: 70\n","3458211052_bb73084398.jpg : Two boys are playing soccer in a park .\n","Predicting for image: 71\n","2414397449_2ac3b78e0d.jpg : Two dogs play with a Frisbee .\n","Predicting for image: 72\n","3085226474_62aba51179.jpg : A boy in a green shirt on a skateboard .\n","Predicting for image: 73\n","968081289_cdba83ce2e.jpg : A young boy jumps off of a rock .\n","Predicting for image: 74\n","2436081047_bca044c1d3.jpg : A little boy is playing with a football swing .\n","Predicting for image: 75\n","2813992915_f732cf8539.jpg : A group of people watching a building in a city .\n","Predicting for image: 76\n","3627011534_485f667b10.jpg : A girl in a green shirt has her glove on his head .\n","Predicting for image: 77\n","3214237686_6566b8b52f.jpg : A man in a black coat is jumping in the air in the air .\n","Predicting for image: 78\n","1248940539_46d33ed487.jpg : Two dogs are playing in the sand .\n","Predicting for image: 79\n","2064790732_219e52e19c.jpg : A man in a red shirt and white shorts and red shorts with a red ball .\n","Predicting for image: 80\n","544576742_283b65fa0d.jpg : A little girl in a green shirt is sitting on a rock path .\n","Predicting for image: 81\n","2731171552_4a808c7d5a.jpg : A little boy in a green shirt is playing with a ball .\n","Predicting for image: 82\n","3609032038_005c789f64.jpg : A man is riding a bicycle through the air .\n","Predicting for image: 83\n"],"name":"stdout"},{"output_type":"stream","text":["3119875880_22f9129a1c.jpg : a man wearing a blue shirt is sitting on a rock wall .\n","Predicting for image: 84\n","3339140382_2e49bc324a.jpg : A man is skiing down a ramp in the air .\n","Predicting for image: 85\n","2712787899_d85048eb6a.jpg : A man and a woman sit on a wood street .\n","Predicting for image: 86\n","3655155990_b0e201dd3c.jpg : A black and white dog jumps in the air .\n","Predicting for image: 87\n","3325497914_f9014d615b.jpg : A dog jumping over a hurdle .\n","Predicting for image: 88\n","468310111_d9396abcbd.jpg : A brown dog is running up in the grass .\n","Predicting for image: 89\n","747921928_48eb02aab2.jpg : a man wearing a red shirt and jeans .\n","Predicting for image: 90\n","3639967449_137f48b43d.jpg : A group of people are looking at a woman in a red coat .\n","Predicting for image: 91\n","2374652725_32f90fa15c.jpg : A black and white dog looking at the camera .\n","Predicting for image: 92\n","3363750526_efcedc47a9.jpg : A girl is holding a camera in a park .\n","Predicting for image: 93\n","2689001252_e0016c89f0.jpg : A boy in a black and white striped shirt is jumping through the playground .\n","Predicting for image: 94\n","3154641421_d1b9b8c24c.jpg : A man wearing a white shirt is playing with a red ball .\n","Predicting for image: 95\n","2631300484_be8621d17b.jpg : A bunch of men all race at a park .\n","Predicting for image: 96\n","3677318686_b018862bb7.jpg : A man and a dog in the field .\n","Predicting for image: 97\n","405615014_03be7ef618.jpg : A man in a blue uniform takes a soccer ball .\n","Predicting for image: 98\n","533979933_a95b03323b.jpg : A brown dog running along a beach .\n","Predicting for image: 99\n","3437654963_c4fdc17e8b.jpg : A brown and white dog is playing with a soccer ball .\n","Predicting for image: 100\n","3462454965_a481809cea.jpg : A group of friends stand on the ground in front of a house .\n","Predicting for image: 101\n","2256133102_e2c8314ecb.jpg : Two people sitting on top of a mountain looking at the water .\n","Predicting for image: 102\n","3186412658_2ab2ebd397.jpg : A family is lounging together while one looks on .\n","Predicting for image: 103\n","3554634863_5f6f616639.jpg : A group of people in front of art .\n","Predicting for image: 104\n","3223055565_68973f5d20.jpg : A girl in a blue shirt is skiing .\n","Predicting for image: 105\n","1554713437_61b64527dd.jpg : A small white dog and a white dog on a field .\n","Predicting for image: 106\n","3150742439_b8a352e1e0.jpg : A dog is trying to catch a white dog to catch a red ball .\n","Predicting for image: 107\n","2238019823_79318d1f11.jpg : A brown dog runs along the beach .\n","Predicting for image: 108\n","3484832904_08619300d9.jpg : A group of children are playing in a water fountain .\n","Predicting for image: 109\n","3365783912_e12c3510d8.jpg : A man walks down a mountain .\n","Predicting for image: 110\n","3185409663_95f6b958d8.jpg : A person in a black jacket is standing in the surf .\n","Predicting for image: 111\n","3207358897_bfa61fa3c6.jpg : A blue and white dog jumps through the air .\n","Predicting for image: 112\n","3263497678_8bb688ca01.jpg : A boy in a striped shirt and white shorts skateboards on a concrete surface .\n","Predicting for image: 113\n","1897025969_0c41688fa6.jpg : A brown and white dog is sitting in the snow .\n","Predicting for image: 114\n","3657016761_d553e514d9.jpg : A woman in a red jacket is looking at the beach .\n","Predicting for image: 115\n","3537400880_8f410d747d.jpg : A brown dog falls his bat .\n","Predicting for image: 116\n","2419221084_01a14176b4.jpg : A brown dog jumps through the water .\n","Predicting for image: 117\n","172097782_f0844ec317.jpg : Two children are in a pool .\n","Predicting for image: 118\n","244571201_0339d8e8d1.jpg : An baseball player and a tan dog in the field .\n","Predicting for image: 119\n","3467219837_7d62213dec.jpg : A little girl in a bathing suit is smiling .\n","Predicting for image: 120\n","2928152792_b16c73434a.jpg : A man is performing a trick on a skateboard .\n","Predicting for image: 121\n","401079494_562454c4d6.jpg : A black and white dog walks on the grass .\n","Predicting for image: 122\n","2396691909_6b8c2f7c44.jpg : A group of soccer players stand in front of a building .\n","Predicting for image: 123\n","3243588540_b418ac7eda.jpg : A group of people .\n","Predicting for image: 124\n","3592992234_6d3fe58a70.jpg : A photographer in a field in the grass .\n","Predicting for image: 125\n","1417031097_ab656bc4bd.jpg : A man is standing in the middle of a red car .\n","Predicting for image: 126\n","1122944218_8eb3607403.jpg : A girl in a brown shirt and black shirt is smiling .\n","Predicting for image: 127\n","3149919755_f9272b10b3.jpg : A group of people are playing in the sand .\n","Predicting for image: 128\n","2682382530_f9f8fd1e89.jpg : A man in a red shirt is standing on the pavement .\n","Predicting for image: 129\n","2453971388_76616b6a82.jpg : A group of people play in the water .\n","Predicting for image: 130\n","3079787482_0757e9d167.jpg : Two women and a woman are posing for a picture .\n","Predicting for image: 131\n","2900274587_f2cbca4c58.jpg : A brown dog with a red collar stands on a red building .\n","Predicting for image: 132\n","3301859683_2d5e4b40a3.jpg : A man in an orange jacket is jumping in the snow .\n","Predicting for image: 133\n","1287073593_f3d2a62455.jpg : A boy stands next to a wall .\n","Predicting for image: 134\n","2718495608_d8533e3ac5.jpg : Two women and a woman are posing for a picture .\n","Predicting for image: 135\n","2054869561_ff723e9eab.jpg : A child with baby gear posing in a red tube .\n","Predicting for image: 136\n","3567061016_62768dcce1.jpg : A little boy is standing on the grass .\n","Predicting for image: 137\n","3221036999_3f7b152d8a.jpg : A young boy with long hair is on a swing .\n","Predicting for image: 138\n","2554081584_233bdf289a.jpg : A man and a woman in a harness .\n","Predicting for image: 139\n","3250695024_93e8ab7305.jpg : A man in a black hat and a man in a black hat .\n","Predicting for image: 140\n","3630332976_fdba22c50b.jpg : A woman in a green sweater is talking to the camera .\n","Predicting for image: 141\n","2902269566_419d9f1d8e.jpg : A man on a bike is wearing a helmet .\n","Predicting for image: 142\n","2544182005_3aa1332bf9.jpg : Black and white dog chasing a standing in the snow .\n","Predicting for image: 143\n","2999730677_0cfa1c146e.jpg : A brown and white dog is running in the backyard .\n","Predicting for image: 144\n","3354883962_170d19bfe4.jpg : A brown and white dog is running on a dirt road .\n","Predicting for image: 145\n","2346401538_f5e8da66fc.jpg : A man in a green shirt is standing by a rock .\n","Predicting for image: 146\n","3605676864_0fb491267e.jpg : A little girl with her hair and green shirt is laying on the street .\n","Predicting for image: 147\n","3658427967_6e2e57458d.jpg : A young man is performing a trick in the air .\n","Predicting for image: 148\n","2868575889_2c030aa8ae.jpg : There is a water .\n","Predicting for image: 149\n","3494394662_3edfd4a34c.jpg : A girl in a flower room .\n","Predicting for image: 150\n","3452127051_fa54a902b3.jpg : A brown dog is jumping over a hurdle .\n","Predicting for image: 151\n","3143155555_32b6d24f34.jpg : A woman in a white shirt and blue is looking at the camera .\n","Predicting for image: 152\n","470373679_98dceb19e7.jpg : a young black dog are standing in a white .\n","Predicting for image: 153\n","542317719_ed4dd95dc2.jpg : A little girl in a pink shirt looking at the camera .\n","Predicting for image: 154\n","2844641033_dab3715a99.jpg : A man in a red shirt is sitting on a bed .\n","Predicting for image: 155\n","2588927489_f4da2f11ec.jpg : A man and a dog are in the grass .\n","Predicting for image: 156\n","2041867793_552819a40b.jpg : A man and a woman are standing near a store .\n","Predicting for image: 157\n","2594042571_2e4666507e.jpg : A woman in a red sweater crawls through a sea .\n","Predicting for image: 158\n","493109089_468e105233.jpg : A little girl in a pink top is playing a picture .\n","Predicting for image: 159\n","3109704348_c6416244ce.jpg : A baseball player is about to throw a ball during a game .\n","Predicting for image: 160\n","241345811_46b5f157d4.jpg : A boy on a football during a stadium .\n","Predicting for image: 161\n","3457045393_2bbbb4e941.jpg : a group of people dressed in white outfits .\n","Predicting for image: 162\n","2797149878_bb8e27ecf9.jpg : A woman wearing a black shirt is playing in the ocean .\n","Predicting for image: 163\n","543007912_23fc735b99.jpg : A man and a woman sit on a bench .\n","Predicting for image: 164\n","3364026240_645d533fda.jpg : Two people are playing in the ocean .\n","Predicting for image: 165\n","466956209_2ffcea3941.jpg : A man gets ready to brush a cave .\n","Predicting for image: 166\n"],"name":"stdout"},{"output_type":"stream","text":["2300168895_a9b83e16fc.jpg : Two dogs playing in the grass .\n","Predicting for image: 167\n","106490881_5a2dd9b7bd.jpg : A young boy jumping in the snow .\n","Predicting for image: 168\n","3694991841_141804da1f.jpg : A dog jumps in the air to catch a ball .\n","Predicting for image: 169\n","1523984678_edd68464da.jpg : Two dogs are running on grass .\n","Predicting for image: 170\n","2529116152_4331dabf50.jpg : A man is performing a trick on a skateboard .\n","Predicting for image: 171\n","1773928579_5664a810dc.jpg : A group of people are playing soccer .\n","Predicting for image: 172\n","191003285_edd8d0cf58.jpg : A man and a dog are sitting on the edge of a building .\n","Predicting for image: 173\n","1392272228_cf104086e6.jpg : A black and white dog is playing in the water .\n","Predicting for image: 174\n","2910758605_73a3f5a5c2.jpg : A man and a woman sit on a cellphone .\n","Predicting for image: 175\n","3507076266_8b17993fbb.jpg : A child in a red helmet riding a dirt path .\n","Predicting for image: 176\n","535830521_aa971319fc.jpg : A group of people are singing .\n","Predicting for image: 177\n","70995350_75d0698839.jpg : A man jumps in the air .\n","Predicting for image: 178\n","909808296_23c427022d.jpg : A black dog is jumping through the woods .\n","Predicting for image: 179\n","3364861247_d590fa170d.jpg : The girl in the red shirt is raising a woman in a hat .\n","Predicting for image: 180\n","3545652636_0746537307.jpg : A boy in a blue shirt is playing a boy in the air .\n","Predicting for image: 181\n","2869491449_1041485a6b.jpg : Two brown dogs are running in the grass .\n","Predicting for image: 182\n","2901074943_041aba4607.jpg : Two asian girls are talking on a painted mat .\n","Predicting for image: 183\n","3480051754_18e5802558.jpg : A group of people are standing in front of some trees .\n","Predicting for image: 184\n","3234401637_84e0d14414.jpg : Two people are sitting on the edge of a beach .\n","Predicting for image: 185\n","1317292658_ba29330a0b.jpg : A man in a stadium kissing kissing .\n","Predicting for image: 186\n","2140182410_8e2a06fbda.jpg : A girl in a red shirt is playing with a picture hockey .\n","Predicting for image: 187\n","3095225232_2e6e6dc92e.jpg : A young boy is playing with a white dog on a slide .\n","Predicting for image: 188\n","2280525192_81911f2b00.jpg : A white dog and a brown dog on the ground .\n","Predicting for image: 189\n","2763044275_aa498eb88b.jpg : A black and brown dog runs on the grass .\n","Predicting for image: 190\n","2559503010_84f20b3bc9.jpg : A tennis player and a white dog are standing in front of a field .\n","Predicting for image: 191\n","496110746_a93ca191ae.jpg : A man and a woman looking at the camera .\n","Predicting for image: 192\n","468608014_09fd20eb9b.jpg : A white dog and a white dog are running around .\n","Predicting for image: 193\n","398662202_97e5819b79.jpg : A child in a race smiles .\n","Predicting for image: 194\n","3141293960_74459f0a24.jpg : A man with a black shirt plays a guitar .\n","Predicting for image: 195\n","2271755053_e1b1ec8442.jpg : The boy is wearing a black t-shirt and red jersey .\n","Predicting for image: 196\n","3181701312_70a379ab6e.jpg : A man and a woman taking a picture .\n","Predicting for image: 197\n","3523471597_87e0bf3b21.jpg : A tan dog is jumping on the playground .\n","Predicting for image: 198\n","2083434441_a93bc6306b.jpg : A man in a red jacket is standing on a brick street with people around .\n","Predicting for image: 199\n","54501196_a9ac9d66f2.jpg : A man in a red jacket is jumping off a rock to catch a rock .\n","Predicting for image: 200\n","751109943_2a7f8e117f.jpg : A man and a woman in white hair and hand at the camera .\n","Predicting for image: 201\n","3121521593_18f0ec14f7.jpg : A man and a woman are posing for a picture .\n","Predicting for image: 202\n","1432179046_8e3d75cf81.jpg : A man in a green shirt and black shorts is looking at the camera .\n","Predicting for image: 203\n","3234115903_f4dfc8fc75.jpg : Men playing basketball .\n","Predicting for image: 204\n","3497224764_6e17544e0d.jpg : A small boy jumps into a pool .\n","Predicting for image: 205\n","2878272032_fda05ffac7.jpg : A man climbing up a rocky mountainside .\n","Predicting for image: 206\n","1536774449_e16b1b6382.jpg : A group of people are standing on a trail in the mountains .\n","Predicting for image: 207\n","2228022180_9597b2a458.jpg : A bunch of men in a line .\n","Predicting for image: 208\n","2708686056_1b8f356264.jpg : A black and white dog is playing in the ocean .\n","Predicting for image: 209\n","1402640441_81978e32a9.jpg : A young boy climbing a rock wall .\n","Predicting for image: 210\n","3437147889_4cf26dd525.jpg : A man in a helmet is racing his bike .\n","Predicting for image: 211\n","448658518_eec0b648a6.jpg : A little girl in a green shirt takes a rock .\n","Predicting for image: 212\n","211295363_49010ca38d.jpg : A group of mountain climbers near the water .\n","Predicting for image: 213\n","583174725_6b522b621f.jpg : Boy in blue jacket getting backwards .\n","Predicting for image: 214\n","2830869109_c4e403eae6.jpg : A black and white dog with a red toy in its mouth .\n","Predicting for image: 215\n","488590040_35a3e96c89.jpg : A girl standing in the snow while holding a big bird .\n","Predicting for image: 216\n","3217266166_4e0091860b.jpg : A girl sits in a line of people .\n","Predicting for image: 217\n","3246991821_750a3097e2.jpg : A woman is playing with a camera in front of a building .\n","Predicting for image: 218\n","3048597471_5697538daf.jpg : A dog with a red ball in its mouth .\n","Predicting for image: 219\n","2854959952_3991a385ab.jpg : A baseball player in a red collar leaps on the ground .\n","Predicting for image: 220\n","2084217208_7bd9bc85e5.jpg : A little girl has hair .\n","Predicting for image: 221\n","435827376_4384c3005a.jpg : A man in a white shirt and white shorts is skating on a skateboard .\n","Predicting for image: 222\n","2944362789_aebbc22db4.jpg : A man and a dog are in a field .\n","Predicting for image: 223\n","2497420371_74788d7ba1.jpg : A boy in a green shirt is riding a bike down a dirt road .\n","Predicting for image: 224\n","309687244_4bdf3b591f.jpg : Two dogs play in the water .\n","Predicting for image: 225\n","3433982387_3fa993cf5a.jpg : A group of people stand on a bench .\n","Predicting for image: 226\n","2782433864_5a0c311d87.jpg : A brown dog is playing with a red toy .\n","Predicting for image: 227\n","136552115_6dc3e7231c.jpg : A man on a mountain bike is hiking through a forest .\n","Predicting for image: 228\n","1679617928_a73c1769be.jpg : A man wearing a blue shirt is sitting on a slide .\n","Predicting for image: 229\n","352981175_16ff5c07e4.jpg : Two men are sitting in the snow .\n","Predicting for image: 230\n","1808370027_2088394eb4.jpg : A brown dog plays in the water .\n","Predicting for image: 231\n","3651971126_309e6a5e22.jpg : Two dogs play with their mouths .\n","Predicting for image: 232\n","3708177171_529bb4ff1d.jpg : A bearded man in a black shirt is skating on a wall .\n","Predicting for image: 233\n","2450299735_62c095f40e.jpg : A young boy is playing in a pool .\n","Predicting for image: 234\n","1387785218_cee67735f5.jpg : A rugby player kicking a ball in his hand .\n","Predicting for image: 235\n","224369028_b1ac40d1fa.jpg : A young boy on a horse in his cart in the air .\n","Predicting for image: 236\n","464251704_b0f0c4c87a.jpg : A man jumps in the air at the edge of a crowd .\n","Predicting for image: 237\n","2648165716_02e2e74fd6.jpg : A brown dog is running on a green slide .\n","Predicting for image: 238\n","3085667767_66041b202e.jpg : A surfer catches a red wave .\n","Predicting for image: 239\n","3211556865_d1d9becf69.jpg : A girl in a , green shirt is overlooking the grass .\n","Predicting for image: 240\n","3503689049_63212220be.jpg : A young boy jumping in the air with his mouth open .\n","Predicting for image: 241\n","1107246521_d16a476380.jpg : Two dogs are playing in the air .\n","Predicting for image: 242\n","3201427741_3033f5b625.jpg : A black and brown dog stands in the snow .\n","Predicting for image: 243\n","3540416981_4e74f08cbb.jpg : A white dog runs on the grass .\n","Predicting for image: 244\n","410453140_5401bf659a.jpg : A little boy is playing with a group of people .\n","Predicting for image: 245\n","3702436188_2c26192fd0.jpg : A man in a black shirt is sitting on a concrete bench .\n","Predicting for image: 246\n","2216695423_1362cb25f3.jpg : A black and tan dog is playing with a black and white dog .\n","Predicting for image: 247\n","2345984157_724823b1e4.jpg : A small brown dog jumps in the water .\n","Predicting for image: 248\n","3317073508_7e13565c1b.jpg : A group of men and a large boy with the lead .\n","Predicting for image: 249\n","2101457132_69c950bc45.jpg : An older man in jeans and a helmet holds a rope .\n","Predicting for image: 250\n"],"name":"stdout"},{"output_type":"stream","text":["3285993030_87b0f1d202.jpg : A black and white dog is chasing after a tennis ball .\n","Predicting for image: 251\n","3220161734_77f42734b9.jpg : A man wears a dark dark shirt .\n","Predicting for image: 252\n","2393264648_a280744f97.jpg : A group of kids watch a chunk of snow .\n","Predicting for image: 253\n","506367606_7cca2bba9b.jpg : A man and a woman wearing a black hat .\n","Predicting for image: 254\n","422763475_0bc814dac6.jpg : A black dog is on the ice of a ice .\n","Predicting for image: 255\n","1982852140_56425fa7a2.jpg : A group of people playing in the ocean .\n","Predicting for image: 256\n","2929506802_5432054d77.jpg : A brown dog is jumping into a tennis game .\n","Predicting for image: 257\n","541063517_35044c554a.jpg : A woman poses for a picture .\n","Predicting for image: 258\n","2595186208_9b16fa0ee3.jpg : A blond dog and a grey dog in a green field .\n","Predicting for image: 259\n","2922973230_5a769ef92a.jpg : A woman in a field in the green grass .\n","Predicting for image: 260\n","166507476_9be5b9852a.jpg : A man wearing a blue helmet is sitting on a curb .\n","Predicting for image: 261\n","114051287_dd85625a04.jpg : A smiling man is playing a game of a tan dog .\n","Predicting for image: 262\n","3582742297_1daa29968e.jpg : A group of dogs are running down a mountain .\n","Predicting for image: 263\n","396360611_941e5849a3.jpg : A group of people are playing in the desert .\n","Predicting for image: 264\n","3504881781_6a842e043b.jpg : A girl in a white shirt makes a book .\n","Predicting for image: 265\n","3558370311_5734a15890.jpg : A man on a skateboard jumps into the air at night .\n","Predicting for image: 266\n","2542662402_d781dd7f7c.jpg : A little boy in a red shirt is blowing bubbles .\n","Predicting for image: 267\n","3532205154_5674b628ea.jpg : A woman in a dress points at the camera .\n","Predicting for image: 268\n","2675685200_0913d84d9b.jpg : A woman wearing a green shirt is standing beside a video street .\n","Predicting for image: 269\n","3565598162_56044bc2f7.jpg : A group of young adults are on a street .\n","Predicting for image: 270\n","3024172109_a10198e1dd.jpg : A guy in a white shirt is running through the air to look on .\n","Predicting for image: 271\n","3116769029_f5a76f04ba.jpg : A little boy is playing with a lot of event .\n","Predicting for image: 272\n","2061354254_faa5bd294b.jpg : A man and a woman are sitting in front of a lake .\n","Predicting for image: 273\n","3576259024_9c05b163aa.jpg : A man in a red jacket is riding a bike .\n","Predicting for image: 274\n","476759700_8911f087f8.jpg : A man in a blue shirt is talking to a city street .\n","Predicting for image: 275\n","2932740428_b15384f389.jpg : A man is standing in the middle of the ocean .\n","Predicting for image: 276\n","3348385580_10b53391f9.jpg : A baseball player in a green shirt and blue and blue uniform doing a toy .\n","Predicting for image: 277\n","2510020918_b2ca0fb2aa.jpg : Two women in red dress sit and posing for a picture .\n","Predicting for image: 278\n","1517721825_10176d0683.jpg : Two dogs run through the water .\n","Predicting for image: 279\n","2788945468_74a9618cfa.jpg : A man in a black shirt is sitting on a wooden bench .\n","Predicting for image: 280\n","2608289957_044849f73e.jpg : A young boy wearing a red shirt and blue shirt is smiling .\n","Predicting for image: 281\n","3328646934_5cca4cebce.jpg : A person is hanging into the air whilst talking to a crowd .\n","Predicting for image: 282\n","537532165_e4b7c0e61a.jpg : A skateboarder is jumping in the air whilst looking into a green ball .\n","Predicting for image: 283\n","2933637854_984614e18b.jpg : A boy holds a basketball .\n","Predicting for image: 284\n","3080056515_3013830309.jpg : A long haired boy with long hair and long hair is in front of a slide .\n","Predicting for image: 285\n","1425069308_488e5fcf9d.jpg : A little girl is standing in the sprinklers .\n","Predicting for image: 286\n","261490838_2f3ac98b12.jpg : A black and brown dog is running through a green field .\n","Predicting for image: 287\n","2926233397_71e617f3a3.jpg : A brown dog with a red stick in its mouth .\n","Predicting for image: 288\n","2963573792_dd51b5fbfb.jpg : A young boy jumping off of a crowd .\n","Predicting for image: 289\n","3416091866_a96003d652.jpg : A silhouette of a man and a woman are standing in front of a red race .\n","Predicting for image: 290\n","2431470169_0eeba7d602.jpg : A boy in a white shirt jumping up a white dog .\n","Predicting for image: 291\n","3099923914_fd450f6d51.jpg : A man in a red shirt is playing a music .\n","Predicting for image: 292\n","524105255_b346f288be.jpg : A little girl in a green shirt is playing by the flower fence .\n","Predicting for image: 293\n","56489627_e1de43de34.jpg : A group of people play in water .\n","Predicting for image: 294\n","2587818583_4aa8e7b174.jpg : The girl in the red coat is sitting on the ground .\n","Predicting for image: 295\n","460935487_75b2da7854.jpg : A man is playing a photo of a pole .\n","Predicting for image: 296\n","3316725440_9ccd9b5417.jpg : A brown dog with a yellow and yellow striped shirt is running through the grass .\n","Predicting for image: 297\n","2573625591_70291c894a.jpg : A brown dog and a brown dog are playing in the grass .\n","Predicting for image: 298\n","3030566410_393c36a6c5.jpg : A man in a red shirt and white shorts is about to hit the ball .\n","Predicting for image: 299\n","1131800850_89c7ffd477.jpg : A man and a woman pose for a picture .\n","Predicting for image: 300\n","3375549004_beee810e60.jpg : A young woman in a black hat and white hat .\n","Predicting for image: 301\n","2470486377_c3a39ccb7b.jpg : A little girl in a pink shirt is jumping on a pink slide .\n","Predicting for image: 302\n","436009777_440c7679a1.jpg : A man on a bicycle in the woods .\n","Predicting for image: 303\n","2862004252_53894bb28b.jpg : A man and a dog stand in the grass .\n","Predicting for image: 304\n","3361990489_92244a58ef.jpg : A man in a wetsuit is jumping a trail .\n","Predicting for image: 305\n","293879742_5fe0ffd894.jpg : a tan dog is walking through a field .\n","Predicting for image: 306\n","3203453897_6317aac6ff.jpg : A woman in a red shirt is standing next to a woman in a red scarf .\n","Predicting for image: 307\n","1772859261_236c09b861.jpg : A brown dog on a rock wall .\n","Predicting for image: 308\n","509123893_07b8ea82a9.jpg : A young boy is sitting in the grass .\n","Predicting for image: 309\n","3168123064_d1983b8f92.jpg : A black dog is running through the snow .\n","Predicting for image: 310\n","2238759450_6475641bdb.jpg : A man is taking a photo of a steep tree .\n","Predicting for image: 311\n","246055693_ccb69ac5c6.jpg : A brown dog and white dog are biting each other .\n","Predicting for image: 312\n","3521374954_37371b49a4.jpg : A man in a shirt and blue shirt is riding a red rope .\n","Predicting for image: 313\n","3143982558_9e2d44c155.jpg : A group of people are posing for a picture .\n","Predicting for image: 314\n","3119076670_64b5340530.jpg : A man and woman are posing for a picture at night .\n","Predicting for image: 315\n","2502905671_c6039804ab.jpg : A man takes a bike in midair .\n","Predicting for image: 316\n","1267711451_e2a754b4f8.jpg : A dog with a red toy in its mouth .\n","Predicting for image: 317\n","2683963310_20dcd5e566.jpg : A man wearing a black shirt and jeans .\n","Predicting for image: 318\n","302983277_69a4e732e4.jpg : A group of children are playing in a line .\n","Predicting for image: 319\n","3584534971_b44f82c4b9.jpg : a boy sits on a ledge .\n","Predicting for image: 320\n","143688283_a96ded20f1.jpg : A boy in a red shirt is kicking a football .\n","Predicting for image: 321\n","1282392036_5a0328eb86.jpg : A group of people are standing in front of a church .\n","Predicting for image: 322\n","2704934519_457dc38986.jpg : There is a man hiking into the water .\n","Predicting for image: 323\n","3499720588_c32590108e.jpg : A dog runs through the air at a backyard course .\n","Predicting for image: 324\n","506738508_327efdf9c3.jpg : A man and a woman in a blue shirt and a white hat .\n","Predicting for image: 325\n","512101751_05a6d93e19.jpg : A dog jumps through the grass .\n","Predicting for image: 326\n","2317714088_bcd081f926.jpg : A little boy is standing in front of a busy street .\n","Predicting for image: 327\n","3275704430_a75828048f.jpg : A man in a white shirt is smiling .\n","Predicting for image: 328\n","2518508760_68d8df7365.jpg : A boy in a white shirt is doing a trick .\n","Predicting for image: 329\n","3254817653_632e840423.jpg : A group of people walk down a city street .\n","Predicting for image: 330\n","3113322995_13781860f2.jpg : A white and white dog with a red collar is wearing a red collar .\n","Predicting for image: 331\n","2103568100_5d018c495b.jpg : A man on a rock wall .\n","Predicting for image: 332\n"],"name":"stdout"},{"output_type":"stream","text":["3518126579_e70e0cbb2b.jpg : A group of people pose for a picture .\n","Predicting for image: 333\n","2192131110_8a40e7c028.jpg : A young boy jumps in the air with a ball in his mouth .\n","Predicting for image: 334\n","2581066814_179d28f306.jpg : A group of people are watching a red bike .\n","Predicting for image: 335\n","480505313_2dc686e5db.jpg : A couple taking a picture .\n","Predicting for image: 336\n","1056338697_4f7d7ce270.jpg : A little boy in a blue shirt is pointing to the camera .\n","Predicting for image: 337\n","532457586_bddfc5251d.jpg : A man in a green shirt and black shorts is looking at the camera .\n","Predicting for image: 338\n","3471841031_a949645ba8.jpg : A group of women in black uniforms swimming in the woods .\n","Predicting for image: 339\n","3295680663_af21ea648b.jpg : A young boy is jumping into the air .\n","Predicting for image: 340\n","415793623_6c1225ae27.jpg : A brown dog is playing with a black dog .\n","Predicting for image: 341\n","2666205903_8d287669e1.jpg : A little girl in a purple shirt and blue sunglasses has her back to the camera .\n","Predicting for image: 342\n","3323988406_e3c8fce690.jpg : A boy wearing a hat and black hat is jumping over a stair path .\n","Predicting for image: 343\n","3347666612_659e6e2207.jpg : Three dogs are running down a green fence .\n","Predicting for image: 344\n","3439382048_d2e23b2b4c.jpg : A little girl in a red uniform and white and white pants .\n","Predicting for image: 345\n","2522297487_57edf117f7.jpg : A man in a gray shirt is looking at the camera .\n","Predicting for image: 346\n","3003691049_f4363c2d5c.jpg : A man in a red jacket is talking to his black dog .\n","Predicting for image: 347\n","2472980433_210ec62874.jpg : A basketball player leaps into the air .\n","Predicting for image: 348\n","2307118114_c258e3a47e.jpg : A baby is in front of a flower room .\n","Predicting for image: 349\n","2410320522_d967f0b75c.jpg : A tan dog carries a soccer ball in its mouth .\n","Predicting for image: 350\n","1408958345_68eea9a4e4.jpg : A man in a red jacket is standing on a beach .\n","Predicting for image: 351\n","498444334_a680d318a1.jpg : A group of people and a woman sitting in front of a brick wall .\n","Predicting for image: 352\n","3596131692_91b8a05606.jpg : A boy baseball in a field .\n","Predicting for image: 353\n","2208310655_a3d83080c5.jpg : A boy in a red shirt is playing guitar .\n","Predicting for image: 354\n","2340206885_58754a799a.jpg : Three black dogs are in the snow .\n","Predicting for image: 355\n","2968182121_b3b491df85.jpg : A greyhound with striped jerseys is running .\n","Predicting for image: 356\n","3514019869_7de4ece2a5.jpg : A dog catches a Frisbee .\n","Predicting for image: 357\n","2162564553_96de62c7e6.jpg : each in a forest .\n","Predicting for image: 358\n","766099402_cdda6964f0.jpg : A group of people jump in a competition .\n","Predicting for image: 359\n","3593392955_a4125087f6.jpg : A white dog is about to jump while walking in the woods .\n","Predicting for image: 360\n","1472230829_803818a383.jpg : A man in a red shirt and red flowered shirt is in the grass .\n","Predicting for image: 361\n","2774554310_007e980a90.jpg : A young boy under a purple slide is sitting on a purple slide .\n","Predicting for image: 362\n","2289068031_fe26990183.jpg : A little girl is playing with her arms .\n","Predicting for image: 363\n","3411393875_a9ff73c67a.jpg : A man wears a microphone in his hand for the shoulder .\n","Predicting for image: 364\n","3406930103_4db7b4dde0.jpg : A dog is running through the snow .\n","Predicting for image: 365\n","497791037_93499238d8.jpg : A young boy is playing with a mountain .\n","Predicting for image: 366\n","3255482333_5bcee79f7e.jpg : A black and white dog is running through the snow .\n","Predicting for image: 367\n","3040033126_9f4b88261b.jpg : A man with a helmet is climbing down a mountain .\n","Predicting for image: 368\n","2354540393_a149722680.jpg : A man in a brown shirt is looking at a woman in a red shirt .\n","Predicting for image: 369\n","2739331794_4ae78f69a0.jpg : A race race car .\n","Predicting for image: 370\n","241346508_0b3907a95b.jpg : The football player in white is challenging the player in white .\n","Predicting for image: 371\n","2877503811_4e311253ec.jpg : A man in a green shirt and a black hat is playing a guitar .\n","Predicting for image: 372\n","3484649669_7bfe62080b.jpg : A dog jumps up to catch the ball .\n","Predicting for image: 373\n","1084040636_97d9633581.jpg : A tan dog on the sand .\n","Predicting for image: 374\n","3027397797_4f1d305ced.jpg : A young girl with her mouth is standing on the beach .\n","Predicting for image: 375\n","2398605966_1d0c9e6a20.jpg : A white dog with a red collar is running in the snow .\n","Predicting for image: 376\n","2533424347_cf2f84872b.jpg : A soccer player is about to jump in a hockey game .\n","Predicting for image: 377\n","189721896_1ffe76d89e.jpg : A rock climber .\n","Predicting for image: 378\n","2089426086_7acc98a3a8.jpg : A woman in a green sweater is climbing up a white wall .\n","Predicting for image: 379\n","2718024196_3ff660416a.jpg : A brown dog walks through the grass holding a yellow ball in its mouth .\n","Predicting for image: 380\n","3072114570_e1c0127529.jpg : A man is on a swing .\n","Predicting for image: 381\n","3516825206_5750824874.jpg : A group of people sit on a rock .\n","Predicting for image: 382\n","3224227640_31865b3651.jpg : a brown dog is running outside .\n","Predicting for image: 383\n","200771289_31902164a7.jpg : A man in a black hat and black hat .\n","Predicting for image: 384\n","3502993968_4ee36afb0e.jpg : A dirt biker is on a racetrack .\n","Predicting for image: 385\n","3692593096_fbaea67476.jpg : A person on a paddling wave .\n","Predicting for image: 386\n","447111935_5af98563e3.jpg : A boy in a red shirt is kicking a football .\n","Predicting for image: 387\n","3568197730_a071d7595b.jpg : A female athlete holds a kick in the air .\n","Predicting for image: 388\n","3569979711_6507841268.jpg : A brown dog is leaping into the air at the beach .\n","Predicting for image: 389\n","180506881_de0f59770f.jpg : A woman wearing a red hat and red scarf .\n","Predicting for image: 390\n","3017521547_f5ef8848e3.jpg : A young boy in a blue shirt kicking a baseball .\n","Predicting for image: 391\n","3503623999_bbd5dcfb18.jpg : A little girl in a purple shirt is lying on a wooden rail .\n","Predicting for image: 392\n","3301811927_a2797339e5.jpg : A hockey player tries to hit the ball .\n","Predicting for image: 393\n","3592968286_b63c81bcd2.jpg : A child in a red shirt .\n","Predicting for image: 394\n","2311690895_0d6efe11c8.jpg : A man and a woman are smiling .\n","Predicting for image: 395\n","452419961_6d42ab7000.jpg : A woman in a black and white scarf .\n","Predicting for image: 396\n","2641770481_c98465ff35.jpg : A man in a red shirt is kicking a basketball .\n","Predicting for image: 397\n","2878190821_6e4e03dc5f.jpg : A young boy jumping off a slide .\n","Predicting for image: 398\n","3725202807_12fbfdd207.jpg : A man in a red shirt sits next to a woman in a red shirt .\n","Predicting for image: 399\n","2938747424_64e64784f0.jpg : A black and white dog is running through the water .\n","Predicting for image: 400\n","1322323208_c7ecb742c6.jpg : A man in a blue shirt is holding a bags with his arm .\n","Predicting for image: 401\n","2458269558_277012780d.jpg : Child in plaid shirt taking a picture .\n","Predicting for image: 402\n","2985679744_75a7102aab.jpg : A man in a red shirt is looking at the camera .\n","Predicting for image: 403\n","317383917_d8bfa350b6.jpg : A A dog in the snow .\n","Predicting for image: 404\n","2482629385_f370b290d1.jpg : A little girl in a green shirt is holding a dirt bike through the grass .\n","Predicting for image: 405\n","293327462_20dee0de56.jpg : A little boy in a jumping trunks and a mountains .\n","Predicting for image: 406\n","359837950_9e22ffe6c2.jpg : A large brown dog is walking on a sandy beach .\n","Predicting for image: 407\n","354642192_3b7666a2dd.jpg : A boy is jumping into a pool .\n","Predicting for image: 408\n","1786425974_c7c5ad6aa1.jpg : Two people stand on a trail with mountains in the background .\n","Predicting for image: 409\n","3767841911_6678052eb6.jpg : A man in an orange shirt is looking down .\n","Predicting for image: 410\n","2884420269_225d27f242.jpg : A boy on a rock wall .\n","Predicting for image: 411\n","2715035273_8fc8b1291c.jpg : A man in a black shirt with a black scarf .\n","Predicting for image: 412\n","3123463486_f5b36a3624.jpg : A white and a white dog with a blue collar .\n","Predicting for image: 413\n","2194286203_5dc620006a.jpg : A group of black dogs are playing in the water .\n","Predicting for image: 414\n","2815256108_fc1302117d.jpg : A man in a striped cap is at the wheel of a bicycle .\n","Predicting for image: 415\n"],"name":"stdout"},{"output_type":"stream","text":["1348304997_afe60a61df.jpg : A little girl in a green shirt and blue shorts is holding tricks .\n","Predicting for image: 416\n","888425986_e4b6c12324.jpg : A crowd of people are watching a green bicycle .\n","Predicting for image: 417\n","3485425825_c2f3446e73.jpg : A group of children playing football on a park course .\n","Predicting for image: 418\n","3217187564_0ffd89dec1.jpg : A black dog jumps up to swing .\n","Predicting for image: 419\n","3589895574_ee08207d26.jpg : A man in a hat , purple hat , and a hat , is playing a game .\n","Predicting for image: 420\n","317109978_cb557802e1.jpg : A man jumps over a motorbike .\n","Predicting for image: 421\n","2224450291_4c133fabe8.jpg : A little girl sitting on the street .\n","Predicting for image: 422\n","3155390408_8e1a81efb2.jpg : A little girl playing with a grassy field .\n","Predicting for image: 423\n","3562050678_4196a7fff3.jpg : A boy in a green shirt is jumping on a railing .\n","Predicting for image: 424\n","2696866120_254a0345bc.jpg : A small brown and white dog with a red toy in the field .\n","Predicting for image: 425\n","3114944484_28b5bb9842.jpg : A group of people are sitting on a bed .\n","Predicting for image: 426\n","751737218_b89839a311.jpg : A person wearing a blue shirt is sitting on a mountain .\n","Predicting for image: 427\n","352382023_7605223d1c.jpg : A dog runs through the snow .\n","Predicting for image: 428\n","247704641_d883902277.jpg : A skateboarder makes a land .\n","Predicting for image: 429\n","3461041826_0e24cdf597.jpg : A dog jumps in the woods .\n","Predicting for image: 430\n","3358558292_6ab14193ed.jpg : A group of completely up a crowd .\n","Predicting for image: 431\n","525863257_053333e612.jpg : A dog walks through the water with a ball in its mouth .\n","Predicting for image: 432\n","2112921744_92bf706805.jpg : A woman and a child on a green and green ball .\n","Predicting for image: 433\n","375392855_54d46ed5c8.jpg : A black and white dog racing fast in the air .\n","Predicting for image: 434\n","1917265421_aeccf1ca38.jpg : A group of people and a girl in a red shirt are standing in a red building .\n","Predicting for image: 435\n","1659358141_0433c9bf99.jpg : A brown and white dog is jumping in the water .\n","Predicting for image: 436\n","2533642917_a5eace85e6.jpg : Two girls are sitting on a blue slide .\n","Predicting for image: 437\n","2204550058_2707d92338.jpg : A woman in a red dress holds her head on her head .\n","Predicting for image: 438\n","2764178773_d63b502812.jpg : A man stands on a rocky cliff .\n","Predicting for image: 439\n","180094434_b0f244832d.jpg : A group of children , a woman and one man in the air .\n","Predicting for image: 440\n","2308978137_bfe776d541.jpg : A little boy is standing in front of art .\n","Predicting for image: 441\n","3358682439_be4b83544c.jpg : A girl in a green shirt is sitting on the grass .\n","Predicting for image: 442\n","2602085456_d1beebcb29.jpg : A woman in blue and white poses for the camera .\n","Predicting for image: 443\n","2589241160_3832440850.jpg : Two dogs are pull a stick .\n","Predicting for image: 444\n","421322723_3470543368.jpg : A man in a black jacket and black cap is standing on a white bench .\n","Predicting for image: 445\n","2124040721_bffc0a091a.jpg : A boy in a red shirt sitting in a red slide .\n","Predicting for image: 446\n","3145967309_b33abe4d84.jpg : A boy and a baby are playing on a wooden bed .\n","Predicting for image: 447\n","300550441_f44ec3701a.jpg : A boy wearing a red t-shirt is making a white and white dog is running .\n","Predicting for image: 448\n","1584315962_5b0b45d02d.jpg : A group of people on a trail in the blue .\n","Predicting for image: 449\n","2460797929_66446c13db.jpg : A man in a blue shirt is playing in the field .\n","Predicting for image: 450\n","2909875716_25c8652614.jpg : A man in a yellow shirt is riding a small horse on a field .\n","Predicting for image: 451\n","3085667865_fa001816be.jpg : A woman is riding a surfboard on a mountain .\n","Predicting for image: 452\n","3624327440_bef4f33f32.jpg : A person is flying through the ocean .\n","Predicting for image: 453\n","979383193_0a542a059d.jpg : A group of ducks in the rocky terrain .\n","Predicting for image: 454\n","3009644534_992e9ea2a7.jpg : A tan dog with a black collar running in the dirt .\n","Predicting for image: 455\n","561940436_64d6fc125d.jpg : A man and a woman in a black and white shirt and a woman .\n","Predicting for image: 456\n","3393926562_66cc01b001.jpg : A man and a woman are sitting on a bench .\n","Predicting for image: 457\n","3299820401_c2589186c5.jpg : A woman rides a bike through the woods .\n","Predicting for image: 458\n","3545586120_283d728a97.jpg : A group of people stand near a line .\n","Predicting for image: 459\n","1467533293_a2656cc000.jpg : A group of seven seven people watching a bridge .\n","Predicting for image: 460\n","373394550_1b2296b8c4.jpg : A young boy jumps in water .\n","Predicting for image: 461\n","539751252_2bd88c456b.jpg : A boy and a boy play in a pool .\n","Predicting for image: 462\n","2621415349_ef1a7e73be.jpg : A little boy is eating .\n","Predicting for image: 463\n","2077079696_03380d218b.jpg : A man in a red shirt is climbing on a rock .\n","Predicting for image: 464\n","566397227_a469e9e415.jpg : A brown dog and a brown dog .\n","Predicting for image: 465\n","115684808_cb01227802.jpg : A group of mountain climbers stand in the mountains .\n","Predicting for image: 466\n","3387542157_81bfd00072.jpg : A small brown and white dog is sliding down a red slide .\n","Predicting for image: 467\n","2646116932_232573f030.jpg : A boy in a red helmet riding a mountain bike .\n","Predicting for image: 468\n","307327914_f98f576adb.jpg : A man dressed as a wedding \" outfit .\n","Predicting for image: 469\n","3044536048_e615466e7f.jpg : A person is jumping into the air .\n","Predicting for image: 470\n","3053743109_a2d780c0d2.jpg : A man in the air in front of a carnival game .\n","Predicting for image: 471\n","2265096094_8cc34d669c.jpg : A horse makes his arms rope .\n","Predicting for image: 472\n","2283966256_70317e1759.jpg : A man and a woman posing for a picture .\n","Predicting for image: 473\n","3609645320_815c294b65.jpg : Two dogs are trying to faces in a field .\n","Predicting for image: 474\n","3047264346_e24601bfbf.jpg : A man in a black shirt is smiling .\n","Predicting for image: 475\n","439037721_cdf1fc7358.jpg : A brown dog is walking through the distance .\n","Predicting for image: 476\n","2594902417_f65d8866a8.jpg : A dog catching a ball in his mouth .\n","Predicting for image: 477\n","533483374_86c5d4c13e.jpg : Two brown dogs are running through the surf .\n","Predicting for image: 478\n","2991575785_bd4868e215.jpg : A group of people are taking pictures .\n","Predicting for image: 479\n","3295391572_cbfde03a10.jpg : A woman in a red shirt stands in a microphone .\n","Predicting for image: 480\n","3217620013_8b17873273.jpg : A man with a camera with a guitar .\n","Predicting for image: 481\n","2526041608_a9775ab8d7.jpg : A man takes a picture on a trail .\n","Predicting for image: 482\n","3028969146_26929ae0e8.jpg : A small brown dog is playing with a yellow toy in its mouth .\n","Predicting for image: 483\n","254295381_d98fa049f4.jpg : A dog jumping on a pole .\n","Predicting for image: 484\n","2148916767_644ea6a7fa.jpg : A dog runs through the snow .\n","Predicting for image: 485\n","3200120942_59cfbb3437.jpg : people in a man in a and white and white and a black and a black and black a black black black black black black black black black black black black white white dog in a white white white\n","Predicting for image: 486\n","3591458156_f1a9a33918.jpg : Two dogs are running around a hill .\n","Predicting for image: 487\n","3354330935_de75be9d2f.jpg : A man in a white jacket is skiing down a snowy mountain .\n","Predicting for image: 488\n","3320356356_1497e53f80.jpg : A woman is standing on a rock overlooking a forest .\n","Predicting for image: 489\n","353180303_6a24179c50.jpg : A child with a green shirt .\n","Predicting for image: 490\n","3064383768_f6838f57da.jpg : Two dogs running through the snow .\n","Predicting for image: 491\n","154871781_ae77696b77.jpg : A sports car is being as a jumping in the air .\n","Predicting for image: 492\n","2616643090_4f2d2d1a44.jpg : A yellow dog and a brown dog are playing with a ball .\n","Predicting for image: 493\n","2049051050_20359a434a.jpg : A woman and a woman looking at a handle .\n","Predicting for image: 494\n","1472882567_33dc14c8b6.jpg : A black dog is standing in the snow .\n","Predicting for image: 495\n","170100272_d820db2199.jpg : A boy jumps a rail .\n","Predicting for image: 496\n","2096771662_984441d20d.jpg : A group of photo and a woman in a white room .\n","Predicting for image: 497\n","363617160_6cb0c723be.jpg : A little girl is standing next to a red child .\n","Predicting for image: 498\n"],"name":"stdout"},{"output_type":"stream","text":["3523474077_16e14bc54c.jpg : A man in a green shirt is jumping into a flower pool .\n","Predicting for image: 499\n","3506468593_7e41a6d9f1.jpg : A group of rock climbers in the woods .\n","Predicting for image: 500\n","1446053356_a924b4893f.jpg : A horse does a stick in his mouth .\n","Predicting for image: 501\n","3123351642_3794f2f601.jpg : a surfer is flying through the ocean .\n","Predicting for image: 502\n","523985664_c866af4850.jpg : A man in a black jacket holds a camera .\n","Predicting for image: 503\n","3251976937_20625dc2b8.jpg : A young girl with her hair stands in the distance .\n","Predicting for image: 504\n","2078311270_f01c9eaf4c.jpg : A group of people are standing in front of a forest trail .\n","Predicting for image: 505\n","350443876_c9769f5734.jpg : A man holds a camera .\n","Predicting for image: 506\n","2649406158_ded6be38de.jpg : A boy wearing a helmet and red shirt is on a skateboard in front of a crowd .\n","Predicting for image: 507\n","215214751_e913b6ff09.jpg : A little girl in a yellow shirt is riding a tennis ball .\n","Predicting for image: 508\n","2926595608_69b22be8d4.jpg : A boys in a blue and white red and white red and white and white and white red white white and boy sitting on a blue and white and white and white and white and white and a dog\n","Predicting for image: 509\n","3310067561_b92017acab.jpg : Two dogs are sniffing each other on the dirt path .\n","Predicting for image: 510\n","997722733_0cb5439472.jpg : A man in a red kayak in the air .\n","Predicting for image: 511\n","1389264266_8170bc1c54.jpg : Two people , one in black , and black standing in the air .\n","Predicting for image: 512\n","2774430374_fee1d793e7.jpg : A little girl rides a male in a field .\n","Predicting for image: 513\n","3384314832_dffc944152.jpg : A little girl in a blue bathing suit is playing with a surfboard .\n","Predicting for image: 514\n","3251648670_9339943ba2.jpg : A boy in purple pants is on a swing .\n","Predicting for image: 515\n","2933912528_52b05f84a1.jpg : A dog runs across the beach .\n","Predicting for image: 516\n","3694093650_547259731e.jpg : A group of people are looking at a staircase .\n","Predicting for image: 517\n","2197275664_fabcf3424b.jpg : A child in a life outfit is pointing to the camera .\n","Predicting for image: 518\n","2505988632_9541f15583.jpg : A couch falls out of a lake .\n","Predicting for image: 519\n","3477715432_79d82487bb.jpg : A woman in a black and white shirt is pointing to the camera .\n","Predicting for image: 520\n","241031254_0c6f30e3d1.jpg : A dog on the grass .\n","Predicting for image: 521\n","2575647360_f5de38c751.jpg : A group of kids are playing in a plain .\n","Predicting for image: 522\n","3539767254_c598b8e6c7.jpg : A man is climbing up a statue of a building .\n","Predicting for image: 523\n","3182121297_38c99b2769.jpg : A man in a green shirt is standing on a lake .\n","Predicting for image: 524\n","1682079482_9a72fa57fa.jpg : A girl in a pink shirt is lying on a wooden chair .\n","Predicting for image: 525\n","3247052319_da8aba1983.jpg : trail\n","Predicting for image: 526\n","249394748_2e4acfbbb5.jpg : A man is airborne in front of a tree .\n","Predicting for image: 527\n","2461616306_3ee7ac1b4b.jpg : A boy jumps into a swimming pool .\n","Predicting for image: 528\n","929679367_ff8c7df2ee.jpg : A dog sits in the grass .\n","Predicting for image: 529\n","468102269_135938e209.jpg : A man in black and black holding a black and black dog in the background .\n","Predicting for image: 530\n","771048251_602e5e8f45.jpg : A little girl with her hair on her head is smiling .\n","Predicting for image: 531\n","2384353160_f395e9a54b.jpg : A woman wearing a black hat and purple hat playing in the water .\n","Predicting for image: 532\n","3245912109_fdeef6b456.jpg : A group of people with hands in the street .\n","Predicting for image: 533\n","3613955682_3860e116cf.jpg : A large group of men with stuffed toys .\n","Predicting for image: 534\n","2866254827_9a8f592017.jpg : A black and white dog jumps up in the air .\n","Predicting for image: 535\n","160792599_6a7ec52516.jpg : A little girl in a bathing green shirt is standing in front of a crowd .\n","Predicting for image: 536\n","3108732084_565b423162.jpg : A man with a backpack is hiking in the air .\n","Predicting for image: 537\n","2991994607_06f24ec7a6.jpg : A woman sits near a cigarette .\n","Predicting for image: 538\n","542179694_e170e9e465.jpg : A group of children are playing in the air .\n","Predicting for image: 539\n","136644343_0e2b423829.jpg : A man in a blue shirt is sitting on a concrete wall .\n","Predicting for image: 540\n","3605061440_1d08c80a57.jpg : A group of children are playing in a park .\n","Predicting for image: 541\n","2358554995_54ed3baa83.jpg : A man in a brown shirt with a brown shirt with a brown shirt .\n","Predicting for image: 542\n","3138399980_d6ab8b2272.jpg : A man is holding a child in the air .\n","Predicting for image: 543\n","2944836001_b38b516286.jpg : A black and white dog jumps through the air by a tree .\n","Predicting for image: 544\n","2949982320_c704b31626.jpg : A person in a black and red shirt and black pants is pushing a slide .\n","Predicting for image: 545\n","2544426580_317b1f1f73.jpg : A boy in a green shirt and blue shorts jumps onto the fence .\n","Predicting for image: 546\n","3006093003_c211737232.jpg : A young girl wearing a white shirt and sunglasses .\n","Predicting for image: 547\n","2370481277_a3085614c9.jpg : Children playing soccer .\n","Predicting for image: 548\n","2707873672_15e6b5d54b.jpg : A group of children posing in the grass .\n","Predicting for image: 549\n","3427118504_93126c83e0.jpg : A man and a woman in a wrestling room .\n","Predicting for image: 550\n","3203908917_53e53c03d1.jpg : A man in a black and white shirt reading a book .\n","Predicting for image: 551\n","1415591512_a84644750c.jpg : A person is on a bicycle in the air .\n","Predicting for image: 552\n","2757803246_8aa3499d26.jpg : A group of people are jumping in a house .\n","Predicting for image: 553\n","2061144717_5b3a1864f0.jpg : A baseball player in a striped shirt jumps on a red ball .\n","Predicting for image: 554\n","3393343330_b13df4d8ec.jpg : A large group of people are watching the player .\n","Predicting for image: 555\n","3569406219_f37ebf7b92.jpg : A young man in a black shirt is going down a dock .\n","Predicting for image: 556\n","3353036763_4cbeba03b2.jpg : A child in a white shirt is being watched by a toy .\n","Predicting for image: 557\n","3498327617_d2e3db3ee3.jpg : A man wearing a helmet is climbing up the mountainside .\n","Predicting for image: 558\n","1343426964_cde3fb54e8.jpg : A woman and a child are sitting in a stadium .\n","Predicting for image: 559\n","3425851292_de92a072ee.jpg : A little girl in a blue shirt is playing with a tennis ball .\n","Predicting for image: 560\n","3630641436_8f9ac5b9b2.jpg : A man rides a surfboard on a dirt ramp .\n","Predicting for image: 561\n","2901880865_3fd7b66a45.jpg : A man is riding a kayak through the ocean .\n","Predicting for image: 562\n","2445283938_ff477c7952.jpg : A young boy is playing with an umbrella .\n","Predicting for image: 563\n","3315616181_15dd137e27.jpg : A woman in a red cap is skating on the street .\n","Predicting for image: 564\n","1572532018_64c030c974.jpg : A young boy in a blue shirt is playing with a camera .\n","Predicting for image: 565\n","2308271254_27fb466eb4.jpg : A black dog runs in the snow .\n","Predicting for image: 566\n","2498897831_0bbb5d5b51.jpg : A group of people in a field of flowers .\n","Predicting for image: 567\n","2170222061_e8bce4a32d.jpg : A black and white dog runs on the ground .\n","Predicting for image: 568\n","2534502836_7a75305655.jpg : A black and white dog play with a brown dog .\n","Predicting for image: 569\n","534875358_6ea30d3091.jpg : A girl on a bicycle is taking a photograph of a white dog .\n","Predicting for image: 570\n","370614351_98b8a166b9.jpg : Many people are standing in front of a wooden sign .\n","Predicting for image: 571\n","3429956016_3c7e3096c2.jpg : A man holds a camera in the snow .\n","Predicting for image: 572\n","514990193_2d2422af2c.jpg : A small boy playing with a red dog while a white dog is playing a toy .\n","Predicting for image: 573\n","1287475186_2dee85f1a5.jpg : A girl holds a tennis ball .\n","Predicting for image: 574\n","2966552760_e65b22cd26.jpg : A toddler is eating a wooden .\n","Predicting for image: 575\n","486712504_36be449055.jpg : A young boy in a blue shirt sits in the pool .\n","Predicting for image: 576\n","3015863181_92ff43f4d8.jpg : A baby in a green shirt is making a wedding .\n","Predicting for image: 577\n","348380010_33bb0599ef.jpg : A brown and one brown dog and one brown and white brown dog are playing in the sand .\n","Predicting for image: 578\n"],"name":"stdout"},{"output_type":"stream","text":["3670907052_c827593564.jpg : A group of people are in a roller swing .\n","Predicting for image: 579\n","1626754053_81126b67b6.jpg : A small black and white dog runs across the grass .\n","Predicting for image: 580\n","3716244806_97d5a1fb61.jpg : A group of lots of wheel and airborne .\n","Predicting for image: 581\n","3641022607_e7a5455d6c.jpg : A man in a red shirt is riding a red bicycle down a rock .\n","Predicting for image: 582\n","2950905787_f2017d3e49.jpg : A woman in a red jacket stands on a mountaintop .\n","Predicting for image: 583\n","3482974845_db4f16befa.jpg : A group of people are playing soccer on the beach .\n","Predicting for image: 584\n","2883099128_0b056eed9e.jpg : A woman in a green shirt is sitting on a green rock .\n","Predicting for image: 585\n","2310126952_7dc86d88f6.jpg : Three dogs are chasing a tennis ball in the snow .\n","Predicting for image: 586\n","2479162876_a5ce3306af.jpg : A dog is running down a path in the dirt .\n","Predicting for image: 587\n","3498997518_c2b16f0a0e.jpg : A football player in white is being tackled by a player in the air .\n","Predicting for image: 588\n","3232470286_903a61ea16.jpg : A baseball player and a tan dog on the field .\n","Predicting for image: 589\n","2183227136_8bb657846b.jpg : A person in a green shirt is looking at the camera .\n","Predicting for image: 590\n","2120383553_5825333a3f.jpg : A brown dog plays with a toy .\n","Predicting for image: 591\n","3544793763_b38546a5e8.jpg : There are a man with a lot of people .\n","Predicting for image: 592\n","1404832008_68e432665b.jpg : A brown dog and a brown dog .\n","Predicting for image: 593\n","3541474181_489f19fae7.jpg : A white dog runs through the snow .\n","Predicting for image: 594\n","3042380610_c5ea61eef8.jpg : A group of people sit on a drinking .\n","Predicting for image: 595\n","486917990_72bd4069af.jpg : A man in a swimming pool .\n","Predicting for image: 596\n","2599444370_9e40103027.jpg : is in a pool .\n","Predicting for image: 597\n","3468694409_a51571d621.jpg : An Asian man wears a green jacket on a colorful floor .\n","Predicting for image: 598\n","494921598_af73bda568.jpg : A boy in a blue shirt is holding a football .\n","Predicting for image: 599\n","197107117_4b438b1872.jpg : A man with a camera in the air .\n","Predicting for image: 600\n","3019842612_8501c1791e.jpg : A A black black dog on a yellow and yellow dog .\n","Predicting for image: 601\n","909191414_1cf5d85821.jpg : A boy in a blue shirt is jumping into a swimming pool .\n","Predicting for image: 602\n","2945036454_280fa5b29f.jpg : A little girl in a yellow shirt is running in a field .\n","Predicting for image: 603\n","2666179615_f05a9d8331.jpg : A little boy in blue is staring at the camera .\n","Predicting for image: 604\n","3030294889_78b2ccbe51.jpg : Three children in the water .\n","Predicting for image: 605\n","509778093_21236bb64d.jpg : the brown dog running on the grass .\n","Predicting for image: 606\n","3245070961_8977fdd548.jpg : A little girl with long hair on a swing .\n","Predicting for image: 607\n","533713007_bf9f3e25b4.jpg : A woman in a green shirt is trying to cross the street .\n","Predicting for image: 608\n","2922222717_12195af92d.jpg : A black and a black and black dog are on the blanket .\n","Predicting for image: 609\n","3191135894_2b4bdabb6d.jpg : A group of people take a line .\n","Predicting for image: 610\n","700884207_d3ec546494.jpg : A man in a black jacket holds a black guitar .\n","Predicting for image: 611\n","2196846255_2c1635359a.jpg : A black and white dog is running through the water .\n","Predicting for image: 612\n","3474406285_01f3d24b71.jpg : A black and white dog is jumping over a hurdle .\n","Predicting for image: 613\n","448252603_7d928c900e.jpg : A person is performing a stunt on a trail .\n","Predicting for image: 614\n","2860872588_f2c7b30e1a.jpg : A group of people are sitting on a wall .\n","Predicting for image: 615\n","880220939_0ef1c37f1f.jpg : A woman and a woman sitting on a red building .\n","Predicting for image: 616\n","820169182_f5e78d7d19.jpg : A child in a blue tent and smiles .\n","Predicting for image: 617\n","3436063693_15c8d377a2.jpg : A little boy with a red shirt is sitting on a backyard bench .\n","Predicting for image: 618\n","1262583859_653f1469a9.jpg : A baseball player in blue is running along a field .\n","Predicting for image: 619\n","3185371756_ff4e9fa8a6.jpg : A child in a blue ice ice in the ice .\n","Predicting for image: 620\n","3591462960_86045906bd.jpg : A group of people are playing in a man 's uniforms .\n","Predicting for image: 621\n","3619416477_9d18580a14.jpg : A man on a surfboard is jumping into the air .\n","Predicting for image: 622\n","3459156091_c1879ebe28.jpg : A man on a green and white shirt is sitting on a street .\n","Predicting for image: 623\n","537559285_29be110134.jpg : A little girl in a pink dress is standing on the grass .\n","Predicting for image: 624\n","3052196390_c59dd24ca8.jpg : A brown dog and a brown dog are playing soccer .\n","Predicting for image: 625\n","2490768374_45d94fc658.jpg : A white dog leaps off a ramp .\n","Predicting for image: 626\n","150387174_24825cf871.jpg : A mountain biker rides on a mountain .\n","Predicting for image: 627\n","1962729184_6996e128e7.jpg : A group of people are walking down a city street .\n","Predicting for image: 628\n","2306674172_dc07c7f847.jpg : Two old women play in a park .\n","Predicting for image: 629\n","2086513494_dbbcb583e7.jpg : A man in a blue shirt is sitting on the street with a dog .\n","Predicting for image: 630\n","2652522323_9218afd8c2.jpg : Four dogs playing hockey .\n","Predicting for image: 631\n","3399284917_721aefe2a7.jpg : A boy jump up for a picture .\n","Predicting for image: 632\n","370713359_7560808550.jpg : Large brown dog stands in front of a crowd .\n","Predicting for image: 633\n","2843695880_eeea6c67db.jpg : A young boy is about to swim into the water .\n","Predicting for image: 634\n","2676764246_c58205a365.jpg : A group of sled dogs are playing in the field .\n","Predicting for image: 635\n","3107513635_fe8a21f148.jpg : A silhouette of a brown and white dog jumping over a red slide .\n","Predicting for image: 636\n","2885387575_9127ea10f1.jpg : Two dogs are playing with a ball .\n","Predicting for image: 637\n","3223224391_be50bf4f43.jpg : A brown and white dog runs through the water .\n","Predicting for image: 638\n","1461667284_041c8a2475.jpg : A group of people in front of a building .\n","Predicting for image: 639\n","2196316998_3b2d63f01f.jpg : A man in a blue helmet is holding a sign .\n","Predicting for image: 640\n","1998457059_c9ac9a1e1a.jpg : A man and a child are flying into the water .\n","Predicting for image: 641\n","3294209955_a1f1e2cc19.jpg : A white dog and a brown dog are playing ball .\n","Predicting for image: 642\n","488408004_a1e26d4886.jpg : A brown dog is jumping over a pole .\n","Predicting for image: 643\n","3135504530_0f4130d8f8.jpg : An Asian Asian boy wearing a red shirt is smiling .\n","Predicting for image: 644\n","3217910740_d1d61c08ab.jpg : A young boy jumps off of a slide .\n","Predicting for image: 645\n","3602838407_bf13e49243.jpg : A young girl does a bicycle\n","Predicting for image: 646\n","2984174290_a915748d77.jpg : A man surfing in the ocean .\n","Predicting for image: 647\n","424779662_568f9606d0.jpg : A group of young girls are sitting on the grass .\n","Predicting for image: 648\n","2431832075_00aa1a4457.jpg : A little boy with his hair play in a blue slide .\n","Predicting for image: 649\n","624742559_ff467d8ebc.jpg : A little boy in a blue shirt is jumping into the playground .\n","Predicting for image: 650\n","3157847991_463e006a28.jpg : A man in a green shirt and black pants is standing on a cliff reading .\n","Predicting for image: 651\n","2893374123_087f98d58a.jpg : A boy in a green shirt is wearing a helmet .\n","Predicting for image: 652\n","3359551687_68f2f0212a.jpg : The football player for the ball .\n","Predicting for image: 653\n","3070031806_3d587c2a66.jpg : Two dogs play in the snow .\n","Predicting for image: 654\n","2480850054_de3433b54a.jpg : A woman taking a picture of a book .\n","Predicting for image: 655\n","3216926094_bc975e84b9.jpg : A brown dog is playing with a colorful ball in its mouth .\n","Predicting for image: 656\n","3449114979_6cdc3e8da8.jpg : A man in a black shirt is skating on a red bench .\n","Predicting for image: 657\n","2543589122_ec3e55f434.jpg : A woman and a dog are sitting on a beach .\n","Predicting for image: 658\n","3530843182_35af2c821c.jpg : A girl is taking a picture with a beautiful child .\n","Predicting for image: 659\n","3472364264_dbde5a8d0a.jpg : A black dog is standing in the snow .\n","Predicting for image: 660\n","3715469645_6d1dc019b3.jpg : A man in a brown shirt sits with her arms out a field .\n","Predicting for image: 661\n"],"name":"stdout"},{"output_type":"stream","text":["2196107384_361d73a170.jpg : A group of men are standing around the wall at night .\n","Predicting for image: 662\n","1561658940_a947f2446a.jpg : A little boy is jumping into the air .\n","Predicting for image: 663\n","3655074079_7df3812bc5.jpg : A woman in a white dress is playing a violin .\n","Predicting for image: 664\n","3004823335_9b82cbd8a7.jpg : A brown dog and a ball in the grass .\n","Predicting for image: 665\n","2495931537_9b8d4474b6.jpg : A group of people stand in a room seat .\n","Predicting for image: 666\n","293881927_ac62900fd4.jpg : A young girl in a green shirt is walking through the grass .\n","Predicting for image: 667\n","3162045919_c2decbb69b.jpg : A small black and white dog is jumping in the water .\n","Predicting for image: 668\n","505929313_7668f021ab.jpg : A little boy playing in the water .\n","Predicting for image: 669\n","3244470342_c08f6bb17e.jpg : A brown dog holds a red ball .\n","Predicting for image: 670\n","3655964639_21e76383d0.jpg : A little girl in a green shirt is playing on a park .\n","Predicting for image: 671\n","3718964174_cb2dc1615e.jpg : A girl in a blue shirt sits in front of a crowd .\n","Predicting for image: 672\n","3388330419_85d72f7cda.jpg : A baby wearing a red hat sits on a red mat .\n","Predicting for image: 673\n","2128119486_4407061c40.jpg : A man in red and white and white hair is in front of the other of buildings .\n","Predicting for image: 674\n","917574521_74fab68514.jpg : Two women sit on the bed .\n","Predicting for image: 675\n","400851260_5911898657.jpg : A man stands on a snowy mountain .\n","Predicting for image: 676\n","270816949_ffad112278.jpg : A man stands in the mountains surrounded by rocks .\n","Predicting for image: 677\n","421730441_6b2267fd31.jpg : A girl with blond hair is on a red bike .\n","Predicting for image: 678\n","429851331_b248ca01cd.jpg : A brown dog is making a red ball .\n","Predicting for image: 679\n","241345905_5826a72da1.jpg : A football player is making a football game .\n","Predicting for image: 680\n","2102360862_264452db8e.jpg : Two men in their orange shirt sit on the edge of a mountain .\n","Predicting for image: 681\n","3051384385_c5c850c1f8.jpg : A man and a woman are standing in front of a boats wall .\n","Predicting for image: 682\n","3500136982_bf7a85531e.jpg : A group of people are walking down a street .\n","Predicting for image: 683\n","416788726_5b4eb1466e.jpg : A man and a dog are standing in front of a house .\n","Predicting for image: 684\n","245895500_a4eb97af02.jpg : There is a man playing in the water .\n","Predicting for image: 685\n","3259002340_707ce96858.jpg : A black and white dog plays with a black and white toy .\n","Predicting for image: 686\n","2796801478_8ebd7e550b.jpg : A little girl in a black and yellow shirt is standing on a street .\n","Predicting for image: 687\n","57422853_b5f6366081.jpg : A group of men are standing in the mountains .\n","Predicting for image: 688\n","1311388430_4ab0cd1a1f.jpg : A person is doing a trick in the air .\n","Predicting for image: 689\n","522063319_33827f1627.jpg : A man in a red shirt is standing in front of a tree .\n","Predicting for image: 690\n","384577800_fc325af410.jpg : A small brown and black dog playing in the snow .\n","Predicting for image: 691\n","3159995270_17334ccb5b.jpg : A young boy in a red shirt playing tennis .\n","Predicting for image: 692\n","2229179070_dc8ea8582e.jpg : A boy in a green shirt and helmet is running through a park .\n","Predicting for image: 693\n","1764955991_5e53a28c87.jpg : A man with a blue shirt is rock climbing in the woods .\n","Predicting for image: 694\n","670609997_5c7fdb3f0b.jpg : A brown dog wears a red mask in the grass .\n","Predicting for image: 695\n","86412576_c53392ef80.jpg : A skateboarder on a motocross bike is jumping off a track .\n","Predicting for image: 696\n","260828892_7925d27865.jpg : A woman in a black bathing suit stands on the beach .\n","Predicting for image: 697\n","3737539561_d1dc161040.jpg : A man is wearing a white and white and white and white and white and of a blue and in a white and a white and in a white and a white and a white and and a a\n","Predicting for image: 698\n","3262075846_5695021d84.jpg : A group of people are standing together .\n","Predicting for image: 699\n","3227148358_f152303584.jpg : A young man wearing a green shirt and hat .\n","Predicting for image: 700\n","2373234213_4ebe9c4ee5.jpg : A man in a blue shirt is climbing on a rope .\n","Predicting for image: 701\n","2914206497_5e36ac6324.jpg : A young boy in a blue shirt runs down the road .\n","Predicting for image: 702\n","488356951_b3b77ad832.jpg : A little girl in a striped shirt .\n","Predicting for image: 703\n","2105756457_a100d8434e.jpg : A group of people are sitting on a wooden bench .\n","Predicting for image: 704\n","3506560025_8d0f4f9ac4.jpg : A man in a red shirt is sitting on a red slide .\n","Predicting for image: 705\n","3456362961_d8f7e347a8.jpg : A young man in a red shirt is jumping off a rock .\n","Predicting for image: 706\n","3044500219_778f9f2b71.jpg : A man and a woman pose for a picture .\n","Predicting for image: 707\n","2301525531_edde12d673.jpg : A man walks through the snow with a dog .\n","Predicting for image: 708\n","3280052365_c4644bf0a5.jpg : A group of men are making their hands in a store .\n","Predicting for image: 709\n","3640422448_a0f42e4559.jpg : A person is taking pictures on a bicycle .\n","Predicting for image: 710\n","2396025708_e4a72e2558.jpg : A surfer catches a huge wave .\n","Predicting for image: 711\n","1433142189_cda8652603.jpg : A brown dog runs along the edge of a rock face with mountains in the background .\n","Predicting for image: 712\n","3214573346_d3a57f0328.jpg : A small child is jumping in the water .\n","Predicting for image: 713\n","3218480482_66af7587c8.jpg : A group of people are standing by a sign .\n","Predicting for image: 714\n","2021613437_d99731f986.jpg : A young boy in a red outfit holds a basketball .\n","Predicting for image: 715\n","2525270674_4ab536e7ec.jpg : A young girl is standing in a puddle in front of some water .\n","Predicting for image: 716\n","3470951932_27ed74eb0b.jpg : A soccer player hitting the ball .\n","Predicting for image: 717\n","2870875612_2cbb9e4a3c.jpg : A brown dog is running on a beach .\n","Predicting for image: 718\n","2541104331_a2d65cfa54.jpg : A brown dog is playing in the woods .\n","Predicting for image: 719\n","444057017_f1e0fcaef7.jpg : A young boy in a bright yellow shirt is sitting on a swing .\n","Predicting for image: 720\n","3597326009_3678a98a43.jpg : A group of people sitting on a bench .\n","Predicting for image: 721\n","3360930596_1e75164ce6.jpg : A man in a black shirt and white shorts .\n","Predicting for image: 722\n","247637795_fdf26a03cf.jpg : A man and a woman in hands .\n","Predicting for image: 723\n","3696698390_989f1488e7.jpg : A young boy is playing in a soccer game .\n","Predicting for image: 724\n","3421789737_f625dd17ed.jpg : A man in a blue shirt swims in a crowd .\n","Predicting for image: 725\n","53043785_c468d6f931.jpg : A girl climbing a huge wave .\n","Predicting for image: 726\n","3058439373_9276a4702a.jpg : A group of people are standing in front of a group of people .\n","Predicting for image: 727\n","2100816230_ff866fb352.jpg : A man is standing on a snowy mountain .\n","Predicting for image: 728\n","2729655904_1dd01922fb.jpg : There is a group of dogs play in the water .\n","Predicting for image: 729\n","3270691950_88583c3524.jpg : A dog plays in the water .\n","Predicting for image: 730\n","3729525173_7f984ed776.jpg : the brown dog jumping in the air .\n","Predicting for image: 731\n","540721368_12ac732c6c.jpg : A young boy wearing a crowd on his head .\n","Predicting for image: 732\n","3686924335_3c51e8834a.jpg : A dog is running through the water .\n","Predicting for image: 733\n","2295216243_0712928988.jpg : A group of men are standing on a red store .\n","Predicting for image: 734\n","3450874870_c4dcf58fb3.jpg : A bird is standing in midair .\n","Predicting for image: 735\n","3061481868_d1e00b1f2e.jpg : A boy on a skateboard does a trick .\n","Predicting for image: 736\n","308487515_7852928f90.jpg : A dog runs on the field .\n","Predicting for image: 737\n","263854883_0f320c1562.jpg : A brown dog and a black dog .\n","Predicting for image: 738\n","3549583146_3e8bb2f7e9.jpg : A person on a motorcycle is jumping into the air .\n","Predicting for image: 739\n","3542484764_77d8920ec9.jpg : A boy in a green shirt is playing on a green swing .\n","Predicting for image: 740\n","3208074567_ac44aeb3f3.jpg : A man is rock climbing .\n","Predicting for image: 741\n","3167365436_c379bda282.jpg : A girl with brown hair and white hair is in the hand .\n","Predicting for image: 742\n","2693425189_47740c22ed.jpg : A woman and a dog in a field .\n","Predicting for image: 743\n"],"name":"stdout"},{"output_type":"stream","text":["434792818_56375e203f.jpg : A child in a red and red helmet climbing across the grass .\n","Predicting for image: 744\n","3635577874_48ebaac734.jpg : A man in a red shirt is skating .\n","Predicting for image: 745\n","3413571342_b9855795e2.jpg : The child is in the water next to the water .\n","Predicting for image: 746\n","2475162978_2c51048dca.jpg : A baseball player player player on the grass .\n","Predicting for image: 747\n","2160266952_a2ab39191b.jpg : A black dog is jumping over a red house .\n","Predicting for image: 748\n","463978865_c87c6ca84c.jpg : A group of men on a motorcycle are about to jump .\n","Predicting for image: 749\n","3585487286_ef9a8d4c56.jpg : A dog running in the snow .\n","Predicting for image: 750\n","3239021459_a6b71bb400.jpg : A man is standing in the middle of the ocean whilst holding a trick .\n","Predicting for image: 751\n","2662845514_8620aaee96.jpg : There is a kid wearing a red shirt playing tennis .\n","Predicting for image: 752\n","3044746136_8b89da5f40.jpg : A group of people are standing in front of a brick building .\n","Predicting for image: 753\n","343218198_1ca90e0734.jpg : A brown dog running through a grassy area .\n","Predicting for image: 754\n","2924259848_effb4dcb82.jpg : A person is climbing up a dirt path .\n","Predicting for image: 755\n","3720366614_dfa8fe1088.jpg : A child is playing in the water .\n","Predicting for image: 756\n","1356796100_b265479721.jpg : A female dog makes after inside a ramp .\n","Predicting for image: 757\n","2905942129_2b4bf59bc0.jpg : A man wearing a black shirt and white shorts and blue shorts .\n","Predicting for image: 758\n","2660008870_b672a4c76a.jpg : A little girl in a bathing suit and a child in background .\n","Predicting for image: 759\n","2274992140_bb9e868bb8.jpg : A group of children in a house .\n","Predicting for image: 760\n","3538213870_9856a76b2a.jpg : A young boy in a red shirt and blue shirt and blue shirt is holding a ball .\n","Predicting for image: 761\n","2206960564_325ed0c7ae.jpg : A little woman is standing in a field .\n","Predicting for image: 762\n","2839038702_e168128665.jpg : A woman in a red shirt and tan boots is attached to a building .\n","Predicting for image: 763\n","424416723_19c56cb365.jpg : A brown dog is running through a field .\n","Predicting for image: 764\n","2876993733_cb26107d18.jpg : The football player is in the action next to a turn .\n","Predicting for image: 765\n","223299142_521aedf9e7.jpg : A girl in a sweater is laying on the beach .\n","Predicting for image: 766\n","3347798761_5c5260b000.jpg : A man on a rocky mountain .\n","Predicting for image: 767\n","1220401002_3f44b1f3f7.jpg : A little girl with long hair and a cast on her hand .\n","Predicting for image: 768\n","3564543247_05cdbc31cf.jpg : A girl in a swimming pool while another young girl and another boy is watching .\n","Predicting for image: 769\n","3385246141_a263d1053e.jpg : A female rider performs a trick .\n","Predicting for image: 770\n","3334537556_a2cf4e9b9a.jpg : A group of people sit on a trail overlooking a forest .\n","Predicting for image: 771\n","2909955251_4b326a46a7.jpg : A man in jeans and a red shirt is jumping into the air .\n","Predicting for image: 772\n","2247889670_413db8094b.jpg : A man on a 4-wheeler is racing in the sand .\n","Predicting for image: 773\n","3186073578_6e115f45f5.jpg : A child in a red hat and red hat lights a cigarette .\n","Predicting for image: 774\n","3192069971_83c5a90b4c.jpg : A person rides a bicycle .\n","Predicting for image: 775\n","3422458549_f3f3878dbf.jpg : A little girl with red hair and red shorts and a red bow .\n","Predicting for image: 776\n","2891617125_f939f604c7.jpg : A dirt biker is riding a dirt bike .\n","Predicting for image: 777\n","279728508_6bd7281f3c.jpg : A group of young men are standing in the desert .\n","Predicting for image: 778\n","2913965136_2d00136697.jpg : A dog and a dog play in the grass .\n","Predicting for image: 779\n","3692892751_f6574e2700.jpg : A man is training a little dog in the middle of a crowd .\n","Predicting for image: 780\n","2288099178_41091aa00c.jpg : Two men in hockey uniforms are trying to make a football game .\n","Predicting for image: 781\n","476233374_e1396998ef.jpg : Two brown dogs are playing with a ball .\n","Predicting for image: 782\n","2559921948_06af25d566.jpg : The boy in the white shirt is skating .\n","Predicting for image: 783\n","2189995738_352607a63b.jpg : A girl in a white shirt is sitting in a lake surrounded by the water .\n","Predicting for image: 784\n","3359530430_249f51972c.jpg : A man in a blue helmet is skiing .\n","Predicting for image: 785\n","317488612_70ac35493b.jpg : A brown dog is playing in the water with a ball in its mouth .\n","Predicting for image: 786\n","2842865689_e37256d9ce.jpg : A dog jumping over a high fence .\n","Predicting for image: 787\n","2225231022_1632d0a5aa.jpg : A man in a black and white cap is reading a book .\n","Predicting for image: 788\n","327415627_6313d32a64.jpg : A tan dog is walking through the cold grass .\n","Predicting for image: 789\n","2292406847_f366350600.jpg : A woman is standing on the water .\n","Predicting for image: 790\n","3571147934_d1c8af1d6e.jpg : A crowd of people are lounging on a ice .\n","Predicting for image: 791\n","2607462776_78e639d891.jpg : The little dog is running through the grass .\n","Predicting for image: 792\n","801607443_f15956d1ce.jpg : A man in a life shirt is laying on the edge of a cliff to hit the water .\n","Predicting for image: 793\n","2176980976_7054c99621.jpg : A man and a woman in red , standing on the beach .\n","Predicting for image: 794\n","3523559027_a65619a34b.jpg : A man kicks a dirt bike .\n","Predicting for image: 795\n","1329832826_432538d331.jpg : Children are playing in a swimming pool .\n","Predicting for image: 796\n","260520547_944f9f4c91.jpg : A man is skating down a set of stairs .\n","Predicting for image: 797\n","2473738924_eca928d12f.jpg : A young boy is jumping in the air as a woman in a black shirt .\n","Predicting for image: 798\n","1765164972_92dac06fa9.jpg : A little boy in a yellow shirt crawls down a slide .\n","Predicting for image: 799\n","2806710650_e201acd913.jpg : A little girl in glasses is about to hit the camera .\n","Predicting for image: 800\n","2501595799_6316001e89.jpg : A red dog leaps into a pool .\n","Predicting for image: 801\n","3697359692_8a5cdbe4fe.jpg : A woman wearing a black jacket and white cast on her hand .\n","Predicting for image: 802\n","3688858505_e8afd1475d.jpg : A man and a woman sit on a boats bench .\n","Predicting for image: 803\n","3396157719_6807d52a81.jpg : A man on a bicycle is riding a bicycle .\n","Predicting for image: 804\n","473220329_819a913bbb.jpg : A man in a field in the field .\n","Predicting for image: 805\n","3228069008_edb2961fc4.jpg : A brown dog is playing with a stick .\n","Predicting for image: 806\n","2861932486_52befd8592.jpg : Brown dog and a brown dog are playing with a green toy .\n","Predicting for image: 807\n","758921886_55a351dd67.jpg : Two women and a man pose for a picture .\n","Predicting for image: 808\n","791338571_7f38510bf7.jpg : A little girl in a red dress walks along a grassy path .\n","Predicting for image: 809\n","3435035138_af32890a4c.jpg : A dog with a yellow toy in his mouth .\n","Predicting for image: 810\n","1339596997_8ac29c1841.jpg : A girl in a red jacket is sitting on the street .\n","Predicting for image: 811\n","3245460937_2710a82709.jpg : A man in a black shirt and white shorts and white shorts .\n","Predicting for image: 812\n","3256275785_9c3af57576.jpg : A little girl in a blue shirt sits on a lake .\n","Predicting for image: 813\n","2856080862_95d793fa9d.jpg : A young man is playing soccer .\n","Predicting for image: 814\n","3179336562_c3d0c0a3bd.jpg : A young man in a green jacket is riding a bike .\n","Predicting for image: 815\n","430173345_86388d8822.jpg : A small brown dog following a larger black dog .\n","Predicting for image: 816\n","1096395242_fc69f0ae5a.jpg : A little boy and a girl sitting on a wooden bench\n","Predicting for image: 817\n","2378149488_648e5deeac.jpg : A person wearing a black shirt sitting on a bench .\n","Predicting for image: 818\n","2358561039_e215a8d6cd.jpg : A woman in a red jacket is looking to the right .\n","Predicting for image: 819\n","2667015110_1670324a33.jpg : A little boy in a blue outfit and blue shorts\n","Predicting for image: 820\n","500446858_125702b296.jpg : A brown dog with a red toy in its mouth .\n","Predicting for image: 821\n","226607225_44d696db6b.jpg : A tan dog is jumping into the ocean .\n","Predicting for image: 822\n","2496370758_a3fbc49837.jpg : A white and white dog with a red ball in its mouth .\n","Predicting for image: 823\n","3259991972_fce3ab18b2.jpg : A man in a red shirt is trying to cross the street .\n","Predicting for image: 824\n"],"name":"stdout"},{"output_type":"stream","text":["229862312_1a0ba19dab.jpg : A brown dog catching a ball in the grass .\n","Predicting for image: 825\n","3333921867_6cc7d7c73d.jpg : A large group of black dogs running in the grass .\n","Predicting for image: 826\n","2248487950_c62d0c81a9.jpg : A group of people in front of a red building .\n","Predicting for image: 827\n","3074842262_62b1b2168c.jpg : Two brown dogs are playing with a man .\n","Predicting for image: 828\n","561417861_8e25d0c0e8.jpg : A man in a red shirt and a striped shirt is standing on a ledge .\n","Predicting for image: 829\n","2646046871_c3a5dbb971.jpg : A brown dog is playing with a ball in his mouth .\n","Predicting for image: 830\n","2944952557_8484f0da8f.jpg : A boy in a red shirt and white shorts is about to kick the ball .\n","Predicting for image: 831\n","3244747165_17028936e0.jpg : Two women and a woman are posing for a picture .\n","Predicting for image: 832\n","2285570521_05015cbf4b.jpg : A man in a red shirt is jumping in the snow .\n","Predicting for image: 833\n","315880837_90db309bab.jpg : A brown and white dog in a red and red cap is running on a snowy path .\n","Predicting for image: 834\n","3375070563_3c290a7991.jpg : A girl in a blue bathing suit and a red shirt is jumping over a snow covered mountain .\n","Predicting for image: 835\n","1298295313_db1f4c6522.jpg : The man in the blue jacket is looking at the blue water .\n","Predicting for image: 836\n","3585598356_8ce815bbb9.jpg : A little girl in a pink shirt is sitting on a fence .\n","Predicting for image: 837\n","2473689180_e9d8fd656a.jpg : A group of people sit on the beach .\n","Predicting for image: 838\n","3258874419_23fec1bdc1.jpg : A greyhound wearing a number jacket and a yellow jacket is sitting on the grass .\n","Predicting for image: 839\n","1237985362_dbafc59280.jpg : A boy in a black jacket is taking a black one with a pink shirt .\n","Predicting for image: 840\n","3290105461_7590f23371.jpg : A young boy walks with his bike in the woods .\n","Predicting for image: 841\n","2644430445_47c985a2ee.jpg : A crowd of people in front of a crowd .\n","Predicting for image: 842\n","732468337_a37075225e.jpg : A dog sits on a bed .\n","Predicting for image: 843\n","113678030_87a6a6e42e.jpg : A man is climbing up a climbing hill .\n","Predicting for image: 844\n","2120411340_104eb610b1.jpg : A group of dogs are running through a line .\n","Predicting for image: 845\n","2450453051_f1d4a78ab4.jpg : A white dog is running over a hurdle .\n","Predicting for image: 846\n","2831217847_555b2f95ca.jpg : Two dogs are playing with a ball .\n","Predicting for image: 847\n","3192266178_f9bf5d3dba.jpg : A group of soccer players and a man in front of trees .\n","Predicting for image: 848\n","326456451_effadbbe49.jpg : A child jumps on a red slide .\n","Predicting for image: 849\n","2663794355_e726ec7e05.jpg : A shirtless man is out of the view of a rock wall .\n","Predicting for image: 850\n","3364151356_eecd07a23e.jpg : A puppy plays with a toy .\n","Predicting for image: 851\n","2251747182_6b67a3ab8b.jpg : A young boy sits on a red slide .\n","Predicting for image: 852\n","3139160252_75109e9e05.jpg : A group of people are shown in the air .\n","Predicting for image: 853\n","219070971_ae43410b9e.jpg : A woman in a black and black striped shirt is standing on the beach .\n","Predicting for image: 854\n","1674612291_7154c5ab61.jpg : A man in a yellow shirt walks down a path .\n","Predicting for image: 855\n","136886677_6026c622eb.jpg : A mountain biker is climbing up a rock face on a rope .\n","Predicting for image: 856\n","3398746625_5199beea71.jpg : A man jumps into the air at the beach .\n","Predicting for image: 857\n","3220650628_4ed964e5b4.jpg : Two men stand near a structure set at night .\n","Predicting for image: 858\n","1082379191_ec1e53f996.jpg : A child in a swing .\n","Predicting for image: 859\n","3741462565_cc35966b7a.jpg : A child makes a funny face .\n","Predicting for image: 860\n","1174525839_7c1e6cfa86.jpg : A child flies through the ocean .\n","Predicting for image: 861\n","3572267708_9d8a81d4a4.jpg : Two women hold onstage .\n","Predicting for image: 862\n","1509786421_f03158adfc.jpg : A woman with a black and white shirt is on a bed .\n","Predicting for image: 863\n","3155987659_b9ea318dd3.jpg : A brown dog and a brown dog on the grass .\n","Predicting for image: 864\n","925491651_57df3a5b36.jpg : A black and white dog is walking through the sand .\n","Predicting for image: 865\n","2735558076_0d7bbc18fc.jpg : A man wearing a black shirt and a blue shirt is doing a trick .\n","Predicting for image: 866\n","300922408_05a4f9938c.jpg : A little girl in a bathing suit is jumping into a pool .\n","Predicting for image: 867\n","1490670858_e122df2560.jpg : a baseball player wearing a blue shirt is looking at the camera .\n","Predicting for image: 868\n","2953015871_cae796b6e7.jpg : A black dog with a brown toy in his mouth .\n","Predicting for image: 869\n","524282699_71e678a6bd.jpg : A dog is running through the air .\n","Predicting for image: 870\n","2890113532_ab2003d74e.jpg : A dog running through a field .\n","Predicting for image: 871\n","1456393634_74022d9056.jpg : two men are playing in the distance .\n","Predicting for image: 872\n","2813033949_e19fa08805.jpg : A baseball player kicks a baseball ball in the air .\n","Predicting for image: 873\n","745880539_cd3f948837.jpg : A brown dog carries a corner .\n","Predicting for image: 874\n","2480327661_fb69829f57.jpg : A young boy with a basketball basketball basketball .\n","Predicting for image: 875\n","3125309108_1011486589.jpg : A teenage girl is standing in front of a woman in a white shirt .\n","Predicting for image: 876\n","3287549827_04dec6fb6e.jpg : A person in a orange shirt is sitting on a rail .\n","Predicting for image: 877\n","391579205_c8373b5411.jpg : A man wearing a red hat and a red hat is smiling .\n","Predicting for image: 878\n","2610447973_89227ff978.jpg : A group of four friends pose in front of a line of water .\n","Predicting for image: 879\n","2698666984_13e17236ae.jpg : A person in a blue helmet is rock climbing .\n","Predicting for image: 880\n","339350939_6643bfb270.jpg : A dog runs down the beach .\n","Predicting for image: 881\n","127490019_7c5c08cb11.jpg : A man in a green shirt is sitting on a rock .\n","Predicting for image: 882\n","1714316707_8bbaa2a2ba.jpg : a man in a red backpack sits on a grassy mountain .\n","Predicting for image: 883\n","3556598205_86c180769d.jpg : A little girl is taking a dive on a beach .\n","Predicting for image: 884\n","757046028_ff5999f91b.jpg : A man in a red shirt is making a sign .\n","Predicting for image: 885\n","132489044_3be606baf7.jpg : A man and a woman in a room surrounded by candles .\n","Predicting for image: 886\n","3613800013_5a54968ab0.jpg : A white dog running on the grass .\n","Predicting for image: 887\n","2577972703_a22c5f2a87.jpg : A little girl is playing on a garden .\n","Predicting for image: 888\n","2073964624_52da3a0fc4.jpg : A little blond girl wearing a red hat wears a flower flower .\n","Predicting for image: 889\n","2194494220_bb2178832c.jpg : A man in a green shirt is standing on the beach .\n","Predicting for image: 890\n","2215136723_960edfea49.jpg : The boy in the red shirt is sitting on the ice .\n","Predicting for image: 891\n","2759860913_f75b39d783.jpg : A man in a yellow shirt is sitting on a mountain .\n","Predicting for image: 892\n","3225310099_d8e419ba56.jpg : A young girl in a black bathing suit is poised in the air .\n","Predicting for image: 893\n","2938120171_970564e3d8.jpg : A brown dog jumps into the air to catch a ball .\n","Predicting for image: 894\n","754852108_72f80d421f.jpg : A little boy in a red shirt is playing with a green rail .\n","Predicting for image: 895\n","3187395715_f2940c2b72.jpg : A man in a pink shirt jumps off a skateboard at a park .\n","Predicting for image: 896\n","3281078518_630a7a7f4f.jpg : A brown dog is playing with a red ball .\n","Predicting for image: 897\n","3071676551_a65741e372.jpg : A man on a surfboard through the sea .\n","Predicting for image: 898\n","3106026005_473a7b1c8c.jpg : A group of people in front of an ice house .\n","Predicting for image: 899\n","3523874798_9ba2fa46e3.jpg : A man with a skateboard jumping out of someone .\n","Predicting for image: 900\n","245252561_4f20f1c89e.jpg : A brown dog is running on a snowy path .\n","Predicting for image: 901\n","3685328542_ab999b83bb.jpg : A group of people stand on a street .\n","Predicting for image: 902\n","3613424631_3ae537624f.jpg : A group of people are going down a path .\n","Predicting for image: 903\n","3584930205_a3f58a4b7c.jpg : A child in a green and yellow shirt is looking up .\n","Predicting for image: 904\n","127488876_f2d2a89588.jpg : A brown dog is jumping into a pool .\n","Predicting for image: 905\n","3578841731_f775cab089.jpg : A brown dog is jumping through the grass .\n","Predicting for image: 906\n"],"name":"stdout"},{"output_type":"stream","text":["2934359101_cdf57442dc.jpg : A young boy wearing a black hat and white hat and black hat .\n","Predicting for image: 907\n","339658315_fbb178c252.jpg : A man in a brown shirt and white shirt is playing a game .\n","Predicting for image: 908\n","2991994415_504d1c0a03.jpg : A child in a red shirt is pointing at the bed .\n","Predicting for image: 909\n","3349451628_4249a21c8f.jpg : A black and white dog with a black toy in the air .\n","Predicting for image: 910\n","3197917064_e679a44b8e.jpg : A black dog plays in the woods .\n","Predicting for image: 911\n","2657484284_daa07a3a1b.jpg : A man in a red shirt and khaki shorts is hiking across a grassy field .\n","Predicting for image: 912\n","2894217628_f1a4153dca.jpg : A group of men are in white uniforms .\n","Predicting for image: 913\n","3424424006_98f9d1921c.jpg : The boy in the white t-shirt is airborne whilst being whilst wearing a helmet .\n","Predicting for image: 914\n","2526585002_10987a63f3.jpg : A boat in a lake .\n","Predicting for image: 915\n","1836335410_de8313a64e.jpg : A group of people in dark dresses .\n","Predicting for image: 916\n","2443380641_7b38d18f5b.jpg : A boy in a blue shirt rides a yellow toy .\n","Predicting for image: 917\n","2208067635_39a03834ca.jpg : A woman is rock climbing .\n","Predicting for image: 918\n","3427233064_6af01bfc5c.jpg : A man and a woman are standing on a bench .\n","Predicting for image: 919\n","799486353_f665d7b0f0.jpg : A long haired girl helping a wooden fence .\n","Predicting for image: 920\n","3741827382_71e93298d0.jpg : A man in a blue shirt is jumping from a sand slide .\n","Predicting for image: 921\n","3578914491_36019ba703.jpg : A light brown dog carries a red ball in its mouth .\n","Predicting for image: 922\n","3197981073_3156963446.jpg : A woman dances and holding a video video statue .\n","Predicting for image: 923\n","416960865_048fd3f294.jpg : A boy in a red shirt is on the sand .\n","Predicting for image: 924\n","197504190_fd1fc3d4b7.jpg : A dog and a creek .\n","Predicting for image: 925\n","2484190118_e89363c465.jpg : A boy in a helmet is playing with a skateboard .\n","Predicting for image: 926\n","2602258549_7401a3cdae.jpg : Two women pose for a picture .\n","Predicting for image: 927\n","493621130_152bdd4e91.jpg : Two playing in the snow .\n","Predicting for image: 928\n","3332467180_d72f9b067d.jpg : A man and a woman walk down the street .\n","Predicting for image: 929\n","2981702521_2459f2c1c4.jpg : A young man in a hat .\n","Predicting for image: 930\n","461505235_590102a5bf.jpg : A man in a red shirt and striped shirt is looking to the camera .\n","Predicting for image: 931\n","1490213660_9ea45550cf.jpg : A dog leaps through the air .\n","Predicting for image: 932\n","300577375_26cc2773a1.jpg : A man in a green jacket and white shorts is wearing a helmet .\n","Predicting for image: 933\n","2549968784_39bfbe44f9.jpg : Boy sliding down playground slide .\n","Predicting for image: 934\n","2075321027_c8fcbaf581.jpg : A girl in a red jacket is walking near a wall .\n","Predicting for image: 935\n","1547883892_e29b3db42e.jpg : A man sitting on a bench in front of a window , holding buildings .\n","Predicting for image: 936\n","2886411666_72d8b12ce4.jpg : A little girl in a green shirt is walking through a field .\n","Predicting for image: 937\n","2239938351_43c73c887c.jpg : a brown and brown dog with a blue collar is playing with a brown dog .\n","Predicting for image: 938\n","2918769188_565dd48060.jpg : A little boy is playing in the sand .\n","Predicting for image: 939\n","3610683688_bbe6d725ed.jpg : A brown dog is coming into the water .\n","Predicting for image: 940\n","3025549604_38b86198f5.jpg : a crowd of playing in a stadium .\n","Predicting for image: 941\n","2073105823_6dacade004.jpg : A man and a dog going down a grass ledge .\n","Predicting for image: 942\n","2447284966_d6bbdb4b6e.jpg : a boy jumps in the air .\n","Predicting for image: 943\n","2600867924_cd502fc911.jpg : A black and white dog is playing with a soccer ball in his mouth .\n","Predicting for image: 944\n","2333288869_8c01e4c859.jpg : A person stands on top of a mountain overlooking a mountain .\n","Predicting for image: 945\n","3589367895_5d3729e3ea.jpg : A group of people on a colorful bike are standing on a brick wall .\n","Predicting for image: 946\n","96420612_feb18fc6c6.jpg : A man in a red shirt is jumping into the air .\n","Predicting for image: 947\n","3375991133_87d7c40925.jpg : People sit at night .\n","Predicting for image: 948\n","3320032226_63390d74a6.jpg : a man in a red and red uniform is making a crowd .\n","Predicting for image: 949\n","2971431335_e192613db4.jpg : A man jumping off of a lake .\n","Predicting for image: 950\n","219301555_17883a51bd.jpg : A brown dog jumps into the air .\n","Predicting for image: 951\n","3222041930_f642f49d28.jpg : A girl with a camera points to the camera .\n","Predicting for image: 952\n","3187492926_8aa85f80c6.jpg : A brown dog leaps into a swimming pool .\n","Predicting for image: 953\n","3673165148_67f217064f.jpg : A man stands on the beach .\n","Predicting for image: 954\n","270724499_107481c88f.jpg : A yellow dog with a red collar runs through a field .\n","Predicting for image: 955\n","2182488373_df73c7cc09.jpg : A group of women are standing in the snow .\n","Predicting for image: 956\n","2421446839_fe7d46c177.jpg : A small boy sits in a fence .\n","Predicting for image: 957\n","2603792708_18a97bac97.jpg : A little girl in a flowery shirt is running on the shoreline .\n","Predicting for image: 958\n","2822290399_97c809d43b.jpg : a brown dog running through the grass .\n","Predicting for image: 959\n","1332722096_1e3de8ae70.jpg : A black and white dog is jumping off of a white field .\n","Predicting for image: 960\n","3694064560_467683205b.jpg : A group of people are sitting in front of a wooden building .\n","Predicting for image: 961\n","3263395801_5e4cee2b9e.jpg : A woman rides on a bike .\n","Predicting for image: 962\n","3701291852_373ea46bb6.jpg : A group of people are sitting at the sunset at night .\n","Predicting for image: 963\n","2343525685_3eba3b6686.jpg : A boy in a red outfit is inside a rock .\n","Predicting for image: 964\n","416106657_cab2a107a5.jpg : A group of dogs playing in the water .\n","Predicting for image: 965\n","387830531_e89c192b92.jpg : Two dogs are playing with a yellow toy .\n","Predicting for image: 966\n","2892995070_39f3c9a56e.jpg : A young boy is playing on the beach .\n","Predicting for image: 967\n","3432550415_e7b77232de.jpg : A bike rider in the air .\n","Predicting for image: 968\n","3564312955_716e86c48b.jpg : A man in a red shirt is holding a camera .\n","Predicting for image: 969\n","3238951136_2a99f1a1a8.jpg : A young girl in a pink bathing suit is walking .\n","Predicting for image: 970\n","3595643050_d312e4b652.jpg : The boy is in the air next to a pole .\n","Predicting for image: 971\n","3139876823_859c7d7c23.jpg : A man stands in the snow .\n","Predicting for image: 972\n","3473264983_67917a931f.jpg : A group of men and a man and a soccer park .\n","Predicting for image: 973\n","2994179598_a45c2732b5.jpg : A woman with a guitar .\n","Predicting for image: 974\n","491405109_798222cfd0.jpg : A group of people are hugging .\n","Predicting for image: 975\n","3115174046_9e96b9ce47.jpg : The man is wearing a black hat and scarf .\n","Predicting for image: 976\n","3631986552_944ea208fc.jpg : A man surfing a wave .\n","Predicting for image: 977\n","3350786891_6d39b234e9.jpg : A group of men in front of a building .\n","Predicting for image: 978\n","3062173277_bfb5ef4c45.jpg : A group of people are standing in front of a building .\n","Predicting for image: 979\n","3108197858_441ff38565.jpg : A woman in a purple shirt is sitting on a park .\n","Predicting for image: 980\n","1224851143_33bcdd299c.jpg : A group of people are walking through a glass structure .\n","Predicting for image: 981\n","3458559770_12cf9f134e.jpg : A person in a red helmet is jumping off a mountain .\n","Predicting for image: 982\n","3425835357_204e620a66.jpg : A man wearing a hat and black shirt and black shirt and black shirt .\n","Predicting for image: 983\n","3214885227_2be09e7cfb.jpg : A person is taking pictures on a high rail .\n","Predicting for image: 984\n","2854207034_1f00555703.jpg : A boy and a dog are running down a green field .\n","Predicting for image: 985\n","2167644298_100ca79f54.jpg : Children in red shirts hold hands .\n","Predicting for image: 986\n","241346971_c100650320.jpg : An American footballer wearing red is running .\n","Predicting for image: 987\n","1386964743_9e80d96b05.jpg : A dog runs through the grass .\n","Predicting for image: 988\n","3397220683_4aca010f86.jpg : A boy in the air on his side .\n","Predicting for image: 989\n","2473791980_805c819bd4.jpg : A man wearing an orange shirt helmet and helmet is riding a rope .\n","Predicting for image: 990\n"],"name":"stdout"},{"output_type":"stream","text":["241345844_69e1c22464.jpg : A football player making a jersey .\n","Predicting for image: 991\n","3256043809_47258e0b3e.jpg : A black dog on the side of a red dog .\n","Predicting for image: 992\n","2351479551_e8820a1ff3.jpg : A man and a black and black dog in a tree .\n","Predicting for image: 993\n","3514179514_cbc3371b92.jpg : A brown dog and a brown dog play in a backyard .\n","Predicting for image: 994\n","1119015538_e8e796281e.jpg : A brown dog and a brown dog .\n","Predicting for image: 995\n","3727752439_907795603b.jpg : A young girl in a slide wearing her mouth .\n","Predicting for image: 996\n","3430607596_7e4f74e3ff.jpg : A child in a blue shirt is walking through a puddle of water .\n","Predicting for image: 997\n","3259666643_ae49524c81.jpg : A man in a red shirt is ready to make a sign .\n","Predicting for image: 998\n","2623930900_b9df917b82.jpg : A group of kids are all hugging .\n","Predicting for image: 999\n","3490736665_38710f4b91.jpg : A young boy jumps in the air with a football .\n","0.484078179369\n"],"name":"stdout"}]},{"metadata":{"id":"KyzQ-hYPn8l_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}