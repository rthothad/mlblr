{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caption Generation\n",
    "Caption generation is a challenging aritifical intelligence problem. Given a picture a textual description of the picture needs to be generated. For instance, for [this](https://github.com/rthothad/mlblr/blob/master/CaptionGenerator/DenseNet-Py2/2513260012_03d33305cf.jpg) picture a description such as \"A black dog is running after a white dog in the snow\" should be generated. \n",
    "\n",
    "This needs two models to be combined to generate the required output. A computer vision model to understand the content of the image and a language model (NLP) to convert the understood content to words and those words should be in the right order. The advantage of applying deep learning to this problem is that a single end to end model can be defined to predict a caption without having to build sophisticated data preparation pipelines.\n",
    "\n",
    "For the **computer vision model** a DenseNet model trained on the Imagenet dataset is used. For the **language model** a Recurrent Neural Networks more specifically Long Short Term Memory Network(LSTM) is used.\n",
    "\n",
    "The computer vision and language models are structured in a **encoder-decoder architecture**. This is an architecture developed for machine translation where an input sequence, say in French, is encoded as a fixed-length vector by an encoder network. A separate decoder network then reads the encoding and generates an output sequence in the new language, say English. A benefit of this approach in addition to the impressive skill of the approach is that a single end-to-end model can be trained on the problem. When adapted for image captioning, the encoder network is a deep convolutional neural network, and the decoder network is a stack of LSTM layers.\n",
    "\n",
    "The two dominant methods prior to end-to-end neural network models for generating image captions were template-based methods and nearest-neighbor-based methods and modifying existing captions.\n",
    "\n",
    "\n",
    "The Flickr8K Dataset was used to train and test the model. The Flickr8K dataset is comprised of more than 8,000 photos and up to 5 captions for each photo. The dataset is available for free. One must complete a request [form](https://illinois.edu/fb/sec/1713398) and the links to the dataset will be emailed.\n",
    "\n",
    "A Bleu Score of 0.500769703674 is achieved.\n",
    "\n",
    "This network was trained on Python 2.7, Keras - 2.1.5 and Tensorflow - 1.7.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer Vision Model\n",
    "A DenseNet model is used to extract the features from the picture. The last classification layer is removed from the DenseNet model. Give an image input, this model will give us a fixed length encoding. \n",
    "The extracted features are an internal representation of the image, not something directly intelligible. A deep convolutional neural network, or CNN, is used as the feature extraction submodel. This network can be trained directly on the images in the image captioning dataset. Alternately, a pre-trained model, such as a state-of-the-art model used for image classification, can be used. It is popular to use top performing models in the **ImageNet** dataset developed for the ILSVRC challenge, such as the Densely Connected Convolutional Network model, called DenseNet.\n",
    "\n",
    "This is the encoder layer in the endcoder-decoder architecture.\n",
    "\n",
    "#### Imagenet\n",
    "ImageNet is a research project to develop a large database of images with annotations, e.g. images and their descriptions. The images and their annotations have been the basis for an image classification challenge called the ImageNet Large Scale Visual Recognition Challenge or ILSVRC since 2010. The result is that research organizations battle it out on pre-defined datasets to see who has the best model for classifying the objects in images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below defines the DenseNet architecture in Keras. Keras also has an implementation of DenseNet but when I tried to classify an elephant picture it misclassified, so I used an implementation from [here]([]https://github.com/titu1994/DenseNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "\n",
    "import warnings\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers.pooling import AveragePooling2D, MaxPooling2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.utils.layer_utils import convert_all_kernels_in_model, convert_dense_weights_data_format\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "import keras.backend as K\n",
    "\n",
    "# from subpixel import SubPixelUpscaling\n",
    "\n",
    "DENSENET_121_WEIGHTS_PATH = r'https://github.com/titu1994/DenseNet/releases/download/v3.0/DenseNet-BC-121-32.h5'\n",
    "DENSENET_161_WEIGHTS_PATH = r'https://github.com/titu1994/DenseNet/releases/download/v3.0/DenseNet-BC-161-48.h5'\n",
    "DENSENET_169_WEIGHTS_PATH = r'https://github.com/titu1994/DenseNet/releases/download/v3.0/DenseNet-BC-169-32.h5'\n",
    "DENSENET_121_WEIGHTS_PATH_NO_TOP = r'https://github.com/titu1994/DenseNet/releases/download/v3.0/DenseNet-BC-121-32-no-top.h5'\n",
    "DENSENET_161_WEIGHTS_PATH_NO_TOP = r'https://github.com/titu1994/DenseNet/releases/download/v3.0/DenseNet-BC-161-48-no-top.h5'\n",
    "DENSENET_169_WEIGHTS_PATH_NO_TOP = r'https://github.com/titu1994/DenseNet/releases/download/v3.0/DenseNet-BC-169-32-no-top.h5'\n",
    "\n",
    "def preprocess_input(x, data_format=None):\n",
    "    \"\"\"Preprocesses a tensor encoding a batch of images.\n",
    "    # Arguments\n",
    "        x: input Numpy tensor, 4D.\n",
    "        data_format: data format of the image tensor.\n",
    "    # Returns\n",
    "        Preprocessed tensor.\n",
    "    \"\"\"\n",
    "    if data_format is None:\n",
    "        data_format = K.image_data_format()\n",
    "    assert data_format in {'channels_last', 'channels_first'}\n",
    "\n",
    "    if data_format == 'channels_first':\n",
    "        if x.ndim == 3:\n",
    "            # 'RGB'->'BGR'\n",
    "            x = x[::-1, ...]\n",
    "            # Zero-center by mean pixel\n",
    "            x[0, :, :] -= 103.939\n",
    "            x[1, :, :] -= 116.779\n",
    "            x[2, :, :] -= 123.68\n",
    "        else:\n",
    "            x = x[:, ::-1, ...]\n",
    "            x[:, 0, :, :] -= 103.939\n",
    "            x[:, 1, :, :] -= 116.779\n",
    "            x[:, 2, :, :] -= 123.68\n",
    "    else:\n",
    "        # 'RGB'->'BGR'\n",
    "        x = x[..., ::-1]\n",
    "        # Zero-center by mean pixel\n",
    "        x[..., 0] -= 103.939\n",
    "        x[..., 1] -= 116.779\n",
    "        x[..., 2] -= 123.68\n",
    "\n",
    "    x *= 0.017 # scale values\n",
    "\n",
    "    return x\n",
    "\n",
    "def __create_dense_net(nb_classes, img_input, include_top, depth=40, nb_dense_block=3, growth_rate=12, nb_filter=-1,\n",
    "                       nb_layers_per_block=-1, bottleneck=False, reduction=0.0, dropout_rate=None, weight_decay=1e-4,\n",
    "                       subsample_initial_block=False, activation='softmax'):\n",
    "    ''' Build the DenseNet model\n",
    "    Args:\n",
    "        nb_classes: number of classes\n",
    "        img_input: tuple of shape (channels, rows, columns) or (rows, columns, channels)\n",
    "        include_top: flag to include the final Dense layer\n",
    "        depth: number or layers\n",
    "        nb_dense_block: number of dense blocks to add to end (generally = 3)\n",
    "        growth_rate: number of filters to add per dense block\n",
    "        nb_filter: initial number of filters. Default -1 indicates initial number of filters is 2 * growth_rate\n",
    "        nb_layers_per_block: number of layers in each dense block.\n",
    "                Can be a -1, positive integer or a list.\n",
    "                If -1, calculates nb_layer_per_block from the depth of the network.\n",
    "                If positive integer, a set number of layers per dense block.\n",
    "                If list, nb_layer is used as provided. Note that list size must\n",
    "                be (nb_dense_block + 1)\n",
    "        bottleneck: add bottleneck blocks\n",
    "        reduction: reduction factor of transition blocks. Note : reduction value is inverted to compute compression\n",
    "        dropout_rate: dropout rate\n",
    "        weight_decay: weight decay rate\n",
    "        subsample_initial_block: Set to True to subsample the initial convolution and\n",
    "                add a MaxPool2D before the dense blocks are added.\n",
    "        subsample_initial:\n",
    "        activation: Type of activation at the top layer. Can be one of 'softmax' or 'sigmoid'.\n",
    "                Note that if sigmoid is used, classes must be 1.\n",
    "    Returns: keras tensor with nb_layers of conv_block appended\n",
    "    '''\n",
    "\n",
    "    concat_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    if reduction != 0.0:\n",
    "        assert reduction <= 1.0 and reduction > 0.0, 'reduction value must lie between 0.0 and 1.0'\n",
    "\n",
    "    # layers in each dense block\n",
    "    if type(nb_layers_per_block) is list or type(nb_layers_per_block) is tuple:\n",
    "        nb_layers = list(nb_layers_per_block)  # Convert tuple to list\n",
    "\n",
    "        assert len(nb_layers) == (nb_dense_block), 'If list, nb_layer is used as provided. ' \\\n",
    "                                                   'Note that list size must be (nb_dense_block)'\n",
    "        final_nb_layer = nb_layers[-1]\n",
    "        nb_layers = nb_layers[:-1]\n",
    "    else:\n",
    "        if nb_layers_per_block == -1:\n",
    "            assert (depth - 4) % 3 == 0, 'Depth must be 3 N + 4 if nb_layers_per_block == -1'\n",
    "            count = int((depth - 4) / 3)\n",
    "\n",
    "            if bottleneck:\n",
    "                count = count // 2\n",
    "\n",
    "            nb_layers = [count for _ in range(nb_dense_block)]\n",
    "            final_nb_layer = count\n",
    "        else:\n",
    "            final_nb_layer = nb_layers_per_block\n",
    "            nb_layers = [nb_layers_per_block] * nb_dense_block\n",
    "\n",
    "    # compute initial nb_filter if -1, else accept users initial nb_filter\n",
    "    if nb_filter <= 0:\n",
    "        nb_filter = 2 * growth_rate\n",
    "\n",
    "    # compute compression factor\n",
    "    compression = 1.0 - reduction\n",
    "\n",
    "    # Initial convolution\n",
    "    if subsample_initial_block:\n",
    "        initial_kernel = (7, 7)\n",
    "        initial_strides = (2, 2)\n",
    "    else:\n",
    "        initial_kernel = (3, 3)\n",
    "        initial_strides = (1, 1)\n",
    "\n",
    "    x = Conv2D(nb_filter, initial_kernel, kernel_initializer='he_normal', padding='same',\n",
    "               strides=initial_strides, use_bias=False, kernel_regularizer=l2(weight_decay))(img_input)\n",
    "\n",
    "    if subsample_initial_block:\n",
    "        x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    # Add dense blocks\n",
    "    for block_idx in range(nb_dense_block - 1):\n",
    "        x, nb_filter = __dense_block(x, nb_layers[block_idx], nb_filter, growth_rate, bottleneck=bottleneck,\n",
    "                                     dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
    "        # add transition_block\n",
    "        x = __transition_block(x, nb_filter, compression=compression, weight_decay=weight_decay)\n",
    "        nb_filter = int(nb_filter * compression)\n",
    "\n",
    "    # The last dense_block does not have a transition_block\n",
    "    x, nb_filter = __dense_block(x, final_nb_layer, nb_filter, growth_rate, bottleneck=bottleneck,\n",
    "                                 dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
    "\n",
    "    x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    if include_top:\n",
    "        x = Dense(nb_classes, activation=activation)(x)\n",
    "\n",
    "    return x\n",
    "  \n",
    "\n",
    "def __transition_block(ip, nb_filter, compression=1.0, weight_decay=1e-4):\n",
    "    ''' Apply BatchNorm, Relu 1x1, Conv2D, optional compression, dropout and Maxpooling2D\n",
    "    Args:\n",
    "        ip: keras tensor\n",
    "        nb_filter: number of filters\n",
    "        compression: calculated as 1 - reduction. Reduces the number of feature maps\n",
    "                    in the transition block.\n",
    "        dropout_rate: dropout rate\n",
    "        weight_decay: weight decay factor\n",
    "    Returns: keras tensor, after applying batch_norm, relu-conv, dropout, maxpool\n",
    "    '''\n",
    "    concat_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(ip)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(int(nb_filter * compression), (1, 1), kernel_initializer='he_normal', padding='same', use_bias=False,\n",
    "               kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = AveragePooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def __dense_block(x, nb_layers, nb_filter, growth_rate, bottleneck=False, dropout_rate=None, weight_decay=1e-4,\n",
    "                  grow_nb_filters=True, return_concat_list=False):\n",
    "    ''' Build a dense_block where the output of each conv_block is fed to subsequent ones\n",
    "    Args:\n",
    "        x: keras tensor\n",
    "        nb_layers: the number of layers of conv_block to append to the model.\n",
    "        nb_filter: number of filters\n",
    "        growth_rate: growth rate\n",
    "        bottleneck: bottleneck block\n",
    "        dropout_rate: dropout rate\n",
    "        weight_decay: weight decay factor\n",
    "        grow_nb_filters: flag to decide to allow number of filters to grow\n",
    "        return_concat_list: return the list of feature maps along with the actual output\n",
    "    Returns: keras tensor with nb_layers of conv_block appended\n",
    "    '''\n",
    "    concat_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    x_list = [x]\n",
    "\n",
    "    for i in range(nb_layers):\n",
    "        cb = __conv_block(x, growth_rate, bottleneck, dropout_rate, weight_decay)\n",
    "        x_list.append(cb)\n",
    "\n",
    "        x = concatenate([x, cb], axis=concat_axis)\n",
    "\n",
    "        if grow_nb_filters:\n",
    "            nb_filter += growth_rate\n",
    "\n",
    "    if return_concat_list:\n",
    "        return x, nb_filter, x_list\n",
    "    else:\n",
    "        return x, nb_filter\n",
    "\n",
    "def __conv_block(ip, nb_filter, bottleneck=False, dropout_rate=None, weight_decay=1e-4):\n",
    "  ''' Apply BatchNorm, Relu, 3x3 Conv2D, optional bottleneck block and dropout\n",
    "  Args:\n",
    "      ip: Input keras tensor\n",
    "      nb_filter: number of filters\n",
    "      bottleneck: add bottleneck block\n",
    "      dropout_rate: dropout rate\n",
    "      weight_decay: weight decay factor\n",
    "  Returns: keras tensor with batch_norm, relu and convolution2d added (optional bottleneck)\n",
    "  '''\n",
    "  concat_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "  x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(ip)\n",
    "  x = Activation('relu')(x)\n",
    "\n",
    "  if bottleneck:\n",
    "      inter_channel = nb_filter * 4  # Obtained from https://github.com/liuzhuang13/DenseNet/blob/master/densenet.lua\n",
    "\n",
    "      x = Conv2D(inter_channel, (1, 1), kernel_initializer='he_normal', padding='same', use_bias=False,\n",
    "                 kernel_regularizer=l2(weight_decay))(x)\n",
    "      x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5)(x)\n",
    "      x = Activation('relu')(x)\n",
    "\n",
    "  x = Conv2D(nb_filter, (3, 3), kernel_initializer='he_normal', padding='same', use_bias=False)(x)\n",
    "  if dropout_rate:\n",
    "      x = Dropout(dropout_rate)(x)\n",
    "\n",
    "  return x\n",
    "\n",
    "def DenseNet(input_shape=None, depth=40, nb_dense_block=3, growth_rate=12, nb_filter=-1, nb_layers_per_block=-1,\n",
    "             bottleneck=False, reduction=0.0, dropout_rate=0.0, weight_decay=1e-4, subsample_initial_block=False,\n",
    "             include_top=True, weights=None, input_tensor=None,\n",
    "             classes=10, activation='softmax'):\n",
    "    '''Instantiate the DenseNet architecture,\n",
    "        optionally loading weights pre-trained\n",
    "        on CIFAR-10. Note that when using TensorFlow,\n",
    "        for best performance you should set\n",
    "        `image_data_format='channels_last'` in your Keras config\n",
    "        at ~/.keras/keras.json.\n",
    "        The model and the weights are compatible with both\n",
    "        TensorFlow and Theano. The dimension ordering\n",
    "        convention used by the model is the one\n",
    "        specified in your Keras config file.\n",
    "        # Arguments\n",
    "            input_shape: optional shape tuple, only to be specified\n",
    "                if `include_top` is False (otherwise the input shape\n",
    "                has to be `(32, 32, 3)` (with `channels_last` dim ordering)\n",
    "                or `(3, 32, 32)` (with `channels_first` dim ordering).\n",
    "                It should have exactly 3 inputs channels,\n",
    "                and width and height should be no smaller than 8.\n",
    "                E.g. `(200, 200, 3)` would be one valid value.\n",
    "            depth: number or layers in the DenseNet\n",
    "            nb_dense_block: number of dense blocks to add to end (generally = 3)\n",
    "            growth_rate: number of filters to add per dense block\n",
    "            nb_filter: initial number of filters. -1 indicates initial\n",
    "                number of filters is 2 * growth_rate\n",
    "            nb_layers_per_block: number of layers in each dense block.\n",
    "                Can be a -1, positive integer or a list.\n",
    "                If -1, calculates nb_layer_per_block from the network depth.\n",
    "                If positive integer, a set number of layers per dense block.\n",
    "                If list, nb_layer is used as provided. Note that list size must\n",
    "                be (nb_dense_block + 1)\n",
    "            bottleneck: flag to add bottleneck blocks in between dense blocks\n",
    "            reduction: reduction factor of transition blocks.\n",
    "                Note : reduction value is inverted to compute compression.\n",
    "            dropout_rate: dropout rate\n",
    "            weight_decay: weight decay rate\n",
    "            subsample_initial_block: Set to True to subsample the initial convolution and\n",
    "                add a MaxPool2D before the dense blocks are added.\n",
    "            include_top: whether to include the fully-connected\n",
    "                layer at the top of the network.\n",
    "            weights: one of `None` (random initialization) or\n",
    "                'imagenet' (pre-training on ImageNet)..\n",
    "            input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "                to use as image input for the model.\n",
    "            classes: optional number of classes to classify images\n",
    "                into, only to be specified if `include_top` is True, and\n",
    "                if no `weights` argument is specified.\n",
    "            activation: Type of activation at the top layer. Can be one of 'softmax' or 'sigmoid'.\n",
    "                Note that if sigmoid is used, classes must be 1.\n",
    "        # Returns\n",
    "            A Keras model instance.\n",
    "        '''\n",
    "\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `cifar10` '\n",
    "                         '(pre-training on CIFAR-10).')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as ImageNet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "\n",
    "    if activation not in ['softmax', 'sigmoid']:\n",
    "        raise ValueError('activation must be one of \"softmax\" or \"sigmoid\"')\n",
    "\n",
    "    if activation == 'sigmoid' and classes != 1:\n",
    "        raise ValueError('sigmoid activation can only be used when classes = 1')\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=32,\n",
    "                                      min_size=8,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      require_flatten=include_top)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    x = __create_dense_net(classes, img_input, include_top, depth, nb_dense_block,\n",
    "                           growth_rate, nb_filter, nb_layers_per_block, bottleneck, reduction,\n",
    "                           dropout_rate, weight_decay, subsample_initial_block, activation)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='densenet')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        weights_loaded = False\n",
    "\n",
    "        if (depth == 121) and (nb_dense_block == 4) and (growth_rate == 32) and (nb_filter == 64) and \\\n",
    "                (bottleneck is True) and (reduction == 0.5) and (dropout_rate == 0.0) and (subsample_initial_block):\n",
    "            if include_top:\n",
    "                weights_path = get_file('DenseNet-BC-121-32.h5',\n",
    "                                        DENSENET_121_WEIGHTS_PATH,\n",
    "                                        cache_subdir='models',\n",
    "                                        md5_hash='a439dd41aa672aef6daba4ee1fd54abd')\n",
    "            else:\n",
    "                weights_path = get_file('DenseNet-BC-121-32-no-top.h5',\n",
    "                                        DENSENET_121_WEIGHTS_PATH_NO_TOP,\n",
    "                                        cache_subdir='models',\n",
    "                                        md5_hash='55e62a6358af8a0af0eedf399b5aea99')\n",
    "            model.load_weights(weights_path)\n",
    "            weights_loaded = True\n",
    "\n",
    "        if (depth == 161) and (nb_dense_block == 4) and (growth_rate == 48) and (nb_filter == 96) and \\\n",
    "                (bottleneck is True) and (reduction == 0.5) and (dropout_rate == 0.0) and (subsample_initial_block):\n",
    "            if include_top:\n",
    "                weights_path = get_file('DenseNet-BC-161-48.h5',\n",
    "                                        DENSENET_161_WEIGHTS_PATH,\n",
    "                                        cache_subdir='models',\n",
    "                                        md5_hash='6c326cf4fbdb57d31eff04333a23fcca')\n",
    "            else:\n",
    "                weights_path = get_file('DenseNet-BC-161-48-no-top.h5',\n",
    "                                        DENSENET_161_WEIGHTS_PATH_NO_TOP,\n",
    "                                        cache_subdir='models',\n",
    "                                        md5_hash='1a9476b79f6b7673acaa2769e6427b92')\n",
    "            model.load_weights(weights_path)\n",
    "            weights_loaded = True\n",
    "\n",
    "        if (depth == 169) and (nb_dense_block == 4) and (growth_rate == 32) and (nb_filter == 64) and \\\n",
    "                (bottleneck is True) and (reduction == 0.5) and (dropout_rate == 0.0) and (subsample_initial_block):\n",
    "            if include_top:\n",
    "                weights_path = get_file('DenseNet-BC-169-32.h5',\n",
    "                                        DENSENET_169_WEIGHTS_PATH,\n",
    "                                        cache_subdir='models',\n",
    "                                        md5_hash='914869c361303d2e39dec640b4e606a6')\n",
    "            else:\n",
    "                weights_path = get_file('DenseNet-BC-169-32-no-top.h5',\n",
    "                                        DENSENET_169_WEIGHTS_PATH_NO_TOP,\n",
    "                                        cache_subdir='models',\n",
    "                                        md5_hash='89c19e8276cfd10585d5fadc1df6859e')\n",
    "            model.load_weights(weights_path)\n",
    "            weights_loaded = True\n",
    "\n",
    "        if weights_loaded:\n",
    "            if K.backend() == 'theano':\n",
    "                convert_all_kernels_in_model(model)\n",
    "\n",
    "            if K.image_data_format() == 'channels_first' and K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image data format convention '\n",
    "                              '(`image_data_format=\"channels_first\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_data_format=\"channels_last\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "\n",
    "            print(\"Weights for the model were loaded successfully\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def DenseNetImageNet121(input_shape=None,\n",
    "                        bottleneck=True,\n",
    "                        reduction=0.5,\n",
    "                        dropout_rate=0.0,\n",
    "                        weight_decay=1e-4,\n",
    "                        include_top=True,\n",
    "                        weights='imagenet',\n",
    "                        input_tensor=None,\n",
    "                        classes=1000,\n",
    "                        activation='softmax'):\n",
    "    return DenseNet(input_shape, depth=121, nb_dense_block=4, growth_rate=32, nb_filter=64,\n",
    "                    nb_layers_per_block=[6, 12, 24, 16], bottleneck=bottleneck, reduction=reduction,\n",
    "                    dropout_rate=dropout_rate, weight_decay=weight_decay, subsample_initial_block=True,\n",
    "                    include_top=include_top, weights=weights, input_tensor=input_tensor,\n",
    "                    classes=classes, activation=activation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried using the Keras implementation of DenseNet to classify an elephant picture. The predictions were not correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Predicted:', [[(u'n03180011', u'desktop_computer', 0.3106413), (u'n06359193', u'web_site', 0.23376717), (u'n03249569', u'drum', 0.1802558), (u'n04380533', u'table_lamp', 0.16848156), (u'n02105251', u'briard', 0.042605225)]])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "\n",
    "model = keras.applications.densenet.DenseNet121(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "\n",
    "img_path = 'elephant.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "#x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "\n",
    "print('Predicted:', decode_predictions(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for the model were loaded successfully\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 112, 112, 64) 9408        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 112, 112, 64) 256         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 112, 112, 64) 0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 56, 56, 64)   0           activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 56, 56, 64)   256         max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 56, 56, 64)   0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 56, 56, 128)  8192        activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 56, 56, 128)  512         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 56, 56, 128)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 56, 56, 32)   36864       activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 56, 56, 96)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 56, 56, 96)   384         concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 56, 56, 96)   0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 56, 56, 128)  12288       activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 56, 56, 128)  512         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 56, 56, 128)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 56, 56, 32)   36864       activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 56, 56, 128)  0           concatenate_59[0][0]             \n",
      "                                                                 conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 56, 56, 128)  512         concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 56, 56, 128)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 56, 56, 128)  16384       activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 56, 56, 128)  512         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 56, 56, 128)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 56, 56, 32)   36864       activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 56, 56, 160)  0           concatenate_60[0][0]             \n",
      "                                                                 conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 56, 56, 160)  640         concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 56, 56, 160)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 56, 56, 128)  20480       activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 56, 56, 128)  512         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 56, 56, 128)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 56, 56, 32)   36864       activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 56, 56, 192)  0           concatenate_61[0][0]             \n",
      "                                                                 conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 56, 56, 192)  768         concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 56, 56, 192)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 56, 56, 128)  24576       activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 56, 56, 128)  512         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 56, 56, 128)  0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 56, 56, 32)   36864       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)    (None, 56, 56, 224)  0           concatenate_62[0][0]             \n",
      "                                                                 conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 56, 56, 224)  896         concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 56, 56, 224)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 56, 56, 128)  28672       activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 56, 56, 128)  512         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 56, 56, 128)  0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 56, 56, 32)   36864       activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 56, 56, 256)  0           concatenate_63[0][0]             \n",
      "                                                                 conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 56, 56, 256)  1024        concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 56, 56, 256)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 56, 56, 128)  32768       activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 28, 28, 128)  0           conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 28, 28, 128)  512         average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 28, 28, 128)  0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 28, 28, 128)  16384       activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 28, 28, 128)  512         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 28, 28, 128)  0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 28, 28, 32)   36864       activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 28, 28, 160)  0           average_pooling2d_4[0][0]        \n",
      "                                                                 conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 28, 28, 160)  640         concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 28, 28, 160)  0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 28, 28, 128)  20480       activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 28, 28, 128)  512         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 28, 28, 128)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 28, 28, 32)   36864       activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 28, 28, 192)  0           concatenate_65[0][0]             \n",
      "                                                                 conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 28, 28, 192)  768         concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 28, 28, 192)  0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 28, 28, 128)  24576       activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 28, 28, 128)  512         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 28, 28, 128)  0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 28, 28, 32)   36864       activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 28, 28, 224)  0           concatenate_66[0][0]             \n",
      "                                                                 conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 28, 28, 224)  896         concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 28, 28, 224)  0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 28, 28, 128)  28672       activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 28, 28, 128)  512         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 28, 28, 128)  0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 28, 28, 32)   36864       activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 28, 28, 256)  0           concatenate_67[0][0]             \n",
      "                                                                 conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 28, 28, 256)  1024        concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 28, 28, 256)  0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 28, 28, 128)  32768       activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 28, 28, 128)  512         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 28, 28, 128)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 28, 28, 32)   36864       activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 28, 28, 288)  0           concatenate_68[0][0]             \n",
      "                                                                 conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 28, 28, 288)  1152        concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 28, 28, 288)  0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 28, 28, 128)  36864       activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 28, 28, 128)  512         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 28, 28, 128)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 28, 28, 32)   36864       activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, 28, 28, 320)  0           concatenate_69[0][0]             \n",
      "                                                                 conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 28, 28, 320)  1280        concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 28, 28, 320)  0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 28, 28, 128)  40960       activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 28, 28, 128)  512         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 28, 28, 128)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 28, 28, 32)   36864       activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)    (None, 28, 28, 352)  0           concatenate_70[0][0]             \n",
      "                                                                 conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 28, 28, 352)  1408        concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 28, 28, 352)  0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 28, 28, 128)  45056       activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 28, 28, 128)  512         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 28, 28, 128)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 28, 28, 32)   36864       activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)    (None, 28, 28, 384)  0           concatenate_71[0][0]             \n",
      "                                                                 conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 28, 28, 384)  1536        concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 28, 28, 384)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 28, 28, 128)  49152       activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 28, 28, 128)  512         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 28, 28, 128)  0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 28, 28, 32)   36864       activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_73 (Concatenate)    (None, 28, 28, 416)  0           concatenate_72[0][0]             \n",
      "                                                                 conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 28, 28, 416)  1664        concatenate_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 28, 28, 416)  0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 28, 28, 128)  53248       activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 28, 28, 128)  512         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 28, 28, 128)  0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 28, 28, 32)   36864       activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_74 (Concatenate)    (None, 28, 28, 448)  0           concatenate_73[0][0]             \n",
      "                                                                 conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 28, 28, 448)  1792        concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 28, 28, 448)  0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 28, 28, 128)  57344       activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 28, 28, 128)  512         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 28, 28, 128)  0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 28, 28, 32)   36864       activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_75 (Concatenate)    (None, 28, 28, 480)  0           concatenate_74[0][0]             \n",
      "                                                                 conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 28, 28, 480)  1920        concatenate_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 28, 28, 480)  0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 28, 28, 128)  61440       activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 28, 28, 128)  512         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 28, 28, 128)  0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 28, 28, 32)   36864       activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_76 (Concatenate)    (None, 28, 28, 512)  0           concatenate_75[0][0]             \n",
      "                                                                 conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 28, 28, 512)  2048        concatenate_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 28, 28, 512)  0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 28, 28, 256)  131072      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 14, 14, 256)  0           conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 14, 14, 256)  1024        average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 14, 14, 256)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 14, 14, 128)  32768       activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 14, 14, 128)  512         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 14, 14, 128)  0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 14, 14, 32)   36864       activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_77 (Concatenate)    (None, 14, 14, 288)  0           average_pooling2d_5[0][0]        \n",
      "                                                                 conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 14, 14, 288)  1152        concatenate_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 14, 14, 288)  0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 14, 14, 128)  36864       activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 14, 14, 128)  512         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 14, 14, 128)  0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 14, 14, 32)   36864       activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_78 (Concatenate)    (None, 14, 14, 320)  0           concatenate_77[0][0]             \n",
      "                                                                 conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 14, 14, 320)  1280        concatenate_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 14, 14, 320)  0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 14, 14, 128)  40960       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 14, 14, 128)  512         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 14, 14, 128)  0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 14, 14, 32)   36864       activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_79 (Concatenate)    (None, 14, 14, 352)  0           concatenate_78[0][0]             \n",
      "                                                                 conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 14, 14, 352)  1408        concatenate_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 14, 14, 352)  0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 14, 14, 128)  45056       activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 14, 14, 128)  512         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 14, 14, 128)  0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 14, 14, 32)   36864       activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_80 (Concatenate)    (None, 14, 14, 384)  0           concatenate_79[0][0]             \n",
      "                                                                 conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 14, 14, 384)  1536        concatenate_80[0][0]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 14, 14, 384)  0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 14, 14, 128)  49152       activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 14, 14, 128)  512         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 14, 14, 128)  0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 14, 14, 32)   36864       activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_81 (Concatenate)    (None, 14, 14, 416)  0           concatenate_80[0][0]             \n",
      "                                                                 conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 14, 14, 416)  1664        concatenate_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 14, 14, 416)  0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 14, 14, 128)  53248       activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 14, 14, 128)  512         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 14, 14, 128)  0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 14, 14, 32)   36864       activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_82 (Concatenate)    (None, 14, 14, 448)  0           concatenate_81[0][0]             \n",
      "                                                                 conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 14, 14, 448)  1792        concatenate_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 14, 14, 448)  0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 14, 14, 128)  57344       activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 14, 14, 128)  512         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 14, 14, 128)  0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 14, 14, 32)   36864       activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_83 (Concatenate)    (None, 14, 14, 480)  0           concatenate_82[0][0]             \n",
      "                                                                 conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 14, 14, 480)  1920        concatenate_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 14, 14, 480)  0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 14, 14, 128)  61440       activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 14, 14, 128)  512         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 14, 14, 128)  0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 14, 14, 32)   36864       activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_84 (Concatenate)    (None, 14, 14, 512)  0           concatenate_83[0][0]             \n",
      "                                                                 conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 14, 14, 512)  2048        concatenate_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 14, 14, 512)  0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 14, 14, 128)  65536       activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 14, 14, 128)  512         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 14, 14, 128)  0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 14, 14, 32)   36864       activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_85 (Concatenate)    (None, 14, 14, 544)  0           concatenate_84[0][0]             \n",
      "                                                                 conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 14, 14, 544)  2176        concatenate_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 14, 14, 544)  0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 14, 14, 128)  69632       activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 14, 14, 128)  512         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 14, 14, 128)  0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 14, 14, 32)   36864       activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_86 (Concatenate)    (None, 14, 14, 576)  0           concatenate_85[0][0]             \n",
      "                                                                 conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 14, 14, 576)  2304        concatenate_86[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 14, 14, 576)  0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 14, 14, 128)  73728       activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 14, 14, 128)  512         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 14, 14, 128)  0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 14, 14, 32)   36864       activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_87 (Concatenate)    (None, 14, 14, 608)  0           concatenate_86[0][0]             \n",
      "                                                                 conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 14, 14, 608)  2432        concatenate_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 14, 14, 608)  0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 14, 14, 128)  77824       activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 14, 14, 128)  512         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 14, 14, 128)  0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 14, 14, 32)   36864       activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_88 (Concatenate)    (None, 14, 14, 640)  0           concatenate_87[0][0]             \n",
      "                                                                 conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 14, 14, 640)  2560        concatenate_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 14, 14, 640)  0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 14, 14, 128)  81920       activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 14, 14, 128)  512         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 14, 14, 128)  0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 14, 14, 32)   36864       activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_89 (Concatenate)    (None, 14, 14, 672)  0           concatenate_88[0][0]             \n",
      "                                                                 conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 14, 14, 672)  2688        concatenate_89[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 14, 14, 672)  0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 14, 14, 128)  86016       activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 14, 14, 128)  512         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 14, 14, 128)  0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 14, 14, 32)   36864       activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_90 (Concatenate)    (None, 14, 14, 704)  0           concatenate_89[0][0]             \n",
      "                                                                 conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 14, 14, 704)  2816        concatenate_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 14, 14, 704)  0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 14, 14, 128)  90112       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 14, 14, 128)  512         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 14, 14, 128)  0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 14, 14, 32)   36864       activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_91 (Concatenate)    (None, 14, 14, 736)  0           concatenate_90[0][0]             \n",
      "                                                                 conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 14, 14, 736)  2944        concatenate_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 14, 14, 736)  0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 14, 14, 128)  94208       activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 14, 14, 128)  512         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 14, 14, 128)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 14, 14, 32)   36864       activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_92 (Concatenate)    (None, 14, 14, 768)  0           concatenate_91[0][0]             \n",
      "                                                                 conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 14, 14, 768)  3072        concatenate_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 14, 14, 768)  0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 14, 14, 128)  98304       activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 14, 14, 128)  512         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 14, 14, 128)  0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 14, 14, 32)   36864       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_93 (Concatenate)    (None, 14, 14, 800)  0           concatenate_92[0][0]             \n",
      "                                                                 conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 14, 14, 800)  3200        concatenate_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 14, 14, 800)  0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 14, 14, 128)  102400      activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 14, 14, 128)  512         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 14, 14, 128)  0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 14, 14, 32)   36864       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_94 (Concatenate)    (None, 14, 14, 832)  0           concatenate_93[0][0]             \n",
      "                                                                 conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 14, 14, 832)  3328        concatenate_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 14, 14, 832)  0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 14, 14, 128)  106496      activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 14, 14, 128)  512         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 14, 14, 128)  0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 14, 14, 32)   36864       activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_95 (Concatenate)    (None, 14, 14, 864)  0           concatenate_94[0][0]             \n",
      "                                                                 conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 14, 14, 864)  3456        concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 14, 14, 864)  0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 14, 14, 128)  110592      activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 14, 14, 128)  512         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 14, 14, 128)  0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 14, 14, 32)   36864       activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)    (None, 14, 14, 896)  0           concatenate_95[0][0]             \n",
      "                                                                 conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 14, 14, 896)  3584        concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 14, 14, 896)  0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 14, 14, 128)  114688      activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 14, 14, 128)  512         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 14, 14, 128)  0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 14, 14, 32)   36864       activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 14, 14, 928)  0           concatenate_96[0][0]             \n",
      "                                                                 conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 14, 14, 928)  3712        concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 14, 14, 928)  0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 14, 14, 128)  118784      activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 14, 14, 128)  512         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 14, 14, 128)  0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 14, 14, 32)   36864       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_98 (Concatenate)    (None, 14, 14, 960)  0           concatenate_97[0][0]             \n",
      "                                                                 conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 14, 14, 960)  3840        concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 14, 14, 960)  0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 14, 14, 128)  122880      activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 14, 14, 128)  512         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 14, 14, 128)  0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 14, 14, 32)   36864       activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_99 (Concatenate)    (None, 14, 14, 992)  0           concatenate_98[0][0]             \n",
      "                                                                 conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 14, 14, 992)  3968        concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 14, 14, 992)  0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 14, 14, 128)  126976      activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 14, 14, 128)  512         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 14, 14, 128)  0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 14, 14, 32)   36864       activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)   (None, 14, 14, 1024) 0           concatenate_99[0][0]             \n",
      "                                                                 conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 14, 14, 1024) 4096        concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 14, 14, 1024) 0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 14, 14, 512)  524288      activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 7, 7, 512)    0           conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 7, 7, 512)    2048        average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 7, 7, 512)    0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 7, 7, 128)    65536       activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 7, 7, 128)    512         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 7, 7, 128)    0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 7, 7, 32)     36864       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)   (None, 7, 7, 544)    0           average_pooling2d_6[0][0]        \n",
      "                                                                 conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 7, 7, 544)    2176        concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 7, 7, 544)    0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 7, 7, 128)    69632       activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 7, 7, 128)    512         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 7, 7, 128)    0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 7, 7, 32)     36864       activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)   (None, 7, 7, 576)    0           concatenate_101[0][0]            \n",
      "                                                                 conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 7, 7, 576)    2304        concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 7, 7, 576)    0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 7, 7, 128)    73728       activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 7, 7, 128)    512         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 7, 7, 128)    0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 7, 7, 32)     36864       activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)   (None, 7, 7, 608)    0           concatenate_102[0][0]            \n",
      "                                                                 conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 7, 7, 608)    2432        concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 7, 7, 608)    0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 7, 7, 128)    77824       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 7, 7, 128)    512         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 7, 7, 128)    0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 7, 7, 32)     36864       activation_217[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)   (None, 7, 7, 640)    0           concatenate_103[0][0]            \n",
      "                                                                 conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 7, 7, 640)    2560        concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 7, 7, 640)    0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 7, 7, 128)    81920       activation_218[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 7, 7, 128)    512         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 7, 7, 128)    0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 7, 7, 32)     36864       activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_105 (Concatenate)   (None, 7, 7, 672)    0           concatenate_104[0][0]            \n",
      "                                                                 conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 7, 7, 672)    2688        concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 7, 7, 672)    0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 7, 7, 128)    86016       activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 7, 7, 128)    512         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 7, 7, 128)    0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 7, 7, 32)     36864       activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)   (None, 7, 7, 704)    0           concatenate_105[0][0]            \n",
      "                                                                 conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 7, 7, 704)    2816        concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 7, 7, 704)    0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 7, 7, 128)    90112       activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 7, 7, 128)    512         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 7, 7, 128)    0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 7, 7, 32)     36864       activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_107 (Concatenate)   (None, 7, 7, 736)    0           concatenate_106[0][0]            \n",
      "                                                                 conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 7, 7, 736)    2944        concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 7, 7, 736)    0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 7, 7, 128)    94208       activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 7, 7, 128)    512         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 7, 7, 128)    0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 7, 7, 32)     36864       activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)   (None, 7, 7, 768)    0           concatenate_107[0][0]            \n",
      "                                                                 conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 7, 7, 768)    3072        concatenate_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 7, 7, 768)    0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 7, 7, 128)    98304       activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 7, 7, 128)    512         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 7, 7, 128)    0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 7, 7, 32)     36864       activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_109 (Concatenate)   (None, 7, 7, 800)    0           concatenate_108[0][0]            \n",
      "                                                                 conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 7, 7, 800)    3200        concatenate_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 7, 7, 800)    0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 7, 7, 128)    102400      activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 7, 7, 128)    512         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 7, 7, 128)    0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 7, 7, 32)     36864       activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_110 (Concatenate)   (None, 7, 7, 832)    0           concatenate_109[0][0]            \n",
      "                                                                 conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 7, 7, 832)    3328        concatenate_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 7, 7, 832)    0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 7, 7, 128)    106496      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 7, 7, 128)    512         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 7, 7, 128)    0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 7, 7, 32)     36864       activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_111 (Concatenate)   (None, 7, 7, 864)    0           concatenate_110[0][0]            \n",
      "                                                                 conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 7, 7, 864)    3456        concatenate_111[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 7, 7, 864)    0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 7, 7, 128)    110592      activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 7, 7, 128)    512         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 7, 7, 128)    0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 7, 7, 32)     36864       activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_112 (Concatenate)   (None, 7, 7, 896)    0           concatenate_111[0][0]            \n",
      "                                                                 conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 7, 7, 896)    3584        concatenate_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 7, 7, 896)    0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 7, 7, 128)    114688      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 7, 7, 128)    512         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 7, 7, 128)    0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 7, 7, 32)     36864       activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_113 (Concatenate)   (None, 7, 7, 928)    0           concatenate_112[0][0]            \n",
      "                                                                 conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 7, 7, 928)    3712        concatenate_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 7, 7, 928)    0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 7, 7, 128)    118784      activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 7, 7, 128)    512         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 7, 7, 128)    0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 7, 7, 32)     36864       activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_114 (Concatenate)   (None, 7, 7, 960)    0           concatenate_113[0][0]            \n",
      "                                                                 conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 7, 7, 960)    3840        concatenate_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 7, 7, 960)    0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 7, 7, 128)    122880      activation_238[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 7, 7, 128)    512         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 7, 7, 128)    0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 7, 7, 32)     36864       activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)   (None, 7, 7, 992)    0           concatenate_114[0][0]            \n",
      "                                                                 conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 7, 7, 992)    3968        concatenate_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 7, 7, 992)    0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 7, 7, 128)    126976      activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 7, 7, 128)    512         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 7, 7, 128)    0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 7, 7, 32)     36864       activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_116 (Concatenate)   (None, 7, 7, 1024)   0           concatenate_115[0][0]            \n",
      "                                                                 conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 7, 7, 1024)   4096        concatenate_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 7, 7, 1024)   0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 1024)         0           activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1000)         1025000     global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 8,062,504\n",
      "Trainable params: 7,978,856\n",
      "Non-trainable params: 83,648\n",
      "__________________________________________________________________________________________________\n",
      "Predicted: [[(u'n02504013', u'Indian_elephant', 0.66329026), (u'n01871265', u'tusker', 0.28634223), (u'n02504458', u'African_elephant', 0.050195783), (u'n02397096', u'warthog', 5.2023577e-05), (u'n02109047', u'Great_Dane', 1.5670445e-05)]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "size = 224\n",
    "\n",
    "#Load DenseNet model\n",
    "model = DenseNetImageNet121(input_shape=(size, size, 3))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "img_path = 'elephant.jpg'\n",
    "#Load an image from file\n",
    "img = image.load_img(img_path, target_size=(size, size))\n",
    "#Convert the image pixels to a Numpy array\n",
    "x = image.img_to_array(img)\n",
    "#Reshape data for the model\n",
    "x = np.expand_dims(x, axis=0)\n",
    "#Prepare the image for the DenseNet model - the image pixels need to be prepared in the same way as the ImageNet training data\n",
    "#was prepared.\n",
    "x = preprocess_input(x)\n",
    "#Predict the probability across all classes\n",
    "preds = model.predict(x)\n",
    "#Conver the probabilities to class labels and print those\n",
    "print('Predicted:', decode_predictions(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flickr 8k Dataset\n",
    "Flicker8k Dataset contains 2 zip files. \n",
    "- Flickr8k Dataset.zip (1 Gigabyte) This is an archive of all photographs. It contains more than 8000 photographs in JPEG format. When you unzip this it will unzip to a folder name that spells 'Flicker' but I renamed the folder to 'Flickr' to be consistent.\n",
    "- Flickr8k text.zip (2.2 Megabytes) This is an archive of all text descriptions for photographs. It contains a number of files containing different sources of descriptions for the photographs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code goes through the dataset and pre calculates all the features for the pictures, so we can save time while training the network. The starting place for this code is the prepare_dataset() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pickle\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "counter = 0\n",
    "\n",
    "def load_doc(filename):\n",
    "    file = open(filename, 'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "def load_set(filename):\n",
    "    doc = load_doc(filename)\n",
    "    dataset = list()\n",
    "    for line in doc.split('\\n'):\n",
    "        if len(line) < 1:\n",
    "            continue\n",
    "        #identifier = line.split('.')[0]\n",
    "        dataset.append(line)\n",
    "    return set(dataset)\n",
    "    \n",
    "#Loads a given image from the folder and prepares the image pixels to be compatible with the DenseNet model\n",
    "def load_image(path):\n",
    "\t#Load an image from file\n",
    "\timg = image.load_img(path, target_size=(224,224))\n",
    "\t#Convert the image pixels to a Numpy array\n",
    "\tx = image.img_to_array(img)\n",
    "\t#Reshape data for the model\n",
    "\tx = np.expand_dims(x, axis=0)\n",
    "\t#Prepare the image for the DenseNet model - the image pixels need to be prepared in the same way as the ImageNet training data\n",
    "\t#was prepared.\n",
    "\tx = preprocess_input(x)\n",
    "\treturn np.asarray(x)\n",
    "\n",
    "#Loads the encoding model to be used to get the encoded values for the pictures\n",
    "def load_encoding_model():\n",
    "    size = 224\n",
    "    model = DenseNetImageNet121(input_shape=(size, size, 3))\n",
    "    #Remove the top classification layer\n",
    "    model.layers.pop()\n",
    "    model = Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
    "    #Make those layer non-trainable\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "\n",
    "#Given an image this returns the encoding for that picture\n",
    "def get_encoding(model, img):\n",
    "\tglobal counter\n",
    "\tcounter += 1\n",
    "\t#Load the image from the folder\n",
    "\timage = load_image('Flickr8k_Dataset/'+str(img))\n",
    "\tpred = model.predict(image)\n",
    "\tpred = np.reshape(pred, pred.shape[1])\n",
    "\tif counter%1000 ==0: \n",
    "\t\tprint (\"Encoding image: \"+str(counter))\n",
    "\t\tprint (pred.shape)\n",
    "\treturn pred\n",
    "\n",
    "#This function does 2 things. Creates the encoded values for the pictures and adds a start and end tag to the captions in the\n",
    "#train and test data.\n",
    "def prepare_dataset(no_imgs = -1):\n",
    "\t#Load train captions to memory    \n",
    "\tf_train_images = open('Flickr8k_text/Flickr_8k.trainImages.txt','rb')\n",
    "\ttrain_imgs = f_train_images.read().strip().split('\\n') if no_imgs == -1 else f_train_images.read().strip().split('\\n')[:no_imgs]\n",
    "\tf_train_images.close()\n",
    "\n",
    "\t#Load test captions to memory    \n",
    "\tf_test_images = open('Flickr8k_text/Flickr_8k.testImages.txt','rb')\n",
    "\ttest_imgs = f_test_images.read().strip().split('\\n') if no_imgs == -1 else f_test_images.read().strip().split('\\n')[:no_imgs]\n",
    "\tf_test_images.close()\n",
    "\n",
    "\t#Create a new file to write the tagged train captions\n",
    "\tf_train_dataset = open('Flickr8k_text/flickr_8k_train_dataset.txt','wb')\n",
    "\tf_train_dataset.write(\"image_id\\tcaptions\\n\")\n",
    "\n",
    "\t#Create a new file to write the tagged test captions\n",
    "\tf_test_dataset = open('Flickr8k_text/flickr_8k_test_dataset.txt','wb')\n",
    "\tf_test_dataset.write(\"image_id\\tcaptions\\n\")\n",
    "    \n",
    "\t#Go through the text file that contains all the captions and load them into 'captions'\n",
    "\tf_captions = open('Flickr8k_text/Flickr8k.token.txt', 'rb')\n",
    "\tcaptions = f_captions.read().strip().split('\\n')\n",
    "\tdata = {}\n",
    "\tfor row in captions:\n",
    "\t\trow = row.split(\"\\t\")\n",
    "\t\trow[0] = row[0][:len(row[0])-2]\n",
    "\t\ttry:\n",
    "\t\t\tdata[row[0]].append(row[1])\n",
    "\t\texcept:\n",
    "\t\t\tdata[row[0]] = [row[1]]\n",
    "\tf_captions.close()\n",
    "\n",
    "\tencoded_images = {}\n",
    "\t#Load encoding model to be used to encode the pictures\n",
    "\tencoding_model = load_encoding_model()\n",
    "\n",
    "\tc_train = 0\n",
    "\t#Go through the train caption list to add the start and end tags    \n",
    "\tfor img in train_imgs:\n",
    "\t\t#print (\"Encoding image: \"+str(img))\n",
    "\t\t#Get encoding for that training picture\n",
    "\t\tencoded_images[img] = get_encoding(encoding_model, img)\n",
    "\t\tfor capt in data[img]:\n",
    "\t\t\tcaption = \"<start> \"+capt+\" <end>\"\n",
    "\t\t\tf_train_dataset.write(img+\"\\t\"+caption+\"\\n\")\n",
    "\t\t\tf_train_dataset.flush()\n",
    "\t\t\tc_train += 1\n",
    "\tf_train_dataset.close()\n",
    "\n",
    "\tc_test = 0\n",
    "\t#Go through the test caption list to add the start and end tags    \n",
    "\tfor img in test_imgs:\n",
    "\t\t#Get encoding for that test picture\n",
    "\t\tencoded_images[img] = get_encoding(encoding_model, img)\n",
    "\t\tfor capt in data[img]:\n",
    "\t\t\tcaption = \"<start> \"+capt+\" <end>\"\n",
    "\t\t\tf_test_dataset.write(img+\"\\t\"+caption+\"\\n\")\n",
    "\t\t\tf_test_dataset.flush()\n",
    "\t\t\tc_test += 1\n",
    "\tf_test_dataset.close()\n",
    "\n",
    "\t#Save the encoded images to a file, which will be used by the model during training\n",
    "\twith open( \"encoded_images.p\", \"wb\" ) as pickle_f:\n",
    "\t\tpickle.dump( encoded_images, pickle_f )\n",
    "\treturn [c_train, c_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for the model were loaded successfully\n",
      "Encoding image: 1000\n",
      "(1024,)\n",
      "Encoding image: 2000\n",
      "(1024,)\n",
      "Encoding image: 3000\n",
      "(1024,)\n",
      "Encoding image: 4000\n",
      "(1024,)\n",
      "Encoding image: 5000\n",
      "(1024,)\n",
      "Encoding image: 6000\n",
      "(1024,)\n",
      "Encoding image: 7000\n",
      "(1024,)\n",
      "Training samples = 30000\n",
      "Test samples = 5000\n"
     ]
    }
   ],
   "source": [
    "#Create the encoding files and tag the captions in the test and training set\n",
    "c_train, c_test = prepare_dataset()\n",
    "print (\"Training samples = \"+str(c_train))\n",
    "print (\"Test samples = \"+str(c_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "\n",
    "lr = 0.001 \n",
    "\n",
    "def schedule_lr(epoch):\n",
    "    if epoch in [11,12,13,14,15]:\n",
    "        lrate = lr/2\n",
    "    elif epoch in [20,21,22,23]:\n",
    "        lrate = lr/2\n",
    "    elif epoch in [24,25,26,27]:  \n",
    "        lrate = lr/4\n",
    "    elif epoch in [28,29,30,31]:  \n",
    "        lrate = lr/6\n",
    "    elif epoch in [32, 33,34,35]:  \n",
    "        lrate = lr/8\n",
    "    elif epoch in [36,37,38,39]:  \n",
    "        lrate = lr/10\n",
    "    elif epoch in [40,41]:  \n",
    "        lrate = lr/12\n",
    "    elif epoch in [42,43]:  \n",
    "        lrate = lr/14\n",
    "    elif epoch in [44,45]:  \n",
    "        lrate = lr/16\n",
    "    elif epoch in [46,47]:  \n",
    "        lrate = lr/18\n",
    "    elif epoch in [48,49]:  \n",
    "        lrate = lr/20\n",
    "    else:\n",
    "        lrate = lr\n",
    "\n",
    "    return lrate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Model\n",
    "Using the fixed length encoding output from the **Computer Vision Model** as the input to the LSTM model we get the output, which are the captions for the given picture.\n",
    "This is the decoder in the encoder-decoder architecture.\n",
    "While a convolutional neural network is used to encode the images, a recurrent neural network, such as a Long Short-Term Memory network, is used to generate the next word in the sequence. The model generates one word of the output textual description, given both the photograph and the description generated so far as input. The model is called recursively until the entire output sequence is generated.\n",
    "The encoder and decoder arhitecture can be implemented using one of two architectures, as the inject and the merge models.\n",
    "\n",
    "### Merge Model\n",
    "Merge model is used below. The merge model combines both the encoded form of the image input with the encoded form of the text description generated so far. The combination of these two encoded inputs is then used by a very simple decoder model to generate the next word in the sequence. The approach uses the recurrent neural network only to encode the text generated so far.\n",
    "This separates the concern of modeling the image input, the text input and the combining & interpretation of the encoded inputs. It is common to use a pre-trained model for encoding the image, but similarly, this architecture also permits a pre-trained language model to be used to encode the caption text input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code creates the dataset required for the network during training. For instance when the picture needs to be trained on a picture with a caption say 'A black dog is running after a white dog in the snow'. The prepare_dataset() function will return the data as:\n",
    "\n",
    "| Picture  | X |y |\n",
    "| ------------- | ------------- |\n",
    "| Encoded values  | A  | black |\n",
    "| Encoded values  | A black  | dog|\n",
    "| Encoded values  | A black dog | is |\n",
    "| Encoded values  | A black dog is  | running |\n",
    "| Encoded values  | A black dog is running  | after |\n",
    "| Encoded values  | A black dog is running after  | a |\n",
    "| Encoded values  | A black dog is running after a  | white |\n",
    "| Encoded values  | A black dog is running after a white  | dog |\n",
    "| Encoded values  | A black dog is running after a white dog  | in |\n",
    "| Encoded values  | A black dog is running after a white dog in   | the|\n",
    "| Encoded values  | A black dog is running after a white dog in the   | snow|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector, Merge, Activation, Flatten\n",
    "from keras.preprocessing import image, sequence\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import cPickle as pickle\n",
    "\n",
    "EMBEDDING_DIM = 128\n",
    "\n",
    "\n",
    "class CaptionGenerator():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.max_cap_len = None\n",
    "        self.vocab_size = None\n",
    "        self.index_word = None\n",
    "        self.word_index = None\n",
    "        self.total_samples = None\n",
    "        self.encoded_images = pickle.load( open( \"encoded_images.p\", \"rb\" ) )\n",
    "        self.variable_initializer()\n",
    "\n",
    "    #Create vocabulary to be used during training and encodes words in each sentences\n",
    "    def variable_initializer(self):\n",
    "        df = pd.read_csv('Flickr8k_text/flickr_8k_train_dataset.txt', delimiter='\\t')\n",
    "        nb_samples = df.shape[0]\n",
    "        iter = df.iterrows()\n",
    "        caps = []\n",
    "        # Create a list of captions\n",
    "        for i in range(nb_samples):\n",
    "            x = iter.next()\n",
    "            caps.append(x[1][1])\n",
    "\n",
    "        self.total_samples=0\n",
    "        # Calculate number of words in the corpus\n",
    "        for text in caps:\n",
    "            self.total_samples+=len(text.split())-1\n",
    "        print (\"Total samples : \" + str(self.total_samples))\n",
    "        \n",
    "        # Create a list of sentences with each sentence split into words\n",
    "        words = [txt.split() for txt in caps]\n",
    "        unique = []\n",
    "\n",
    "        # Creeate a list of words\n",
    "        for word in words:\n",
    "            unique.extend(word)\n",
    "\n",
    "        #Make a unique list of workds\n",
    "        unique = list(set(unique))\n",
    "        self.vocab_size = len(unique)\n",
    "        self.word_index = {}\n",
    "        self.index_word = {}\n",
    "        for i, word in enumerate(unique):\n",
    "            # integer encode words\n",
    "            self.word_index[word]=i\n",
    "            self.index_word[i]=word\n",
    "\n",
    "        max_len = 0\n",
    "        # Calculate the largest amount of words present in a sentence in the given corpus. This is used to pad all sequences\n",
    "        # to be of this length so it is consistent.\n",
    "        for caption in caps:\n",
    "            if(len(caption.split()) > max_len):\n",
    "                max_len = len(caption.split())\n",
    "        self.max_cap_len = max_len\n",
    "        print (\"Vocabulary size: \"+str(self.vocab_size))\n",
    "        print (\"Maximum caption length: \"+str(self.max_cap_len))\n",
    "        print (\"Variables initialization done!\")\n",
    "\n",
    "\n",
    "    #This progressively loads the data required during training. This technique is used when the entire dataset cannot be \n",
    "    #fit into memory\n",
    "    def data_generator(self, batch_size = 32):\n",
    "        partial_caps = []\n",
    "        next_words = []\n",
    "        images = []\n",
    "        print (\"Generating data...\")\n",
    "        gen_count = 0\n",
    "        #Read the tagged captions from training dataset\n",
    "        df = pd.read_csv('Flickr8k_text/flickr_8k_train_dataset.txt', delimiter='\\t')\n",
    "        nb_samples = df.shape[0]\n",
    "        iter = df.iterrows()\n",
    "        caps = []\n",
    "        imgs = []\n",
    "        #Go through each line in the training dataset and create a list of captions and images\n",
    "        for i in range(nb_samples):\n",
    "            x = iter.next()\n",
    "            caps.append(x[1][1])\n",
    "            imgs.append(x[1][0])\n",
    "\n",
    "\n",
    "        total_count = 0\n",
    "        #this loop will exit when all the data in the training set is passed to the network during training \n",
    "        while 1:\n",
    "            image_counter = -1\n",
    "            #Loop through all the captions in the training data\n",
    "            for text in caps:\n",
    "                image_counter+=1\n",
    "                #Get the encoded image for the picture. This will be the input to the  denseNet model\n",
    "                current_image = self.encoded_images[imgs[image_counter]]\n",
    "\n",
    "                #create a list of words from the sentence\n",
    "                for i in range(len(text.split())-1):\n",
    "                    total_count+=1\n",
    "                    #get the first word in the sentence\n",
    "                    partial = [self.word_index[txt] for txt in text.split()[:i+1]]\n",
    "                    partial_caps.append(partial)\n",
    "                    next = np.zeros(self.vocab_size)\n",
    "                    #the 'next' calls this in a loop to create the 'X', y mentioned above in the table at the beginning\n",
    "                    next[self.word_index[text.split()[i+1]]] = 1\n",
    "                    next_words.append(next)\n",
    "                    images.append(current_image)\n",
    "\n",
    "                    #when the batch size is reached return the 'Picture', 'X' and 'y' values collected so far.\n",
    "                    if total_count>=batch_size:\n",
    "                        next_words = np.asarray(next_words)\n",
    "                        images = np.asarray(images)\n",
    "                        # pad all sequences to a fixed length\n",
    "                        partial_caps = sequence.pad_sequences(partial_caps, maxlen=self.max_cap_len, padding='post')\n",
    "                        total_count = 0\n",
    "                        gen_count+=1\n",
    "                        if gen_count%1000 ==0: print (\"yielding count: \"+str(gen_count))\n",
    "                        yield [[images, partial_caps], next_words]\n",
    "                        partial_caps = []\n",
    "                        next_words = []\n",
    "                        images = []\n",
    "        \n",
    "    def load_image(self, path):\n",
    "        img = image.load_img(path, target_size=(224,224))\n",
    "        x = image.img_to_array(img)\n",
    "        return np.asarray(x)\n",
    "\n",
    "    #Define the model\n",
    "    def create_model(self, ret_model = False):\n",
    "        #Define the DenseNet model\n",
    "        image_model = Sequential()\n",
    "        #The input dim should match the output generated by the last but one layer of the DenseNet model\n",
    "        image_model.add(Dense(EMBEDDING_DIM, input_dim = 1024, activation='relu'))\n",
    "        #Repeat the input depending on the length of the output. We are informing the decoder as to how many times to repeat itself\n",
    "        image_model.add(RepeatVector(self.max_cap_len))\n",
    "\n",
    "        #Define the decoder model\n",
    "        lang_model = Sequential()\n",
    "        lang_model.add(Embedding(self.vocab_size, 256, input_length=self.max_cap_len))\n",
    "        lang_model.add(LSTM(256,return_sequences=True))\n",
    "        #Apply the dense layer to each of the timesteps\n",
    "        lang_model.add(TimeDistributed(Dense(EMBEDDING_DIM)))\n",
    "\n",
    "        #Define the 'Merge' model\n",
    "        model = Sequential()\n",
    "        model.add(Merge([image_model, lang_model], mode='concat'))\n",
    "        model.add(LSTM(1000,return_sequences=False))\n",
    "        model.add(Dense(self.vocab_size))\n",
    "        model.add(Activation('softmax'))\n",
    "\n",
    "        print (\"Model created!\")\n",
    "\n",
    "        if(ret_model==True):\n",
    "            return model\n",
    "\n",
    "        #model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "        optimizer = keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "        lr_metric = get_lr_metric(optimizer)\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer = 'rmsprop', metrics=['accuracy', lr_metric])\n",
    "        return model\n",
    "\n",
    "    def get_word(self,index):\n",
    "        return self.index_word[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def train_model(weight = None, batch_size=32, epochs = 10, initial_epoch = 0):\n",
    "    # create captiongenerator\n",
    "    cg = CaptionGenerator()\n",
    "    # create the model\n",
    "    model = cg.create_model()\n",
    "\n",
    "    #when weight is provided use those\n",
    "    if weight != None:\n",
    "        model.load_weights(weight)\n",
    "\n",
    "    counter = 0\n",
    "    fileid = model.name\n",
    "    logfilename = fileid + \"-log.csv\"\n",
    "    # update the metrics to a file at the end of each epoch \n",
    "    csv_logger = keras.callbacks.CSVLogger(logfilename, separator=',', append=True)\n",
    "\n",
    "    file_name = 'weights-improvement-{epoch:02d}.hdf5'\n",
    "    # interested in monitoring the 'loss' value\n",
    "    checkpoint = ModelCheckpoint(file_name, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "    \n",
    "    # define a variable learning rate scheduler\n",
    "    lr_scheduler = keras.callbacks.LearningRateScheduler(schedule_lr)\n",
    "\n",
    "    # Functions to be called at the end of each epoch\n",
    "    callbacks_list = [checkpoint, csv_logger, lr_scheduler]\n",
    "    #fit the model using a progressive loader\n",
    "    model.fit_generator(cg.data_generator(batch_size=batch_size), initial_epoch=initial_epoch, steps_per_epoch=cg.total_samples/batch_size, epochs=epochs, verbose=1, callbacks=callbacks_list)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        model.save('Models/WholeModel.h5', overwrite=True)\n",
    "        model.save_weights('Models/Weights.h5',overwrite=True)\n",
    "    except:\n",
    "        print (\"Error in saving model.\")\n",
    "    print (\"Training complete...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples : 383454\n",
      "Vocabulary size: 8256\n",
      "Maximum caption length: 40\n",
      "Variables initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:126: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created!\n",
      "Generating data...\n",
      "Epoch 1/10\n",
      "176/176 [==============================] - 267s 2s/step - loss: 5.4758 - acc: 0.0784 - lr: 0.0010\n",
      "\n",
      "Epoch 00001: loss improved from inf to 5.47579, saving model to weights-improvement-01.hdf5\n",
      "Epoch 2/10\n",
      "176/176 [==============================] - 265s 2s/step - loss: 5.0744 - acc: 0.1308 - lr: 0.0010\n",
      "\n",
      "Epoch 00002: loss improved from 5.47579 to 5.07437, saving model to weights-improvement-02.hdf5\n",
      "Epoch 3/10\n",
      "176/176 [==============================] - 265s 2s/step - loss: 4.5493 - acc: 0.2302 - lr: 0.0010\n",
      "\n",
      "Epoch 00003: loss improved from 5.07437 to 4.54932, saving model to weights-improvement-03.hdf5\n",
      "Epoch 4/10\n",
      "176/176 [==============================] - 265s 2s/step - loss: 4.3229 - acc: 0.2518 - lr: 0.0010\n",
      "\n",
      "Epoch 00004: loss improved from 4.54932 to 4.32290, saving model to weights-improvement-04.hdf5\n",
      "Epoch 5/10\n",
      "176/176 [==============================] - 265s 2s/step - loss: 4.0822 - acc: 0.2752 - lr: 0.0010\n",
      "\n",
      "Epoch 00005: loss improved from 4.32290 to 4.08217, saving model to weights-improvement-05.hdf5\n",
      "Epoch 6/10\n",
      "109/176 [=================>............] - ETA: 1:40 - loss: 3.8451 - acc: 0.2998 - lr: 0.0010yielding count: 1000\n",
      "176/176 [==============================] - 265s 2s/step - loss: 3.7921 - acc: 0.3056 - lr: 0.0010\n",
      "\n",
      "Epoch 00006: loss improved from 4.08217 to 3.79212, saving model to weights-improvement-06.hdf5\n",
      "Epoch 7/10\n",
      "176/176 [==============================] - 265s 2s/step - loss: 3.5509 - acc: 0.3277 - lr: 0.0010\n",
      "\n",
      "Epoch 00007: loss improved from 3.79212 to 3.55086, saving model to weights-improvement-07.hdf5\n",
      "Epoch 8/10\n",
      "176/176 [==============================] - 265s 2s/step - loss: 3.3701 - acc: 0.3424 - lr: 0.0010\n",
      "\n",
      "Epoch 00008: loss improved from 3.55086 to 3.37010, saving model to weights-improvement-08.hdf5\n",
      "Epoch 9/10\n",
      "176/176 [==============================] - 265s 2s/step - loss: 3.2187 - acc: 0.3566 - lr: 0.0010\n",
      "\n",
      "Epoch 00009: loss improved from 3.37010 to 3.21866, saving model to weights-improvement-09.hdf5\n",
      "Epoch 10/10\n",
      "176/176 [==============================] - 266s 2s/step - loss: 3.0899 - acc: 0.3675 - lr: 0.0010\n",
      "\n",
      "Epoch 00010: loss improved from 3.21866 to 3.08985, saving model to weights-improvement-10.hdf5\n",
      "Error in saving model.\n",
      "Training complete...\n",
      "\n",
      "('Time taken to train with 50 epochs is ', 30.598837133333337)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.clock()\n",
    "train_model(initial_epoch = 0, epochs=10, batch_size=2176)\n",
    "toc = time.clock()\n",
    "print('Time taken to train with 50 epochs is ', ((toc - tic)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples : 383454\n",
      "Vocabulary size: 8256\n",
      "Maximum caption length: 40\n",
      "Variables initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:126: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created!\n",
      "Generating data...Epoch 11/15\n",
      "\n",
      "176/176 [==============================] - 273s 2s/step - loss: 3.0238 - acc: 0.3772 - lr: 0.0010\n",
      "\n",
      "Epoch 00011: loss improved from inf to 3.02379, saving model to weights-improvement-11.hdf5\n",
      "Epoch 12/15\n",
      "176/176 [==============================] - 270s 2s/step - loss: 2.7621 - acc: 0.4016 - lr: 0.0010\n",
      "\n",
      "Epoch 00012: loss improved from 3.02379 to 2.76205, saving model to weights-improvement-12.hdf5\n",
      "Epoch 13/15\n",
      "176/176 [==============================] - 271s 2s/step - loss: 2.6551 - acc: 0.4128 - lr: 0.0010\n",
      "\n",
      "Epoch 00013: loss improved from 2.76205 to 2.65512, saving model to weights-improvement-13.hdf5\n",
      "Epoch 14/15\n",
      "176/176 [==============================] - 271s 2s/step - loss: 2.5755 - acc: 0.4217 - lr: 0.0010\n",
      "\n",
      "Epoch 00014: loss improved from 2.65512 to 2.57547, saving model to weights-improvement-14.hdf5\n",
      "Epoch 15/15\n",
      "176/176 [==============================] - 270s 2s/step - loss: 2.4990 - acc: 0.4315 - lr: 0.0010\n",
      "\n",
      "Epoch 00015: loss improved from 2.57547 to 2.49902, saving model to weights-improvement-15.hdf5\n",
      "Error in saving model.\n",
      "Training complete...\n",
      "\n",
      "Time taken to train with 5 epochs is 15.43760335 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.clock()\n",
    "initial_epoch = 10\n",
    "epochs=15\n",
    "weight='weights-improvement-10.hdf5'\n",
    "\n",
    "train_model(initial_epoch = initial_epoch, epochs=epochs, batch_size=2176, weight=weight)\n",
    "\n",
    "toc = time.clock()\n",
    "print(\"Time taken to train with \" + str(epochs - initial_epoch) + \" epochs is \" + str(((toc - tic)/60)) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples : 383454\n",
      "Vocabulary size: 8256\n",
      "Maximum caption length: 40\n",
      "Variables initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:126: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created!\n",
      "Generating data...\n",
      "Epoch 16/20\n",
      "176/176 [==============================] - 281s 2s/step - loss: 2.3930 - acc: 0.4466 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 00016: loss improved from inf to 2.39298, saving model to weights-improvement-16.hdf5\n",
      "Epoch 17/20\n",
      "176/176 [==============================] - 276s 2s/step - loss: 2.3919 - acc: 0.4464 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 00017: loss improved from 2.39298 to 2.39190, saving model to weights-improvement-17.hdf5\n",
      "Epoch 18/20\n",
      "176/176 [==============================] - 276s 2s/step - loss: 2.3322 - acc: 0.4537 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 00018: loss improved from 2.39190 to 2.33217, saving model to weights-improvement-18.hdf5\n",
      "Epoch 19/20\n",
      "176/176 [==============================] - 276s 2s/step - loss: 2.2673 - acc: 0.4635 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 00019: loss improved from 2.33217 to 2.26732, saving model to weights-improvement-19.hdf5\n",
      "Epoch 20/20\n",
      "176/176 [==============================] - 275s 2s/step - loss: 2.2103 - acc: 0.4724 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 00020: loss improved from 2.26732 to 2.21030, saving model to weights-improvement-20.hdf5\n",
      "Error in saving model.\n",
      "Training complete...\n",
      "\n",
      "Time taken to train with 5 epochs is 15.53058585 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.clock()\n",
    "initial_epoch = 15\n",
    "epochs=20\n",
    "weight='weights-improvement-15.hdf5'\n",
    "lr = 0.001\n",
    "lr = lr/2\n",
    "\n",
    "train_model(initial_epoch = initial_epoch, epochs=epochs, batch_size=2176, weight=weight)\n",
    "\n",
    "toc = time.clock()\n",
    "print(\"Time taken to train with \" + str(epochs - initial_epoch) + \" epochs is \" + str(((toc - tic)/60)) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples : 383454\n",
      "Vocabulary size: 8256\n",
      "Maximum caption length: 40\n",
      "Variables initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:126: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created!\n",
      "Generating data...Epoch 21/25\n",
      "\n",
      "176/176 [==============================] - 247s 1s/step - loss: 2.0915 - acc: 0.4933 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 00021: loss improved from inf to 2.09154, saving model to weights-improvement-21.hdf5\n",
      "Epoch 22/25\n",
      "176/176 [==============================] - 243s 1s/step - loss: 2.0182 - acc: 0.5068 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 00022: loss improved from 2.09154 to 2.01820, saving model to weights-improvement-22.hdf5\n",
      "Epoch 23/25\n",
      "176/176 [==============================] - 242s 1s/step - loss: 1.9662 - acc: 0.5169 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 00023: loss improved from 2.01820 to 1.96618, saving model to weights-improvement-23.hdf5\n",
      "Epoch 24/25\n",
      "176/176 [==============================] - 244s 1s/step - loss: 1.9159 - acc: 0.5274 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 00024: loss improved from 1.96618 to 1.91589, saving model to weights-improvement-24.hdf5\n",
      "Epoch 25/25\n",
      "176/176 [==============================] - 243s 1s/step - loss: 1.9126 - acc: 0.5278 - lr: 5.0000e-04\n",
      "\n",
      "Epoch 00025: loss improved from 1.91589 to 1.91262, saving model to weights-improvement-25.hdf5\n",
      "Error in saving model.\n",
      "Training complete...\n",
      "\n",
      "Time taken to train with 5 epochs is 16.8826267667 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.clock()\n",
    "initial_epoch = 20\n",
    "epochs=25\n",
    "weight='weights-improvement-20.hdf5'\n",
    "lr = 0.001\n",
    "lr = lr/2\n",
    "\n",
    "train_model(initial_epoch = initial_epoch, epochs=epochs, batch_size=2176, weight=weight)\n",
    "\n",
    "toc = time.clock()\n",
    "print(\"Time taken to train with \" + str(epochs - initial_epoch) + \" epochs is \" + str(((toc - tic)/60)) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples : 383454\n",
      "Vocabulary size: 8256\n",
      "Maximum caption length: 40\n",
      "Variables initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:126: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created!\n",
      "Generating data...\n",
      "Epoch 26/30\n",
      "176/176 [==============================] - 260s 1s/step - loss: 1.8719 - acc: 0.5373 - lr: 0.0010\n",
      "\n",
      "Epoch 00026: loss improved from inf to 1.87186, saving model to weights-improvement-26.hdf5\n",
      "Epoch 27/30\n",
      "176/176 [==============================] - 256s 1s/step - loss: 1.8166 - acc: 0.5479 - lr: 0.0010\n",
      "\n",
      "Epoch 00027: loss improved from 1.87186 to 1.81656, saving model to weights-improvement-27.hdf5\n",
      "Epoch 28/30\n",
      "176/176 [==============================] - 256s 1s/step - loss: 1.7724 - acc: 0.5569 - lr: 0.0010\n",
      "\n",
      "Epoch 00028: loss improved from 1.81656 to 1.77244, saving model to weights-improvement-28.hdf5\n",
      "Epoch 29/30\n",
      "176/176 [==============================] - 256s 1s/step - loss: 1.7114 - acc: 0.5705 - lr: 0.0010\n",
      "\n",
      "Epoch 00029: loss improved from 1.77244 to 1.71143, saving model to weights-improvement-29.hdf5\n",
      "Epoch 30/30\n",
      "176/176 [==============================] - 256s 1s/step - loss: 1.6703 - acc: 0.5800 - lr: 0.0010\n",
      "\n",
      "Epoch 00030: loss improved from 1.71143 to 1.67026, saving model to weights-improvement-30.hdf5\n",
      "Error in saving model.\n",
      "Training complete...\n",
      "\n",
      "Time taken to train with 5 epochs is 15.82796535 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.clock()\n",
    "initial_epoch = 25\n",
    "epochs=30\n",
    "weight='weights-improvement-25.hdf5'\n",
    "lr = 0.001\n",
    "#lr = lr/4\n",
    "\n",
    "train_model(initial_epoch = initial_epoch, epochs=epochs, batch_size=2176, weight=weight)\n",
    "\n",
    "toc = time.clock()\n",
    "print(\"Time taken to train with \" + str(epochs - initial_epoch) + \" epochs is \" + str(((toc - tic)/60)) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples : 383454\n",
      "Vocabulary size: 8256\n",
      "Maximum caption length: 40\n",
      "Variables initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:126: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created!\n",
      "Epoch 31/35\n",
      "Generating data...\n",
      "176/176 [==============================] - 281s 2s/step - loss: 1.6470 - acc: 0.5857 - lr: 0.0010\n",
      "\n",
      "Epoch 00031: loss improved from inf to 1.64701, saving model to weights-improvement-31.hdf5\n",
      "Epoch 32/35\n",
      "176/176 [==============================] - 275s 2s/step - loss: 1.6081 - acc: 0.5947 - lr: 0.0010\n",
      "\n",
      "Epoch 00032: loss improved from 1.64701 to 1.60813, saving model to weights-improvement-32.hdf5\n",
      "Epoch 33/35\n",
      "176/176 [==============================] - 275s 2s/step - loss: 1.5945 - acc: 0.5976 - lr: 0.0010\n",
      "\n",
      "Epoch 00033: loss improved from 1.60813 to 1.59445, saving model to weights-improvement-33.hdf5\n",
      "Epoch 34/35\n",
      "176/176 [==============================] - 275s 2s/step - loss: 1.5689 - acc: 0.6040 - lr: 0.0010\n",
      "\n",
      "Epoch 00034: loss improved from 1.59445 to 1.56893, saving model to weights-improvement-34.hdf5\n",
      "Epoch 35/35\n",
      "176/176 [==============================] - 275s 2s/step - loss: 1.5397 - acc: 0.6107 - lr: 0.0010\n",
      "\n",
      "Epoch 00035: loss improved from 1.56893 to 1.53968, saving model to weights-improvement-35.hdf5\n",
      "Error in saving model.\n",
      "Training complete...\n",
      "\n",
      "Time taken to train with 5 epochs is 15.39327855 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.clock()\n",
    "initial_epoch = 30\n",
    "epochs=35\n",
    "weight='weights-improvement-30.hdf5'\n",
    "lr = 0.001\n",
    "#lr = lr/3\n",
    "# tried with 0.001 it was hovering below 0.59\n",
    "#Tried wit lr/2 the accuracy went down by 3 basis points during the first epoch\n",
    "# trying with 0.002\n",
    "train_model(initial_epoch = initial_epoch, epochs=epochs, batch_size=2176, weight=weight)\n",
    "\n",
    "toc = time.clock()\n",
    "print(\"Time taken to train with \" + str(epochs - initial_epoch) + \" epochs is \" + str(((toc - tic)/60)) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples : 383454\n",
      "Vocabulary size: 8256\n",
      "Maximum caption length: 40\n",
      "Variables initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:126: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created!\n",
      "Generating data...\n",
      "Epoch 36/40\n",
      "176/176 [==============================] - 249s 1s/step - loss: 1.5225 - acc: 0.6154 - lr: 0.0010\n",
      "\n",
      "Epoch 00036: loss improved from inf to 1.52246, saving model to weights-improvement-36.hdf5\n",
      "Epoch 37/40\n",
      "176/176 [==============================] - 245s 1s/step - loss: 1.5374 - acc: 0.6113 - lr: 0.0010\n",
      "\n",
      "Epoch 00037: loss did not improve\n",
      "Epoch 38/40\n",
      "176/176 [==============================] - 245s 1s/step - loss: 1.5178 - acc: 0.6164 - lr: 0.0010\n",
      "\n",
      "Epoch 00038: loss improved from 1.52246 to 1.51777, saving model to weights-improvement-38.hdf5\n",
      "Epoch 39/40\n",
      "176/176 [==============================] - 245s 1s/step - loss: 1.4968 - acc: 0.6222 - lr: 0.0010\n",
      "\n",
      "Epoch 00039: loss improved from 1.51777 to 1.49675, saving model to weights-improvement-39.hdf5\n",
      "Epoch 40/40\n",
      "176/176 [==============================] - 245s 1s/step - loss: 1.4773 - acc: 0.6268 - lr: 0.0010\n",
      "\n",
      "Epoch 00040: loss improved from 1.49675 to 1.47725, saving model to weights-improvement-40.hdf5\n",
      "Error in saving model.\n",
      "Training complete...\n",
      "\n",
      "Time taken to train with 5 epochs is 16.4409871667 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.clock()\n",
    "initial_epoch = 35\n",
    "epochs=40\n",
    "weight='weights-improvement-35.hdf5'\n",
    "lr = 0.001\n",
    "#lr = lr/2\n",
    "train_model(initial_epoch = initial_epoch, epochs=epochs, batch_size=2176, weight=weight)\n",
    "\n",
    "toc = time.clock()\n",
    "print(\"Time taken to train with \" + str(epochs - initial_epoch) + \" epochs is \" + str(((toc - tic)/60)) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples : 383454\n",
      "Vocabulary size: 8256\n",
      "Maximum caption length: 40\n",
      "Variables initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:126: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created!\n",
      "Generating data...\n",
      "Epoch 41/45\n",
      "176/176 [==============================] - 260s 1s/step - loss: 1.4712 - acc: 0.6268 - lr: 0.0020\n",
      "\n",
      "Epoch 00041: loss improved from inf to 1.47117, saving model to weights-improvement-41.hdf5\n",
      "Epoch 42/45\n",
      "176/176 [==============================] - 257s 1s/step - loss: 1.4372 - acc: 0.6348 - lr: 0.0020\n",
      "\n",
      "Epoch 00042: loss improved from 1.47117 to 1.43716, saving model to weights-improvement-42.hdf5\n",
      "Epoch 43/45\n",
      "176/176 [==============================] - 256s 1s/step - loss: 1.3959 - acc: 0.6452 - lr: 0.0020\n",
      "\n",
      "Epoch 00043: loss improved from 1.43716 to 1.39589, saving model to weights-improvement-43.hdf5\n",
      "Epoch 44/45\n",
      "176/176 [==============================] - 256s 1s/step - loss: 1.3689 - acc: 0.6523 - lr: 0.0020\n",
      "\n",
      "Epoch 00044: loss improved from 1.39589 to 1.36893, saving model to weights-improvement-44.hdf5\n",
      "Epoch 45/45\n",
      "176/176 [==============================] - 257s 1s/step - loss: 1.3385 - acc: 0.6603 - lr: 0.0020\n",
      "\n",
      "Epoch 00045: loss improved from 1.36893 to 1.33845, saving model to weights-improvement-45.hdf5\n",
      "Error in saving model.\n",
      "Training complete...\n",
      "\n",
      "Time taken to train with 5 epochs is 15.7627675833 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.clock()\n",
    "initial_epoch = 40\n",
    "epochs=45\n",
    "weight='weights-improvement-40.hdf5'\n",
    "lr = 0.001\n",
    "lr = lr * 2\n",
    "train_model(initial_epoch = initial_epoch, epochs=epochs, batch_size=2176, weight=weight)\n",
    "\n",
    "toc = time.clock()\n",
    "print(\"Time taken to train with \" + str(epochs - initial_epoch) + \" epochs is \" + str(((toc - tic)/60)) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples : 383454\n",
      "Vocabulary size: 8256\n",
      "Maximum caption length: 40\n",
      "Variables initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:126: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created!\n",
      "Generating data...Epoch 46/50\n",
      "\n",
      "176/176 [==============================] - 268s 2s/step - loss: 1.3247 - acc: 0.6643 - lr: 0.0020\n",
      "\n",
      "Epoch 00046: loss improved from inf to 1.32470, saving model to weights-improvement-46.hdf5\n",
      "Epoch 47/50\n",
      "176/176 [==============================] - 264s 2s/step - loss: 1.2971 - acc: 0.6714 - lr: 0.0020\n",
      "\n",
      "Epoch 00047: loss improved from 1.32470 to 1.29706, saving model to weights-improvement-47.hdf5\n",
      "Epoch 48/50\n",
      "176/176 [==============================] - 264s 1s/step - loss: 1.2772 - acc: 0.6767 - lr: 0.0020\n",
      "\n",
      "Epoch 00048: loss improved from 1.29706 to 1.27719, saving model to weights-improvement-48.hdf5\n",
      "Epoch 49/50\n",
      "176/176 [==============================] - 264s 2s/step - loss: 1.2647 - acc: 0.6797 - lr: 0.0020\n",
      "\n",
      "Epoch 00049: loss improved from 1.27719 to 1.26466, saving model to weights-improvement-49.hdf5\n",
      "Epoch 50/50\n",
      "176/176 [==============================] - 264s 2s/step - loss: 1.2483 - acc: 0.6835 - lr: 0.0020\n",
      "\n",
      "Epoch 00050: loss improved from 1.26466 to 1.24835, saving model to weights-improvement-50.hdf5\n",
      "Error in saving model.\n",
      "Training complete...\n",
      "\n",
      "Time taken to train with 5 epochs is 15.6972003667 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.clock()\n",
    "initial_epoch = 45\n",
    "epochs = 50\n",
    "weight='weights-improvement-45.hdf5'\n",
    "lr = 0.001\n",
    "lr = lr * 2\n",
    "train_model(initial_epoch = initial_epoch, epochs=epochs, batch_size=2176, weight=weight)\n",
    "\n",
    "toc = time.clock()\n",
    "print(\"Time taken to train with \" + str(epochs - initial_epoch) + \" epochs is \" + str(((toc - tic)/60)) + \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples : 383454\n",
      "Vocabulary size: 8256\n",
      "Maximum caption length: 40\n",
      "Variables initialization done!\n"
     ]
    }
   ],
   "source": [
    "import pickle as pickle\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "import nltk\n",
    "\n",
    "cg = CaptionGenerator()\n",
    "\n",
    "def process_caption(caption):\n",
    "\tcaption_split = caption.split()\n",
    "\tprocessed_caption = caption_split[1:]\n",
    "\ttry:\n",
    "\t\tend_index = processed_caption.index('<end>')\n",
    "\t\tprocessed_caption = processed_caption[:end_index]\n",
    "\texcept:\n",
    "\t\tpass\n",
    "\treturn \" \".join([word for word in processed_caption])\n",
    "\n",
    "def get_best_caption(captions):\n",
    "    captions.sort(key = lambda l:l[1])\n",
    "    best_caption = captions[-1][0]\n",
    "    return \" \".join([cg.index_word[index] for index in best_caption])\n",
    "\n",
    "def get_all_captions(captions):\n",
    "    final_captions = []\n",
    "    captions.sort(key = lambda l:l[1])\n",
    "    for caption in captions:\n",
    "        text_caption = \" \".join([cg.index_word[index] for index in caption[0]])\n",
    "        final_captions.append([text_caption, caption[1]])\n",
    "    return final_captions\n",
    "\n",
    "def generate_captions(model, image, beam_size):\n",
    "\tstart = [cg.word_index['<start>']]\n",
    "\tcaptions = [[start,0.0]]\n",
    "\twhile(len(captions[0][0]) < cg.max_cap_len):\n",
    "\t\ttemp_captions = []\n",
    "\t\tfor caption in captions:\n",
    "\t\t\tpartial_caption = sequence.pad_sequences([caption[0]], maxlen=cg.max_cap_len, padding='post')\n",
    "\t\t\tnext_words_pred = model.predict([np.asarray([image]), np.asarray(partial_caption)])[0]\n",
    "\t\t\tnext_words = np.argsort(next_words_pred)[-beam_size:]\n",
    "\t\t\tfor word in next_words:\n",
    "\t\t\t\tnew_partial_caption, new_partial_caption_prob = caption[0][:], caption[1]\n",
    "\t\t\t\tnew_partial_caption.append(word)\n",
    "\t\t\t\tnew_partial_caption_prob+=next_words_pred[word]\n",
    "\t\t\t\ttemp_captions.append([new_partial_caption,new_partial_caption_prob])\n",
    "\t\tcaptions = temp_captions\n",
    "\t\tcaptions.sort(key = lambda l:l[1])\n",
    "\t\tcaptions = captions[-beam_size:]\n",
    "\n",
    "\treturn captions\n",
    "\n",
    "def test_model(weight, img_name, beam_size = 3):\n",
    "\tencoded_images = pickle.load( open( \"encoded_images.p\", \"rb\" ) )\n",
    "\tmodel = cg.create_model(ret_model = True)\n",
    "\tmodel.load_weights(weight)\n",
    "\n",
    "\timage = encoded_images[img_name]\n",
    "\tcaptions = generate_captions(model, image, beam_size)\n",
    "\treturn process_caption(get_best_caption(captions))\n",
    "\t#return [process_caption(caption[0]) for caption in get_all_captions(captions)] \n",
    "\n",
    "def bleu_score(hypotheses, references):\n",
    "\treturn nltk.translate.bleu_score.corpus_bleu(references, hypotheses)\n",
    "\n",
    "def test_model_on_images(weight, img_dir, beam_size = 3):\n",
    "\timgs = []\n",
    "\tcaptions = {}\n",
    "\twith open(img_dir, 'rb') as f_images:\n",
    "\t\timgs = f_images.read().strip().split('\\n')\n",
    "\tencoded_images = pickle.load( open( \"encoded_images.p\", \"rb\" ) )\n",
    "\tmodel = cg.create_model(ret_model = True)\n",
    "\tmodel.load_weights(weight)\n",
    "\n",
    "\tf_pred_caption = open('predicted_captions.txt', 'wb')\n",
    "\n",
    "\tfor count, img_name in enumerate(imgs):\n",
    "\t\tprint (\"Predicting for image: \"+str(count))\n",
    "\t\timage = encoded_images[img_name]\n",
    "\t\timage_captions = generate_captions(model, image, beam_size)\n",
    "\t\tbest_caption = process_caption(get_best_caption(image_captions))\n",
    "\t\tcaptions[img_name] = best_caption\n",
    "\t\tprint (img_name+\" : \"+str(best_caption))\n",
    "\t\tf_pred_caption.write(img_name+\"\\t\"+str(best_caption))\n",
    "\t\tf_pred_caption.flush()\n",
    "\tf_pred_caption.close()\n",
    "\n",
    "\tf_captions = open('Flickr8k_text/Flickr8k.token.txt', 'rb')\n",
    "\tcaptions_text = f_captions.read().strip().split('\\n')\n",
    "\timage_captions_pair = {}\n",
    "\tfor row in captions_text:\n",
    "\t\trow = row.split(\"\\t\")\n",
    "\t\trow[0] = row[0][:len(row[0])-2]\n",
    "\t\ttry:\n",
    "\t\t\timage_captions_pair[row[0]].append(row[1])\n",
    "\t\texcept:\n",
    "\t\t\timage_captions_pair[row[0]] = [row[1]]\n",
    "\tf_captions.close()\n",
    "\t\n",
    "\thypotheses=[]\n",
    "\treferences = []\n",
    "\tfor img_name in imgs:\n",
    "\t\thypothesis = captions[img_name]\n",
    "\t\treference = image_captions_pair[img_name]\n",
    "\t\thypotheses.append(hypothesis)\n",
    "\t\treferences.append(reference)\n",
    "\n",
    "\treturn bleu_score(hypotheses, references)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:126: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created!\n",
      "Predicting for image: 0\n",
      "3385593926_d3e9c21170.jpg : A group of people on a beach .\n",
      "Predicting for image: 1\n",
      "2677656448_6b7e7702af.jpg : A child in a blue suit in a pool .\n",
      "Predicting for image: 2\n",
      "311146855_0b65fdb169.jpg : A man in a yellow shirt is sitting on a yellow couch .\n",
      "Predicting for image: 3\n",
      "1258913059_07c613f7ff.jpg : A woman is sitting on a railing with a firetruck .\n",
      "Predicting for image: 4\n",
      "241347760_d44c8d3a01.jpg : A girl in a red uniform is running with a football .\n",
      "Predicting for image: 5\n",
      "2654514044_a70a6e2c21.jpg : Two dogs playing in the grass .\n",
      "Predicting for image: 6\n",
      "2339106348_2df90aa6a9.jpg : A woman in a white shirt is staring at a woman .\n",
      "Predicting for image: 7\n",
      "256085101_2c2617c5d0.jpg : A dog playing with a stuffed ball .\n",
      "Predicting for image: 8\n",
      "280706862_14c30d734a.jpg : A small brown dog is standing in the dirt .\n",
      "Predicting for image: 9\n",
      "3072172967_630e9c69d0.jpg : A group of men in white uniforms .\n",
      "Predicting for image: 10\n",
      "3482062809_3b694322c4.jpg : A man and woman are walking down the street .\n",
      "Predicting for image: 11\n",
      "1167669558_87a8a467d6.jpg : A girl with a red hat is holding a blue toy .\n",
      "Predicting for image: 12\n",
      "2847615962_c330bded6e.jpg : A young girl in a green dress is holding a book in front of a fence .\n",
      "Predicting for image: 13\n",
      "3344233740_c010378da7.jpg : A black and white dog is sitting on a crosswalk on a crosswalk .\n",
      "Predicting for image: 14\n",
      "2435685480_a79d42e564.jpg : A person performing a trick on a skateboard .\n",
      "Predicting for image: 15\n",
      "3110649716_c17e14670e.jpg : A man in a red jacket is smiling while another is smiling .\n",
      "Predicting for image: 16\n",
      "2511019188_ca71775f2d.jpg : Two dogs are playing with a white and white dog .\n",
      "Predicting for image: 17\n",
      "2521770311_3086ca90de.jpg : A young girl with a blue shirt is sitting on a back of stairs .\n",
      "Predicting for image: 18\n",
      "2723477522_d89f5ac62b.jpg : A group of people in a field .\n",
      "Predicting for image: 19\n",
      "2218609886_892dcd6915.jpg : A young girl in a yellow jacket is smiling .\n",
      "Predicting for image: 20\n",
      "3745451546_fc8ec70cbd.jpg : A little boy plays in the pool .\n",
      "Predicting for image: 21\n",
      "2844018783_524b08e5aa.jpg : A girl and a woman are standing next to a fence in front of a building .\n",
      "Predicting for image: 22\n",
      "3100251515_c68027cc22.jpg : Many people are standing on a bench with a lot of rack .\n",
      "Predicting for image: 23\n",
      "2207244634_1db1a1890b.jpg : A man in a green shirt is playing tennis .\n",
      "Predicting for image: 24\n",
      "2943023421_e297f05e11.jpg : A man wearing a red shirt and a red jacket is standing on a handrail .\n",
      "Predicting for image: 25\n",
      "3286822339_5535af6b93.jpg : A man in a red jacket is standing in front of a crowd .\n",
      "Predicting for image: 26\n",
      "2479652566_8f9fac8af5.jpg : A man and a woman sit on a dirt wall .\n",
      "Predicting for image: 27\n",
      "1394368714_3bc7c19969.jpg : A woman and a woman are sitting on a rock .\n",
      "Predicting for image: 28\n",
      "872622575_ba1d3632cc.jpg : A group of men on a mountain .\n",
      "Predicting for image: 29\n",
      "2309860995_c2e2a0feeb.jpg : A man wearing a black shirt and a black shirt is smiling .\n",
      "Predicting for image: 30\n",
      "241347204_007d83e252.jpg : A girl in a red uniform is running with a red bag .\n",
      "Predicting for image: 31\n",
      "3502343542_f9b46688e5.jpg : A person wearing a backpack is riding a mountain .\n",
      "Predicting for image: 32\n",
      "757332692_6866ae545c.jpg : A brown dog looking at a stuffed blanket .\n",
      "Predicting for image: 33\n",
      "2748729903_3c7c920c4d.jpg : A man in a green jacket is walking along a pond .\n",
      "Predicting for image: 34\n",
      "494792770_2c5f767ac0.jpg : A brown dog is holding a stick in its mouth .\n",
      "Predicting for image: 35\n",
      "3213992947_3f3f967a9f.jpg : A girl in red plays in the ocean .\n",
      "Predicting for image: 36\n",
      "2295750198_6d152d7ceb.jpg : A dog is running through a park .\n",
      "Predicting for image: 37\n",
      "2358898017_24496b80e8.jpg : A brown dog is running through green grass .\n",
      "Predicting for image: 38\n",
      "3222055946_45f7293bb2.jpg : A girl in a red jacket is jumping over a skateboard .\n",
      "Predicting for image: 39\n",
      "444481722_690d0cadcf.jpg : A person in a black and black shirt is standing in the air on a pole .\n",
      "Predicting for image: 40\n",
      "2647049174_0fb47cee2e.jpg : A young girl in a red t-shirt is standing on a red brick ledge .\n",
      "Predicting for image: 41\n",
      "1174629344_a2e1a2bdbf.jpg : A group of girls are walking down the street .\n",
      "Predicting for image: 42\n",
      "2921094201_2ed70a7963.jpg : A young girl wearing a white shirt is staring at a hospital wall .\n",
      "Predicting for image: 43\n",
      "2553550034_5901aa9d6c.jpg : A child with a red shirt and red helmet plays on a rock .\n",
      "Predicting for image: 44\n",
      "3045613316_4e88862836.jpg : A boy is jumping on a dirt ramp .\n",
      "Predicting for image: 45\n",
      "2706766641_a9df81969d.jpg : A man is standing on a wood wall with her arms out .\n",
      "Predicting for image: 46\n",
      "510531976_90bbee22a2.jpg : A young boy does a trick on his skateboard .\n",
      "Predicting for image: 47\n",
      "485245061_5a5de43e20.jpg : A group of people are shown in the snow .\n",
      "Predicting for image: 48\n",
      "3070011270_390e597783.jpg : A black dog is jumping through the water .\n",
      "Predicting for image: 49\n",
      "1352410176_af6b139734.jpg : A little boy plays in a body of water .\n",
      "Predicting for image: 50\n",
      "1131932671_c8d17751b3.jpg : A young girl wearing a white shirt and brown shorts is jumping in the water .\n",
      "Predicting for image: 51\n",
      "3155451946_c0862c70cb.jpg : A group of people in a match .\n",
      "Predicting for image: 52\n",
      "2762301555_48a0d0aa24.jpg : A boy in a bathing suit is playing with a green umbrella .\n",
      "Predicting for image: 53\n",
      "3442242092_e579538d82.jpg : A man in a black coat holding a sign in a city .\n",
      "Predicting for image: 54\n",
      "2415803492_56a673dc25.jpg : A man in blue shorts is climbing on a bench .\n",
      "Predicting for image: 55\n",
      "2884301336_dc8e974431.jpg : A young boy in a blue shirt is playing in a pool of water .\n",
      "Predicting for image: 56\n",
      "3453259666_9ecaa8bb4b.jpg : A little boy in a striped shirt is playing with a water tripod .\n",
      "Predicting for image: 57\n",
      "3016606751_0e8be20abd.jpg : A man climbs up a rock face .\n",
      "Predicting for image: 58\n",
      "3642220260_3aa8a52670.jpg : Two dogs are running through the water .\n",
      "Predicting for image: 59\n",
      "2612488996_9450de0e54.jpg : A basketball player in the red shirt is running .\n",
      "Predicting for image: 60\n",
      "1499581619_a5f65a882c.jpg : A man in a black shirt is standing in front of a man in a red shirt .\n",
      "Predicting for image: 61\n",
      "1427391496_ea512cbe7f.jpg : A man with a red coat is sleeping in front of a white brick wall .\n",
      "Predicting for image: 62\n",
      "3601843201_4809e66909.jpg : A motorcyclist is being ridden on a racetrack .\n",
      "Predicting for image: 63\n",
      "3584561689_b6eb24dd70.jpg : a man jumps off a ramp .\n",
      "Predicting for image: 64\n",
      "138718600_f430ebca17.jpg : A woman in a pink dress is going down a bench .\n",
      "Predicting for image: 65\n",
      "3220126881_b0a4f7cccb.jpg : A little girl in a black shirt runs along a beach\n",
      "Predicting for image: 66\n",
      "300314926_0b2e4b64f5.jpg : A yellow dog makes a trick .\n",
      "Predicting for image: 67\n",
      "3128164023_ebe8da4c32.jpg : A man in a yellow shirt is sitting in a pool .\n",
      "Predicting for image: 68\n",
      "324208502_674488bcea.jpg : A group of people are waiting to cross the street .\n",
      "Predicting for image: 69\n",
      "3647750811_395fbd397e.jpg : A black and white dog is playing with a black and white dog .\n",
      "Predicting for image: 70\n",
      "3458211052_bb73084398.jpg : A child in a red shirt is sitting on a river near a lake .\n",
      "Predicting for image: 71\n",
      "2414397449_2ac3b78e0d.jpg : A brown and white dog in the snow .\n",
      "Predicting for image: 72\n",
      "3085226474_62aba51179.jpg : A man in a yellow shirt is sitting on a track .\n",
      "Predicting for image: 73\n",
      "968081289_cdba83ce2e.jpg : A man and a dog on the beach .\n",
      "Predicting for image: 74\n",
      "2436081047_bca044c1d3.jpg : A man holds a child in the middle of a playground .\n",
      "Predicting for image: 75\n",
      "2813992915_f732cf8539.jpg : Two people sit on a dock in front of a water bench .\n",
      "Predicting for image: 76\n",
      "3627011534_485f667b10.jpg : A man in a yellow sweater is laughing .\n",
      "Predicting for image: 77\n",
      "3214237686_6566b8b52f.jpg : A person is skiing down a snowy hill .\n",
      "Predicting for image: 78\n",
      "1248940539_46d33ed487.jpg : A brown dog is running in a lake .\n",
      "Predicting for image: 79\n",
      "2064790732_219e52e19c.jpg : A man in a red uniform swings against a shot during a rival player .\n",
      "Predicting for image: 80\n",
      "544576742_283b65fa0d.jpg : A boy does a trick on a unicycle .\n",
      "Predicting for image: 81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2731171552_4a808c7d5a.jpg : A young boy in a red shirt is running around in a red car .\n",
      "Predicting for image: 82\n",
      "3609032038_005c789f64.jpg : A man on a skateboard is jumping over a hill .\n",
      "Predicting for image: 83\n",
      "3119875880_22f9129a1c.jpg : A man on a white haired rock on a white wall .\n",
      "Predicting for image: 84\n",
      "3339140382_2e49bc324a.jpg : A person in midair performing a trick off a ramp .\n",
      "Predicting for image: 85\n",
      "2712787899_d85048eb6a.jpg : The little girl is holding a ball .\n",
      "Predicting for image: 86\n",
      "3655155990_b0e201dd3c.jpg : A black dog walks in the ocean .\n",
      "Predicting for image: 87\n",
      "3325497914_f9014d615b.jpg : A group of men wearing swim trunks run along a city street .\n",
      "Predicting for image: 88\n",
      "468310111_d9396abcbd.jpg : A black and white and white dog running through a grassy field .\n",
      "Predicting for image: 89\n",
      "747921928_48eb02aab2.jpg : A skateboarder in a onstage .\n",
      "Predicting for image: 90\n",
      "3639967449_137f48b43d.jpg : A group of people are looking at the camera .\n",
      "Predicting for image: 91\n",
      "2374652725_32f90fa15c.jpg : Three dogs are playing in the snow .\n",
      "Predicting for image: 92\n",
      "3363750526_efcedc47a9.jpg : A little boy is in the air with a toy in his mouth .\n",
      "Predicting for image: 93\n",
      "2689001252_e0016c89f0.jpg : A young girl jumping off a wall .\n",
      "Predicting for image: 94\n",
      "3154641421_d1b9b8c24c.jpg : The basketball player in the orange jersey is trying to get the ball .\n",
      "Predicting for image: 95\n",
      "2631300484_be8621d17b.jpg : A woman in a green shirt and helmet is sitting on a sidewalk with a young girl .\n",
      "Predicting for image: 96\n",
      "3677318686_b018862bb7.jpg : A young boy in a pink shirt and blue shirt is running through the grass .\n",
      "Predicting for image: 97\n",
      "405615014_03be7ef618.jpg : A baseball player is hitting the ball .\n",
      "Predicting for image: 98\n",
      "533979933_a95b03323b.jpg : A boy is running on the beach .\n",
      "Predicting for image: 99\n",
      "3437654963_c4fdc17e8b.jpg : A black and white dog is playing with a toy in its mouth .\n",
      "Predicting for image: 100\n",
      "3462454965_a481809cea.jpg : A brown dog and a white dog are standing in a field .\n",
      "Predicting for image: 101\n",
      "2256133102_e2c8314ecb.jpg : A man and a white dog are standing on the water .\n",
      "Predicting for image: 102\n",
      "3186412658_2ab2ebd397.jpg : A group of people are playing a game .\n",
      "Predicting for image: 103\n",
      "3554634863_5f6f616639.jpg : A group of people are in front of a group of people in a crowd .\n",
      "Predicting for image: 104\n",
      "3223055565_68973f5d20.jpg : A group of people are standing on a snowy mountain .\n",
      "Predicting for image: 105\n",
      "1554713437_61b64527dd.jpg : A brown dog is playing with a white dog in the grass .\n",
      "Predicting for image: 106\n",
      "3150742439_b8a352e1e0.jpg : A man wearing a black shirt and hat and a white hat walks down the sidewalk .\n",
      "Predicting for image: 107\n",
      "2238019823_79318d1f11.jpg : A person on a surfboard coming into the water .\n",
      "Predicting for image: 108\n",
      "3484832904_08619300d9.jpg : A little girl is scaling a rock .\n",
      "Predicting for image: 109\n",
      "3365783912_e12c3510d8.jpg : A group of people are doing tricks on a snowy mountain .\n",
      "Predicting for image: 110\n",
      "3185409663_95f6b958d8.jpg : A black dog is running in the middle of the snow .\n",
      "Predicting for image: 111\n",
      "3207358897_bfa61fa3c6.jpg : Two people sit on a bench in a competition .\n",
      "Predicting for image: 112\n",
      "3263497678_8bb688ca01.jpg : A dog jumps over a hurdle .\n",
      "Predicting for image: 113\n",
      "1897025969_0c41688fa6.jpg : A man with a striped shirt is playing in the snow .\n",
      "Predicting for image: 114\n",
      "3657016761_d553e514d9.jpg : A black and white dog is playing with a red ball .\n",
      "Predicting for image: 115\n",
      "3537400880_8f410d747d.jpg : A brown dog jumps over a branch in the water .\n",
      "Predicting for image: 116\n",
      "2419221084_01a14176b4.jpg : A man is coming through the water next to a wave .\n",
      "Predicting for image: 117\n",
      "172097782_f0844ec317.jpg : A boy in a pink shirt is jumping in the water .\n",
      "Predicting for image: 118\n",
      "244571201_0339d8e8d1.jpg : Two children are in front of a building .\n",
      "Predicting for image: 119\n",
      "3467219837_7d62213dec.jpg : A man in a yellow shirt is riding a ball in a pool of water .\n",
      "Predicting for image: 120\n",
      "2928152792_b16c73434a.jpg : A man wearing black is jumping in the air on a skateboard .\n",
      "Predicting for image: 121\n",
      "401079494_562454c4d6.jpg : A white dog and a brown dog are playing with a soccer ball in the grass .\n",
      "Predicting for image: 122\n",
      "2396691909_6b8c2f7c44.jpg : A boy in a darkened suit plays with a microphone .\n",
      "Predicting for image: 123\n",
      "3243588540_b418ac7eda.jpg : A woman is holding a picture of a child .\n",
      "Predicting for image: 124\n",
      "3592992234_6d3fe58a70.jpg : A boy stands on a river watch a tree .\n",
      "Predicting for image: 125\n",
      "1417031097_ab656bc4bd.jpg : A group of people sitting in front of a small building .\n",
      "Predicting for image: 126\n",
      "1122944218_8eb3607403.jpg : A brown and white dog is holding a red ball in front of its mouth .\n",
      "Predicting for image: 127\n",
      "3149919755_f9272b10b3.jpg : There is a man in a skateboard trick in a skate park .\n",
      "Predicting for image: 128\n",
      "2682382530_f9f8fd1e89.jpg : A young boy does a trick on a rail .\n",
      "Predicting for image: 129\n",
      "2453971388_76616b6a82.jpg : A person doing a trick on a pool .\n",
      "Predicting for image: 130\n",
      "3079787482_0757e9d167.jpg : A brown and brown dog is holding a black shirt .\n",
      "Predicting for image: 131\n",
      "2900274587_f2cbca4c58.jpg : A little girl in a yellow shirt Dogs in the air .\n",
      "Predicting for image: 132\n",
      "3301859683_2d5e4b40a3.jpg : A skier in a red jacket is skiing in the snow .\n",
      "Predicting for image: 133\n",
      "1287073593_f3d2a62455.jpg : A man in a grey jacket is standing in front of a beach .\n",
      "Predicting for image: 134\n",
      "2718495608_d8533e3ac5.jpg : Two dogs are smiling .\n",
      "Predicting for image: 135\n",
      "2054869561_ff723e9eab.jpg : A child in a red shirt is sliding down a red and red toy .\n",
      "Predicting for image: 136\n",
      "3567061016_62768dcce1.jpg : A young boy with a striped shirt is riding a green ball .\n",
      "Predicting for image: 137\n",
      "3221036999_3f7b152d8a.jpg : A boy in a green shirt is racing in a park .\n",
      "Predicting for image: 138\n",
      "2554081584_233bdf289a.jpg : A young boy wearing a grey top is standing on the floor .\n",
      "Predicting for image: 139\n",
      "3250695024_93e8ab7305.jpg : A man and a woman are standing behind a group of women .\n",
      "Predicting for image: 140\n",
      "3630332976_fdba22c50b.jpg : A young girl wearing a red shirt is holding a lot of flowers .\n",
      "Predicting for image: 141\n",
      "2902269566_419d9f1d8e.jpg : A man is riding a swing .\n",
      "Predicting for image: 142\n",
      "2544182005_3aa1332bf9.jpg : A young boy is standing in the snow in the snow .\n",
      "Predicting for image: 143\n",
      "2999730677_0cfa1c146e.jpg : A white dog is jumping over a pile of leaves .\n",
      "Predicting for image: 144\n",
      "3354883962_170d19bfe4.jpg : A black and white dog is laying in the snow .\n",
      "Predicting for image: 145\n",
      "2346401538_f5e8da66fc.jpg : A group of people are walking down a snowy street .\n",
      "Predicting for image: 146\n",
      "3605676864_0fb491267e.jpg : A little boy with a pink shirt and a green shirt smiling .\n",
      "Predicting for image: 147\n",
      "3658427967_6e2e57458d.jpg : Two people are performing a turn in the water .\n",
      "Predicting for image: 148\n",
      "2868575889_2c030aa8ae.jpg : A young boy doing a trick on a skateboard .\n",
      "Predicting for image: 149\n",
      "3494394662_3edfd4a34c.jpg : A baby looking at the camera .\n",
      "Predicting for image: 150\n",
      "3452127051_fa54a902b3.jpg : A young girl is jumping over an obstacle course .\n",
      "Predicting for image: 151\n",
      "3143155555_32b6d24f34.jpg : A woman with long hair and a tan shirt looks at her face .\n",
      "Predicting for image: 152\n",
      "470373679_98dceb19e7.jpg : a dog leading the train .\n",
      "Predicting for image: 153\n",
      "542317719_ed4dd95dc2.jpg : A girl with long hair sits by a slide .\n",
      "Predicting for image: 154\n",
      "2844641033_dab3715a99.jpg : A brown and white dog stands in the water with a ball in its mouth .\n",
      "Predicting for image: 155\n",
      "2588927489_f4da2f11ec.jpg : A young boy poses on the grass .\n",
      "Predicting for image: 156\n",
      "2041867793_552819a40b.jpg : A man in a red shirt and tie is standing in front of a white brick wall .\n",
      "Predicting for image: 157\n",
      "2594042571_2e4666507e.jpg : A man in a black shirt and a black shirt is smiling .\n",
      "Predicting for image: 158\n",
      "493109089_468e105233.jpg : The man in the red dress is wearing a helmet .\n",
      "Predicting for image: 159\n",
      "3109704348_c6416244ce.jpg : A young boy holds a soccer ball on a grassy field .\n",
      "Predicting for image: 160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241345811_46b5f157d4.jpg : A woman in a white shirt is running .\n",
      "Predicting for image: 161\n",
      "3457045393_2bbbb4e941.jpg : A group of children in a crowded park .\n",
      "Predicting for image: 162\n",
      "2797149878_bb8e27ecf9.jpg : A man in a blue shirt and glasses is standing in the snow .\n",
      "Predicting for image: 163\n",
      "543007912_23fc735b99.jpg : A man in a white shirt and black shorts sits on a bench .\n",
      "Predicting for image: 164\n",
      "3364026240_645d533fda.jpg : Three people are playing in the water .\n",
      "Predicting for image: 165\n",
      "466956209_2ffcea3941.jpg : A black and white dog is playing in the dirt .\n",
      "Predicting for image: 166\n",
      "2300168895_a9b83e16fc.jpg : Two dogs are playing with each other in the grass .\n",
      "Predicting for image: 167\n",
      "106490881_5a2dd9b7bd.jpg : A person in a helmet is jumping over a wooden fence .\n",
      "Predicting for image: 168\n",
      "3694991841_141804da1f.jpg : A brown dog is playing in the grass .\n",
      "Predicting for image: 169\n",
      "1523984678_edd68464da.jpg : A black and white dog runs through the grass .\n",
      "Predicting for image: 170\n",
      "2529116152_4331dabf50.jpg : A man is performing a trick on a dirt ramp .\n",
      "Predicting for image: 171\n",
      "1773928579_5664a810dc.jpg : A group of people walk down a street .\n",
      "Predicting for image: 172\n",
      "191003285_edd8d0cf58.jpg : A man in a red shirt and sunglasses is sitting on a tripod with other people in the background .\n",
      "Predicting for image: 173\n",
      "1392272228_cf104086e6.jpg : A white and white dog is carrying a stick in its mouth .\n",
      "Predicting for image: 174\n",
      "2910758605_73a3f5a5c2.jpg : A group of people stand on a platform .\n",
      "Predicting for image: 175\n",
      "3507076266_8b17993fbb.jpg : A boy in a red shirt rides on a swing .\n",
      "Predicting for image: 176\n",
      "535830521_aa971319fc.jpg : A man is standing in the back of a train .\n",
      "Predicting for image: 177\n",
      "70995350_75d0698839.jpg : A skier is jumping high into the air .\n",
      "Predicting for image: 178\n",
      "909808296_23c427022d.jpg : A large brown dog is walking through the woods .\n",
      "Predicting for image: 179\n",
      "3364861247_d590fa170d.jpg : A group of people are dancing .\n",
      "Predicting for image: 180\n",
      "3545652636_0746537307.jpg : A man in a red shirt plays in a game .\n",
      "Predicting for image: 181\n",
      "2869491449_1041485a6b.jpg : A black and brown dog is playing with a toy in its mouth .\n",
      "Predicting for image: 182\n",
      "2901074943_041aba4607.jpg : A boy in a colorful shirt is jumping over a floor .\n",
      "Predicting for image: 183\n",
      "3480051754_18e5802558.jpg : A group of people and dogs and one with a silly nose .\n",
      "Predicting for image: 184\n",
      "3234401637_84e0d14414.jpg : A little girl in red is standing on a beach .\n",
      "Predicting for image: 185\n",
      "1317292658_ba29330a0b.jpg : A black and white dog plays in the snow .\n",
      "Predicting for image: 186\n",
      "2140182410_8e2a06fbda.jpg : A group of people in Dog in the snow .\n",
      "Predicting for image: 187\n",
      "3095225232_2e6e6dc92e.jpg : A person in a brown shirt is climbing a skateboard in the air .\n",
      "Predicting for image: 188\n",
      "2280525192_81911f2b00.jpg : A brown dog carries a tennis ball in its mouth through the grass .\n",
      "Predicting for image: 189\n",
      "2763044275_aa498eb88b.jpg : A black and black dog is walking on the grass .\n",
      "Predicting for image: 190\n",
      "2559503010_84f20b3bc9.jpg : A small black and white dog jumps up to fall in a crowd .\n",
      "Predicting for image: 191\n",
      "496110746_a93ca191ae.jpg : A little girl in a yellow shirt holding a Surfer in his hand .\n",
      "Predicting for image: 192\n",
      "468608014_09fd20eb9b.jpg : A furry dog staring at the camera .\n",
      "Predicting for image: 193\n",
      "398662202_97e5819b79.jpg : A group of children are looking at a picture .\n",
      "Predicting for image: 194\n",
      "3141293960_74459f0a24.jpg : A girl in a dark suit is looking at a window .\n",
      "Predicting for image: 195\n",
      "2271755053_e1b1ec8442.jpg : A boy is wearing an orange shirt .\n",
      "Predicting for image: 196\n",
      "3181701312_70a379ab6e.jpg : A man and a woman sit in front of a brick wall .\n",
      "Predicting for image: 197\n",
      "3523471597_87e0bf3b21.jpg : A woman is jumping over a window .\n",
      "Predicting for image: 198\n",
      "2083434441_a93bc6306b.jpg : A brown dog running through the snow .\n",
      "Predicting for image: 199\n",
      "54501196_a9ac9d66f2.jpg : A group of people sit on a rock in front of a mountain .\n",
      "Predicting for image: 200\n",
      "751109943_2a7f8e117f.jpg : A man in a blue shirt holds a small child wearing a blue shirt .\n",
      "Predicting for image: 201\n",
      "3121521593_18f0ec14f7.jpg : Two dogs posing for a picture .\n",
      "Predicting for image: 202\n",
      "1432179046_8e3d75cf81.jpg : A man in black is looking out into the water .\n",
      "Predicting for image: 203\n",
      "3234115903_f4dfc8fc75.jpg : Two hockey players are playing a game .\n",
      "Predicting for image: 204\n",
      "3497224764_6e17544e0d.jpg : A woman in a blue shirt and blue blue shirt .\n",
      "Predicting for image: 205\n",
      "2878272032_fda05ffac7.jpg : A brown dog running through the water .\n",
      "Predicting for image: 206\n",
      "1536774449_e16b1b6382.jpg : A group of people sit on a hill in the forest .\n",
      "Predicting for image: 207\n",
      "2228022180_9597b2a458.jpg : A group of seven men in Couple in front of an outdoor wall .\n",
      "Predicting for image: 208\n",
      "2708686056_1b8f356264.jpg : A surfer is running through the snow .\n",
      "Predicting for image: 209\n",
      "1402640441_81978e32a9.jpg : A man is rock climbing .\n",
      "Predicting for image: 210\n",
      "3437147889_4cf26dd525.jpg : A person in a red and yellow helmet running around on a dirt track .\n",
      "Predicting for image: 211\n",
      "448658518_eec0b648a6.jpg : A man in a yellow shirt is standing by a sign set in the distance .\n",
      "Predicting for image: 212\n",
      "211295363_49010ca38d.jpg : A man in a red jacket is jumping into the waves .\n",
      "Predicting for image: 213\n",
      "583174725_6b522b621f.jpg : A man in blue shirt swings on the beach .\n",
      "Predicting for image: 214\n",
      "2830869109_c4e403eae6.jpg : A brown dog is holding onto a black dog in a field .\n",
      "Predicting for image: 215\n",
      "488590040_35a3e96c89.jpg : A man in a black shirt and black jeans is doing a trick in the air .\n",
      "Predicting for image: 216\n",
      "3217266166_4e0091860b.jpg : A brown and brown dog is standing in the sand .\n",
      "Predicting for image: 217\n",
      "3246991821_750a3097e2.jpg : A young boy does tricks on his bicycle on a pile of steps .\n",
      "Predicting for image: 218\n",
      "3048597471_5697538daf.jpg : A dog with a stick in its mouth is carrying a stick in its mouth .\n",
      "Predicting for image: 219\n",
      "2854959952_3991a385ab.jpg : A man in a red shirt is about to do a soccer ball .\n",
      "Predicting for image: 220\n",
      "2084217208_7bd9bc85e5.jpg : The man in the white t-shirt is wearing a white hat .\n",
      "Predicting for image: 221\n",
      "435827376_4384c3005a.jpg : A man in a brown shirt and a white hat walks down the beach .\n",
      "Predicting for image: 222\n",
      "2944362789_aebbc22db4.jpg : A little boy on the edge of a large stream .\n",
      "Predicting for image: 223\n",
      "2497420371_74788d7ba1.jpg : A group of people are standing in a fountain .\n",
      "Predicting for image: 224\n",
      "309687244_4bdf3b591f.jpg : A brown dog is running on a sandy beach .\n",
      "Predicting for image: 225\n",
      "3433982387_3fa993cf5a.jpg : A group of people are standing in front of a house .\n",
      "Predicting for image: 226\n",
      "2782433864_5a0c311d87.jpg : A brown dog runs through the dirt .\n",
      "Predicting for image: 227\n",
      "136552115_6dc3e7231c.jpg : A boy on a motorcycle is running through a forest .\n",
      "Predicting for image: 228\n",
      "1679617928_a73c1769be.jpg : A man in a yellow shirt is sitting in a playground\n",
      "Predicting for image: 229\n",
      "352981175_16ff5c07e4.jpg : A man wearing a blue shirt and blue pants is lying in the snow .\n",
      "Predicting for image: 230\n",
      "1808370027_2088394eb4.jpg : A black dog is running through the dirt .\n",
      "Predicting for image: 231\n",
      "3651971126_309e6a5e22.jpg : A dog dog with a red ball in its mouth .\n",
      "Predicting for image: 232\n",
      "3708177171_529bb4ff1d.jpg : A person in a red shirt and jeans is crossing the street .\n",
      "Predicting for image: 233\n",
      "2450299735_62c095f40e.jpg : A boy in blue is going down a swimming pool .\n",
      "Predicting for image: 234\n",
      "1387785218_cee67735f5.jpg : A baseball player jumps over a hurdle .\n",
      "Predicting for image: 235\n",
      "224369028_b1ac40d1fa.jpg : A group of wheel people on a park bench .\n",
      "Predicting for image: 236\n",
      "464251704_b0f0c4c87a.jpg : A man stands in the air in the air in the snow .\n",
      "Predicting for image: 237\n",
      "2648165716_02e2e74fd6.jpg : The man is wearing a white hat .\n",
      "Predicting for image: 238\n",
      "3085667767_66041b202e.jpg : A surfer rides a wave .\n",
      "Predicting for image: 239\n",
      "3211556865_d1d9becf69.jpg : A girl wears a helmet and a helmet is walking .\n",
      "Predicting for image: 240\n",
      "3503689049_63212220be.jpg : A man in a purple sweatshirt on a ice in a park .\n",
      "Predicting for image: 241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1107246521_d16a476380.jpg : A black dog and a brown dog are playing with a soccer ball .\n",
      "Predicting for image: 242\n",
      "3201427741_3033f5b625.jpg : A little boy in a orange jacket is in the snow .\n",
      "Predicting for image: 243\n",
      "3540416981_4e74f08cbb.jpg : Two dogs running on the grass .\n",
      "Predicting for image: 244\n",
      "410453140_5401bf659a.jpg : A group of people in front of a modern building .\n",
      "Predicting for image: 245\n",
      "3702436188_2c26192fd0.jpg : A black and white dog is sitting on a dog in a park .\n",
      "Predicting for image: 246\n",
      "2216695423_1362cb25f3.jpg : Two dogs are eating each other .\n",
      "Predicting for image: 247\n",
      "2345984157_724823b1e4.jpg : A brown dog jumps over a large pile of water .\n",
      "Predicting for image: 248\n",
      "3317073508_7e13565c1b.jpg : A group of people are all on the street in the middle of a race .\n",
      "Predicting for image: 249\n",
      "2101457132_69c950bc45.jpg : A man in a red shirt is rock climbing .\n",
      "Predicting for image: 250\n",
      "3285993030_87b0f1d202.jpg : A group of three people are running on a dirt path .\n",
      "Predicting for image: 251\n",
      "3220161734_77f42734b9.jpg : A skateboarder performs a trick on a skateboard .\n",
      "Predicting for image: 252\n",
      "2393264648_a280744f97.jpg : A boy in a black dress stands next to a picture of snow .\n",
      "Predicting for image: 253\n",
      "506367606_7cca2bba9b.jpg : A man and a woman sit at a cellphone .\n",
      "Predicting for image: 254\n",
      "422763475_0bc814dac6.jpg : A black and black dog training the ball in the snow .\n",
      "Predicting for image: 255\n",
      "1982852140_56425fa7a2.jpg : People are running along the beach .\n",
      "Predicting for image: 256\n",
      "2929506802_5432054d77.jpg : A dog jumps off a rope while a boy is in the air .\n",
      "Predicting for image: 257\n",
      "541063517_35044c554a.jpg : A group of people are playing in the water\n",
      "Predicting for image: 258\n",
      "2595186208_9b16fa0ee3.jpg : A white dog is running through the grass .\n",
      "Predicting for image: 259\n",
      "2922973230_5a769ef92a.jpg : A man in a blue shirt runs through a grassy field .\n",
      "Predicting for image: 260\n",
      "166507476_9be5b9852a.jpg : A brown dog swims in a lake .\n",
      "Predicting for image: 261\n",
      "114051287_dd85625a04.jpg : A man in a blue shirt is laughing .\n",
      "Predicting for image: 262\n",
      "3582742297_1daa29968e.jpg : A brown dog is walking through a field .\n",
      "Predicting for image: 263\n",
      "396360611_941e5849a3.jpg : A man splashing in the water .\n",
      "Predicting for image: 264\n",
      "3504881781_6a842e043b.jpg : A man in a white shirt and sandals is smiling .\n",
      "Predicting for image: 265\n",
      "3558370311_5734a15890.jpg : Many people gather on a dirt track .\n",
      "Predicting for image: 266\n",
      "2542662402_d781dd7f7c.jpg : A girl in a blue shirt is smoking .\n",
      "Predicting for image: 267\n",
      "3532205154_5674b628ea.jpg : A baby and a woman play in a tube .\n",
      "Predicting for image: 268\n",
      "2675685200_0913d84d9b.jpg : A man and a woman sit on the side of a brick wall .\n",
      "Predicting for image: 269\n",
      "3565598162_56044bc2f7.jpg : A group of people are walking down a street in front of a wall .\n",
      "Predicting for image: 270\n",
      "3024172109_a10198e1dd.jpg : A brown dog jumps out of something .\n",
      "Predicting for image: 271\n",
      "3116769029_f5a76f04ba.jpg : A little girl wearing an orange shirt is sitting on a trampoline .\n",
      "Predicting for image: 272\n",
      "2061354254_faa5bd294b.jpg : A little girl in a black shirt and gold jeans is sitting on the track .\n",
      "Predicting for image: 273\n",
      "3576259024_9c05b163aa.jpg : A boy in a green shirt is riding his bike through a dirt trail .\n",
      "Predicting for image: 274\n",
      "476759700_8911f087f8.jpg : A man in a red shirt holds a young girl on the beach .\n",
      "Predicting for image: 275\n",
      "2932740428_b15384f389.jpg : A person is jumping in the air on a sandy beach .\n",
      "Predicting for image: 276\n",
      "3348385580_10b53391f9.jpg : A little boy in a purple shirt is sitting on a red slide .\n",
      "Predicting for image: 277\n",
      "2510020918_b2ca0fb2aa.jpg : Two children are going for a picture .\n",
      "Predicting for image: 278\n",
      "1517721825_10176d0683.jpg : Two dogs are running in the water .\n",
      "Predicting for image: 279\n",
      "2788945468_74a9618cfa.jpg : A man is sitting on a dock on a pier in front of a window .\n",
      "Predicting for image: 280\n",
      "2608289957_044849f73e.jpg : A little boy in a blue shirt is sitting on a paved wall .\n",
      "Predicting for image: 281\n",
      "3328646934_5cca4cebce.jpg : A boy in a blue shirt is running through the water .\n",
      "Predicting for image: 282\n",
      "537532165_e4b7c0e61a.jpg : A young boy is on a ledge with a child in the background\n",
      "Predicting for image: 283\n",
      "2933637854_984614e18b.jpg : A girl in a blue shirt is wearing a blue shirt .\n",
      "Predicting for image: 284\n",
      "3080056515_3013830309.jpg : A young boy with blonde hair is on a playground .\n",
      "Predicting for image: 285\n",
      "1425069308_488e5fcf9d.jpg : A woman poses next to a fence in front of a building .\n",
      "Predicting for image: 286\n",
      "261490838_2f3ac98b12.jpg : A brown dog wearing a collar hills .\n",
      "Predicting for image: 287\n",
      "2926233397_71e617f3a3.jpg : A brown dog carries a red ball in its mouth .\n",
      "Predicting for image: 288\n",
      "2963573792_dd51b5fbfb.jpg : A little boy in the air while jumping into the pool .\n",
      "Predicting for image: 289\n",
      "3416091866_a96003d652.jpg : A woman in a black jacket is standing on a busy street .\n",
      "Predicting for image: 290\n",
      "2431470169_0eeba7d602.jpg : A man in a green jacket is looking at the camera in front of trees .\n",
      "Predicting for image: 291\n",
      "3099923914_fd450f6d51.jpg : A group of people sit on a busy street .\n",
      "Predicting for image: 292\n",
      "524105255_b346f288be.jpg : A man wearing a yellow bathing suit walks in a field .\n",
      "Predicting for image: 293\n",
      "56489627_e1de43de34.jpg : A little girl walks in the water .\n",
      "Predicting for image: 294\n",
      "2587818583_4aa8e7b174.jpg : The young boy in the blue shirt is playing on a colorful floor .\n",
      "Predicting for image: 295\n",
      "460935487_75b2da7854.jpg : A young girl wearing a red shirt and sunglasses is sitting on a swing .\n",
      "Predicting for image: 296\n",
      "3316725440_9ccd9b5417.jpg : A child in a green dress is sitting on a swing .\n",
      "Predicting for image: 297\n",
      "2573625591_70291c894a.jpg : A little boy and a woman play in the grass .\n",
      "Predicting for image: 298\n",
      "3030566410_393c36a6c5.jpg : A boy in a red shirt is running on the field .\n",
      "Predicting for image: 299\n",
      "1131800850_89c7ffd477.jpg : A man with a red shirt is standing on a rock .\n",
      "Predicting for image: 300\n",
      "3375549004_beee810e60.jpg : A man is sitting on a boat on a boat .\n",
      "Predicting for image: 301\n",
      "2470486377_c3a39ccb7b.jpg : A group of young kids are playing football on a swing .\n",
      "Predicting for image: 302\n",
      "436009777_440c7679a1.jpg : A young boy playing on a sidewalk .\n",
      "Predicting for image: 303\n",
      "2862004252_53894bb28b.jpg : Black and white dog running through a muddy field .\n",
      "Predicting for image: 304\n",
      "3361990489_92244a58ef.jpg : A man on the ground with his skateboard on the ground\n",
      "Predicting for image: 305\n",
      "293879742_5fe0ffd894.jpg : Two dogs are playing in a field .\n",
      "Predicting for image: 306\n",
      "3203453897_6317aac6ff.jpg : A boy in a red shirt is standing on a concrete wall next to a green building .\n",
      "Predicting for image: 307\n",
      "1772859261_236c09b861.jpg : A man walking through water in the water .\n",
      "Predicting for image: 308\n",
      "509123893_07b8ea82a9.jpg : A man in a purple shirt is sitting on a stone girl .\n",
      "Predicting for image: 309\n",
      "3168123064_d1983b8f92.jpg : A black dog running through the snow .\n",
      "Predicting for image: 310\n",
      "2238759450_6475641bdb.jpg : A man on a skateboard is standing on a boat .\n",
      "Predicting for image: 311\n",
      "246055693_ccb69ac5c6.jpg : Two dogs are playing in the grass .\n",
      "Predicting for image: 312\n",
      "3521374954_37371b49a4.jpg : A little boy is climbing a rock wall .\n",
      "Predicting for image: 313\n",
      "3143982558_9e2d44c155.jpg : A man in a black top is sitting on a woman 's guitar .\n",
      "Predicting for image: 314\n",
      "3119076670_64b5340530.jpg : A group of people are sitting at a train .\n",
      "Predicting for image: 315\n",
      "2502905671_c6039804ab.jpg : A man is doing a trick in the air on a ramp .\n",
      "Predicting for image: 316\n",
      "1267711451_e2a754b4f8.jpg : A brown dog is jumping over a bend on a dirt track .\n",
      "Predicting for image: 317\n",
      "2683963310_20dcd5e566.jpg : A man in a black shirt and a black shirt plays with something in her hand .\n",
      "Predicting for image: 318\n",
      "302983277_69a4e732e4.jpg : A little boy in a yellow shirt lying on a pool .\n",
      "Predicting for image: 319\n",
      "3584534971_b44f82c4b9.jpg : A man in a striped shirt holding a tennis ball in front of his hands .\n",
      "Predicting for image: 320\n",
      "143688283_a96ded20f1.jpg : A little boy in a blue shirt is holding a tennis ball in his mouth .\n",
      "Predicting for image: 321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1282392036_5a0328eb86.jpg : Two children and one dogs are standing in front of a flock of dogs .\n",
      "Predicting for image: 322\n",
      "2704934519_457dc38986.jpg : A man wearing a wetsuit is jumping in the air into the water .\n",
      "Predicting for image: 323\n",
      "3499720588_c32590108e.jpg : A man is jumping over a hurdle .\n",
      "Predicting for image: 324\n",
      "506738508_327efdf9c3.jpg : A man in a white shirt and jeans poses for the camera .\n",
      "Predicting for image: 325\n",
      "512101751_05a6d93e19.jpg : A little girl in a yellow shirt runs through the grass .\n",
      "Predicting for image: 326\n",
      "2317714088_bcd081f926.jpg : A man walking down a street in a busy city street .\n",
      "Predicting for image: 327\n",
      "3275704430_a75828048f.jpg : A man in a red hat , and a hat looks at a face .\n",
      "Predicting for image: 328\n",
      "2518508760_68d8df7365.jpg : A race car car is standing on a racetrack .\n",
      "Predicting for image: 329\n",
      "3254817653_632e840423.jpg : A group of people are walking down the street .\n",
      "Predicting for image: 330\n",
      "3113322995_13781860f2.jpg : A black and white dog is running through the snow .\n",
      "Predicting for image: 331\n",
      "2103568100_5d018c495b.jpg : A man splashing in the water .\n",
      "Predicting for image: 332\n",
      "3518126579_e70e0cbb2b.jpg : A man sits on a white railing in front of a forest .\n",
      "Predicting for image: 333\n",
      "2192131110_8a40e7c028.jpg : A young boy is performing a tennis ball .\n",
      "Predicting for image: 334\n",
      "2581066814_179d28f306.jpg : A group of men in uniform are racing in a parade .\n",
      "Predicting for image: 335\n",
      "480505313_2dc686e5db.jpg : A man in a brown shirt is sitting in front of a tree .\n",
      "Predicting for image: 336\n",
      "1056338697_4f7d7ce270.jpg : A man with a blue shirt with a broken face .\n",
      "Predicting for image: 337\n",
      "532457586_bddfc5251d.jpg : A man sitting in front of a glass wall .\n",
      "Predicting for image: 338\n",
      "3471841031_a949645ba8.jpg : A group of young children racing on a woodland path .\n",
      "Predicting for image: 339\n",
      "3295680663_af21ea648b.jpg : A boy in a yellow shirt is walking through the field .\n",
      "Predicting for image: 340\n",
      "415793623_6c1225ae27.jpg : A black dog is running through water .\n",
      "Predicting for image: 341\n",
      "2666205903_8d287669e1.jpg : A man is wearing a colorful shirt and face .\n",
      "Predicting for image: 342\n",
      "3323988406_e3c8fce690.jpg : A man in a black shirt and hat is standing on a brick wall .\n",
      "Predicting for image: 343\n",
      "3347666612_659e6e2207.jpg : Two dogs are running through a yard .\n",
      "Predicting for image: 344\n",
      "3439382048_d2e23b2b4c.jpg : A group of people are in the air .\n",
      "Predicting for image: 345\n",
      "2522297487_57edf117f7.jpg : Two women are sitting together in front of a restaurant .\n",
      "Predicting for image: 346\n",
      "3003691049_f4363c2d5c.jpg : A man is sitting on a sidewalk with his toy in its mouth .\n",
      "Predicting for image: 347\n",
      "2472980433_210ec62874.jpg : A group of people are in front of a race car .\n",
      "Predicting for image: 348\n",
      "2307118114_c258e3a47e.jpg : A young boy in a red shirt is sliding down a red slide .\n",
      "Predicting for image: 349\n",
      "2410320522_d967f0b75c.jpg : A dog runs through a field .\n",
      "Predicting for image: 350\n",
      "1408958345_68eea9a4e4.jpg : A young girl wearing a blue life shirt is running in the water .\n",
      "Predicting for image: 351\n",
      "498444334_a680d318a1.jpg : A woman in a pink shirt is walking down a brick street .\n",
      "Predicting for image: 352\n",
      "3596131692_91b8a05606.jpg : A soccer player in a red and white shirt is challenging the ball on a grassy field .\n",
      "Predicting for image: 353\n",
      "2208310655_a3d83080c5.jpg : A baby plays with a white and white and white dog .\n",
      "Predicting for image: 354\n",
      "2340206885_58754a799a.jpg : A brown dog in the snow in the snow .\n",
      "Predicting for image: 355\n",
      "2968182121_b3b491df85.jpg : A greyhound greyhound wearing a number 6 and number is racing on a dirt track .\n",
      "Predicting for image: 356\n",
      "3514019869_7de4ece2a5.jpg : A black and white dog is sitting on a lawn .\n",
      "Predicting for image: 357\n",
      "2162564553_96de62c7e6.jpg : Two dogs are running in the water .\n",
      "Predicting for image: 358\n",
      "766099402_cdda6964f0.jpg : A group of people in front of a blue jump .\n",
      "Predicting for image: 359\n",
      "3593392955_a4125087f6.jpg : A brown dog is playing in the grass .\n",
      "Predicting for image: 360\n",
      "1472230829_803818a383.jpg : A little boy in a pink shirt and a pink shirt is sitting on a sandy beach .\n",
      "Predicting for image: 361\n",
      "2774554310_007e980a90.jpg : A man wearing a red shirt and sunglasses .\n",
      "Predicting for image: 362\n",
      "2289068031_fe26990183.jpg : A woman in a yellow jacket is playing with a large dog on the beach .\n",
      "Predicting for image: 363\n",
      "3411393875_a9ff73c67a.jpg : A man in a rollerskating suit is playing .\n",
      "Predicting for image: 364\n",
      "3406930103_4db7b4dde0.jpg : A brown dog runs through the snow .\n",
      "Predicting for image: 365\n",
      "497791037_93499238d8.jpg : A man in a helmet sits on a mountain .\n",
      "Predicting for image: 366\n",
      "3255482333_5bcee79f7e.jpg : A girl in a grey jacket is riding a bicycle in the snow .\n",
      "Predicting for image: 367\n",
      "3040033126_9f4b88261b.jpg : A man is rock climbing .\n",
      "Predicting for image: 368\n",
      "2354540393_a149722680.jpg : A man in a brown shirt holds a brown dog in the air .\n",
      "Predicting for image: 369\n",
      "2739331794_4ae78f69a0.jpg : A person on a motorcycle goes down a track .\n",
      "Predicting for image: 370\n",
      "241346508_0b3907a95b.jpg : A football player swings the player in red .\n",
      "Predicting for image: 371\n",
      "2877503811_4e311253ec.jpg : A woman in a white shirt and sneakers is standing near a table .\n",
      "Predicting for image: 372\n",
      "3484649669_7bfe62080b.jpg : Two dogs are playing together in the dirt .\n",
      "Predicting for image: 373\n",
      "1084040636_97d9633581.jpg : A brown dog is laying on a black and black dog .\n",
      "Predicting for image: 374\n",
      "3027397797_4f1d305ced.jpg : A young girl wearing a black shirt is sitting near a brown truck .\n",
      "Predicting for image: 375\n",
      "2398605966_1d0c9e6a20.jpg : Two dogs play in snow .\n",
      "Predicting for image: 376\n",
      "2533424347_cf2f84872b.jpg : A race car is driving through the street .\n",
      "Predicting for image: 377\n",
      "189721896_1ffe76d89e.jpg : A group of people are standing in a field .\n",
      "Predicting for image: 378\n",
      "2089426086_7acc98a3a8.jpg : A man in a green shirt is jumping over a wooden chair .\n",
      "Predicting for image: 379\n",
      "2718024196_3ff660416a.jpg : A brown dog walks through a sprinkler .\n",
      "Predicting for image: 380\n",
      "3072114570_e1c0127529.jpg : A man wearing a helmet is riding a dirt bike .\n",
      "Predicting for image: 381\n",
      "3516825206_5750824874.jpg : A group of people posing for a picture .\n",
      "Predicting for image: 382\n",
      "3224227640_31865b3651.jpg : A small brown dog is running through the dirt .\n",
      "Predicting for image: 383\n",
      "200771289_31902164a7.jpg : A man with a hat and a white hat .\n",
      "Predicting for image: 384\n",
      "3502993968_4ee36afb0e.jpg : A man in a green jacket does a wheelie in the air .\n",
      "Predicting for image: 385\n",
      "3692593096_fbaea67476.jpg : A person wearing a black shirt runs across a field of water .\n",
      "Predicting for image: 386\n",
      "447111935_5af98563e3.jpg : A little girl in a pink shirt walks through the grass .\n",
      "Predicting for image: 387\n",
      "3568197730_a071d7595b.jpg : A little boy does a green shirt and a girl on his skateboard .\n",
      "Predicting for image: 388\n",
      "3569979711_6507841268.jpg : A person in an orange suit is flying across the sand\n",
      "Predicting for image: 389\n",
      "180506881_de0f59770f.jpg : A man in a black striped shirt looks out .\n",
      "Predicting for image: 390\n",
      "3017521547_f5ef8848e3.jpg : A girl in a blue dress is wearing a blue helmet .\n",
      "Predicting for image: 391\n",
      "3503623999_bbd5dcfb18.jpg : A young boy wearing a red shirt with a star hat\n",
      "Predicting for image: 392\n",
      "3301811927_a2797339e5.jpg : A hockey player in a green uniform is running .\n",
      "Predicting for image: 393\n",
      "3592968286_b63c81bcd2.jpg : A child in a red shirt sits on a red .\n",
      "Predicting for image: 394\n",
      "2311690895_0d6efe11c8.jpg : A brown and white dog chewing on a white and black and black and black dog .\n",
      "Predicting for image: 395\n",
      "452419961_6d42ab7000.jpg : A man is standing in front of a window .\n",
      "Predicting for image: 396\n",
      "2641770481_c98465ff35.jpg : A man on a basketball during a field .\n",
      "Predicting for image: 397\n",
      "2878190821_6e4e03dc5f.jpg : A man in a blue shirt stands on a rail .\n",
      "Predicting for image: 398\n",
      "3725202807_12fbfdd207.jpg : A young girl looking at a woman in a pink shirt .\n",
      "Predicting for image: 399\n",
      "2938747424_64e64784f0.jpg : Black dog running through shallow water .\n",
      "Predicting for image: 400\n",
      "1322323208_c7ecb742c6.jpg : A man in a white shirt is carrying a brown dog on a beach .\n",
      "Predicting for image: 401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2458269558_277012780d.jpg : A little boy in a blue shirt is riding a ride to a swing .\n",
      "Predicting for image: 402\n",
      "2985679744_75a7102aab.jpg : A man in a black shirt with a backpack .\n",
      "Predicting for image: 403\n",
      "317383917_d8bfa350b6.jpg : Two dogs running through the snow .\n",
      "Predicting for image: 404\n",
      "2482629385_f370b290d1.jpg : A man in a blue shirt is walking through tall grass .\n",
      "Predicting for image: 405\n",
      "293327462_20dee0de56.jpg : A woman sits on a wall with her arms out .\n",
      "Predicting for image: 406\n",
      "359837950_9e22ffe6c2.jpg : Two dogs are playing in the field .\n",
      "Predicting for image: 407\n",
      "354642192_3b7666a2dd.jpg : A dog swims in water .\n",
      "Predicting for image: 408\n",
      "1786425974_c7c5ad6aa1.jpg : A man in a black jacket is running on the grass .\n",
      "Predicting for image: 409\n",
      "3767841911_6678052eb6.jpg : A little girl in a yellow shirt plays with a Frisbee .\n",
      "Predicting for image: 410\n",
      "2884420269_225d27f242.jpg : A man in a pink shirt is climbing a skateboard on a skateboard .\n",
      "Predicting for image: 411\n",
      "2715035273_8fc8b1291c.jpg : A little girl in a blue shirt stands in front of a car .\n",
      "Predicting for image: 412\n",
      "3123463486_f5b36a3624.jpg : A black and white dog is playing with a ball in a field .\n",
      "Predicting for image: 413\n",
      "2194286203_5dc620006a.jpg : A dog with a red collar is laying on a gravel hill .\n",
      "Predicting for image: 414\n",
      "2815256108_fc1302117d.jpg : A group of people , a crowd car sits in a skate skate park .\n",
      "Predicting for image: 415\n",
      "1348304997_afe60a61df.jpg : A group of children jumping over a rail .\n",
      "Predicting for image: 416\n",
      "888425986_e4b6c12324.jpg : Many people sit on a bench under a lake .\n",
      "Predicting for image: 417\n",
      "3485425825_c2f3446e73.jpg : A man and a woman are playing with a stick in front of a group of people .\n",
      "Predicting for image: 418\n",
      "3217187564_0ffd89dec1.jpg : A greyhound is sitting on a dirt track .\n",
      "Predicting for image: 419\n",
      "3589895574_ee08207d26.jpg : A woman is sitting on a red phone in a green hat .\n",
      "Predicting for image: 420\n",
      "317109978_cb557802e1.jpg : A brown dog is playing with a tennis ball in its mouth\n",
      "Predicting for image: 421\n",
      "2224450291_4c133fabe8.jpg : A group of women in African uniforms standing in the park .\n",
      "Predicting for image: 422\n",
      "3155390408_8e1a81efb2.jpg : A dog plays with a red toy .\n",
      "Predicting for image: 423\n",
      "3562050678_4196a7fff3.jpg : A group of people racing in front of a mountain range .\n",
      "Predicting for image: 424\n",
      "2696866120_254a0345bc.jpg : A large brown dog carries a toy in his mouth .\n",
      "Predicting for image: 425\n",
      "3114944484_28b5bb9842.jpg : A woman in a white shirt and holding a group of people .\n",
      "Predicting for image: 426\n",
      "751737218_b89839a311.jpg : A young boy in a red shirt is sitting on a bench in a backyard .\n",
      "Predicting for image: 427\n",
      "352382023_7605223d1c.jpg : A black and white dog running through the snow .\n",
      "Predicting for image: 428\n",
      "247704641_d883902277.jpg : A white dog running in the water .\n",
      "Predicting for image: 429\n",
      "3461041826_0e24cdf597.jpg : A dog is walking on a trail .\n",
      "Predicting for image: 430\n",
      "3358558292_6ab14193ed.jpg : A group of students standing in a crowd .\n",
      "Predicting for image: 431\n",
      "525863257_053333e612.jpg : A black and white dog is about to jump over a pond .\n",
      "Predicting for image: 432\n",
      "2112921744_92bf706805.jpg : A person in a green shirt walks down a grassy road .\n",
      "Predicting for image: 433\n",
      "375392855_54d46ed5c8.jpg : A boy wearing a blue shirt and blue shirt is jumping over a red fence .\n",
      "Predicting for image: 434\n",
      "1917265421_aeccf1ca38.jpg : A group of people are sitting on a marathon .\n",
      "Predicting for image: 435\n",
      "1659358141_0433c9bf99.jpg : Two dogs play in the dirt .\n",
      "Predicting for image: 436\n",
      "2533642917_a5eace85e6.jpg : A little boy slides down a slide .\n",
      "Predicting for image: 437\n",
      "2204550058_2707d92338.jpg : A young boy with black hair and a blue hat .\n",
      "Predicting for image: 438\n",
      "2764178773_d63b502812.jpg : A group of people are walking on a dirt path .\n",
      "Predicting for image: 439\n",
      "180094434_b0f244832d.jpg : A man walks down on a sidewalk with a funny mask walks down .\n",
      "Predicting for image: 440\n",
      "2308978137_bfe776d541.jpg : A man and a man are standing in a church .\n",
      "Predicting for image: 441\n",
      "3358682439_be4b83544c.jpg : A group of children playing with a toy in front of a fence .\n",
      "Predicting for image: 442\n",
      "2602085456_d1beebcb29.jpg : The woman is looking at the camera .\n",
      "Predicting for image: 443\n",
      "2589241160_3832440850.jpg : A brown dog carries a stick in his mouth .\n",
      "Predicting for image: 444\n",
      "421322723_3470543368.jpg : A man in a black jacket and tie is standing in front of a desk .\n",
      "Predicting for image: 445\n",
      "2124040721_bffc0a091a.jpg : A girl with a red shirt is smiling on a red slide .\n",
      "Predicting for image: 446\n",
      "3145967309_b33abe4d84.jpg : A little boy with a cast on her face .\n",
      "Predicting for image: 447\n",
      "300550441_f44ec3701a.jpg : A dog runs through a field .\n",
      "Predicting for image: 448\n",
      "1584315962_5b0b45d02d.jpg : A climber making a trick off a ramp .\n",
      "Predicting for image: 449\n",
      "2460797929_66446c13db.jpg : A basketball player in a red uniform is sitting on a football game .\n",
      "Predicting for image: 450\n",
      "2909875716_25c8652614.jpg : A black dog runs through the grass .\n",
      "Predicting for image: 451\n",
      "3085667865_fa001816be.jpg : A surfer is flying through the ocean .\n",
      "Predicting for image: 452\n",
      "3624327440_bef4f33f32.jpg : A man on a wave .\n",
      "Predicting for image: 453\n",
      "979383193_0a542a059d.jpg : A group of people scaling a rock .\n",
      "Predicting for image: 454\n",
      "3009644534_992e9ea2a7.jpg : A black and white dog is running on the grass .\n",
      "Predicting for image: 455\n",
      "561940436_64d6fc125d.jpg : A man wearing a black shirt and a black hat is smiling .\n",
      "Predicting for image: 456\n",
      "3393926562_66cc01b001.jpg : A little boy in a red shirt and black shorts is playing in the street .\n",
      "Predicting for image: 457\n",
      "3299820401_c2589186c5.jpg : A man in a red t-shirt is jumping off a bicycle .\n",
      "Predicting for image: 458\n",
      "3545586120_283d728a97.jpg : A man in a red shirt .\n",
      "Predicting for image: 459\n",
      "1467533293_a2656cc000.jpg : A man and a woman sit in front of a building .\n",
      "Predicting for image: 460\n",
      "373394550_1b2296b8c4.jpg : A black and white dog jumps into the pool .\n",
      "Predicting for image: 461\n",
      "539751252_2bd88c456b.jpg : A young boy is jumping in the pool of a water slide .\n",
      "Predicting for image: 462\n",
      "2621415349_ef1a7e73be.jpg : The little girl is holding a hat .\n",
      "Predicting for image: 463\n",
      "2077079696_03380d218b.jpg : A man wearing a red shirt stands on top of a rock cliff .\n",
      "Predicting for image: 464\n",
      "566397227_a469e9e415.jpg : A brown dog with a brown collar walks in a grassy field .\n",
      "Predicting for image: 465\n",
      "115684808_cb01227802.jpg : A group of people are running through the snow .\n",
      "Predicting for image: 466\n",
      "3387542157_81bfd00072.jpg : A little boy in a blue shirt is running down the slide .\n",
      "Predicting for image: 467\n",
      "2646116932_232573f030.jpg : A little boy wearing a striped shirt is hanging out in a garden .\n",
      "Predicting for image: 468\n",
      "307327914_f98f576adb.jpg : A skateboarder plays with a guitar .\n",
      "Predicting for image: 469\n",
      "3044536048_e615466e7f.jpg : A black and white dog is jumping in the water .\n",
      "Predicting for image: 470\n",
      "3053743109_a2d780c0d2.jpg : A group of people sit in front of a store in a parade .\n",
      "Predicting for image: 471\n",
      "2265096094_8cc34d669c.jpg : Two dogs are playing in a river .\n",
      "Predicting for image: 472\n",
      "2283966256_70317e1759.jpg : A man on a dirt bike is running on a dirt road .\n",
      "Predicting for image: 473\n",
      "3609645320_815c294b65.jpg : Two dogs are running through a field .\n",
      "Predicting for image: 474\n",
      "3047264346_e24601bfbf.jpg : A man with a hat .\n",
      "Predicting for image: 475\n",
      "439037721_cdf1fc7358.jpg : Two people are at the beach .\n",
      "Predicting for image: 476\n",
      "2594902417_f65d8866a8.jpg : A brown dog is playing in a field .\n",
      "Predicting for image: 477\n",
      "533483374_86c5d4c13e.jpg : White dog with a purple collar is running in the air in the water .\n",
      "Predicting for image: 478\n",
      "2991575785_bd4868e215.jpg : A man in a dress is standing in front of a brick building .\n",
      "Predicting for image: 479\n",
      "3295391572_cbfde03a10.jpg : A woman and woman are standing next to another boy .\n",
      "Predicting for image: 480\n",
      "3217620013_8b17873273.jpg : The basketball player is wearing a red shirt .\n",
      "Predicting for image: 481\n",
      "2526041608_a9775ab8d7.jpg : A man on a swing with a black and white dog .\n",
      "Predicting for image: 482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3028969146_26929ae0e8.jpg : Two dogs are running in a field .\n",
      "Predicting for image: 483\n",
      "254295381_d98fa049f4.jpg : A boy wearing a blue shirt is jumping over a hurdle .\n",
      "Predicting for image: 484\n",
      "2148916767_644ea6a7fa.jpg : A black and white dog is running through the snow .\n",
      "Predicting for image: 485\n",
      "3200120942_59cfbb3437.jpg : a , a , a , a , a , in a red , in a black , black and black , a man and a man and a , a man , a , a , and a\n",
      "Predicting for image: 486\n",
      "3591458156_f1a9a33918.jpg : A brown and white dog is jumping over a Frisbee in the air .\n",
      "Predicting for image: 487\n",
      "3354330935_de75be9d2f.jpg : Skiiers of people on a snowy mountain .\n",
      "Predicting for image: 488\n",
      "3320356356_1497e53f80.jpg : A man with a pink shirt is running down a dirt path .\n",
      "Predicting for image: 489\n",
      "353180303_6a24179c50.jpg : Two women in orange shirts are smiling for the camera .\n",
      "Predicting for image: 490\n",
      "3064383768_f6838f57da.jpg : A black and white dog plays in the water .\n",
      "Predicting for image: 491\n",
      "154871781_ae77696b77.jpg : A rail is midair in a park .\n",
      "Predicting for image: 492\n",
      "2616643090_4f2d2d1a44.jpg : A small white and white and white dog wearing a white t-shirt is playing with a yellow ball .\n",
      "Predicting for image: 493\n",
      "2049051050_20359a434a.jpg : A woman in black and black and black top is posing for a digital camera .\n",
      "Predicting for image: 494\n",
      "1472882567_33dc14c8b6.jpg : A climber is scaling a snow-covered mountain .\n",
      "Predicting for image: 495\n",
      "170100272_d820db2199.jpg : A group of young people are sitting on a playground course .\n",
      "Predicting for image: 496\n",
      "2096771662_984441d20d.jpg : A man in a black shirt is sitting in front of a man who is looking on .\n",
      "Predicting for image: 497\n",
      "363617160_6cb0c723be.jpg : A small boy is jumping in the air .\n",
      "Predicting for image: 498\n",
      "3523474077_16e14bc54c.jpg : A man in a black shirt stands in front of a wooden building .\n",
      "Predicting for image: 499\n",
      "3506468593_7e41a6d9f1.jpg : A group of people racing on a river .\n",
      "Predicting for image: 500\n",
      "1446053356_a924b4893f.jpg : A young boy carries a tennis ball in its mouth .\n",
      "Predicting for image: 501\n",
      "3123351642_3794f2f601.jpg : A man in a red shirt and t-shirt is standing on a beach .\n",
      "Predicting for image: 502\n",
      "523985664_c866af4850.jpg : A man with a white shirt is holding a baby in the air .\n",
      "Predicting for image: 503\n",
      "3251976937_20625dc2b8.jpg : A man in swim trunks is running .\n",
      "Predicting for image: 504\n",
      "2078311270_f01c9eaf4c.jpg : A woman wearing a black shirt is wearing a black hat and a white hat with a black backpack and backpack .\n",
      "Predicting for image: 505\n",
      "350443876_c9769f5734.jpg : A man in a black shirt is riding a skateboard on a busy street .\n",
      "Predicting for image: 506\n",
      "2649406158_ded6be38de.jpg : A race car is about to fall in front of a crowd .\n",
      "Predicting for image: 507\n",
      "215214751_e913b6ff09.jpg : A person in a green wetsuit is riding on a wave .\n",
      "Predicting for image: 508\n",
      "2926595608_69b22be8d4.jpg : A young boy jumping in the air .\n",
      "Predicting for image: 509\n",
      "3310067561_b92017acab.jpg : a black and white dog is playing with a stuffed ball .\n",
      "Predicting for image: 510\n",
      "997722733_0cb5439472.jpg : A man wearing a red shirt and sits on a rock in the woods .\n",
      "Predicting for image: 511\n",
      "1389264266_8170bc1c54.jpg : A man in a purple dress and a purple sweatshirt is holding his hair .\n",
      "Predicting for image: 512\n",
      "2774430374_fee1d793e7.jpg : A little boy is playing with a ball .\n",
      "Predicting for image: 513\n",
      "3384314832_dffc944152.jpg : A dog is being pulled into a field of water .\n",
      "Predicting for image: 514\n",
      "3251648670_9339943ba2.jpg : A man in a red shirt plays on a red slide .\n",
      "Predicting for image: 515\n",
      "2933912528_52b05f84a1.jpg : Two brown dogs on the beach .\n",
      "Predicting for image: 516\n",
      "3694093650_547259731e.jpg : A group of people pose for a fence .\n",
      "Predicting for image: 517\n",
      "2197275664_fabcf3424b.jpg : A young boy with a purple hat is smiling .\n",
      "Predicting for image: 518\n",
      "2505988632_9541f15583.jpg : A young boy is holding a dog on his dog .\n",
      "Predicting for image: 519\n",
      "3477715432_79d82487bb.jpg : A woman wearing a purple shirt and glasses is standing in front of a white brick wall .\n",
      "Predicting for image: 520\n",
      "241031254_0c6f30e3d1.jpg : A woman in a green shirt and a child in a green shirt is standing in a wooded area .\n",
      "Predicting for image: 521\n",
      "2575647360_f5de38c751.jpg : A woman in a striped hat is jumping in front of a restaurant .\n",
      "Predicting for image: 522\n",
      "3539767254_c598b8e6c7.jpg : A man sits on a bridge and a man and a girl on the top .\n",
      "Predicting for image: 523\n",
      "3182121297_38c99b2769.jpg : A man is doing a trick in the air in the air in the air .\n",
      "Predicting for image: 524\n",
      "1682079482_9a72fa57fa.jpg : A little girl in a white shirt is sitting in front of a wooden slide\n",
      "Predicting for image: 525\n",
      "3247052319_da8aba1983.jpg : A group of people in a field .\n",
      "Predicting for image: 526\n",
      "249394748_2e4acfbbb5.jpg : A black dog is sleeping in front of a tennis ball .\n",
      "Predicting for image: 527\n",
      "2461616306_3ee7ac1b4b.jpg : A boy in a blue shirt is in the pool .\n",
      "Predicting for image: 528\n",
      "929679367_ff8c7df2ee.jpg : A brown and white dog is playing with a black dog .\n",
      "Predicting for image: 529\n",
      "468102269_135938e209.jpg : A man in a black shirt and black pants is sitting on the wall .\n",
      "Predicting for image: 530\n",
      "771048251_602e5e8f45.jpg : A little girl in front of the camera .\n",
      "Predicting for image: 531\n",
      "2384353160_f395e9a54b.jpg : A person in a wetsuit smiles in the snow .\n",
      "Predicting for image: 532\n",
      "3245912109_fdeef6b456.jpg : A group of people are standing in a race .\n",
      "Predicting for image: 533\n",
      "3613955682_3860e116cf.jpg : A bunch of people walk in a parade .\n",
      "Predicting for image: 534\n",
      "2866254827_9a8f592017.jpg : A little boy wearing a helmet and wearing a helmet and wearing a yellow jacket .\n",
      "Predicting for image: 535\n",
      "160792599_6a7ec52516.jpg : People are playing in a swimming pool .\n",
      "Predicting for image: 536\n",
      "3108732084_565b423162.jpg : A black and white dog doing a trick on the side of a mountain .\n",
      "Predicting for image: 537\n",
      "2991994607_06f24ec7a6.jpg : A woman in a blue shirt and a white shirt is sleeping in a crowd .\n",
      "Predicting for image: 538\n",
      "542179694_e170e9e465.jpg : A group of people in uniforms stand in front of a building .\n",
      "Predicting for image: 539\n",
      "136644343_0e2b423829.jpg : Kid with long hair is holding a child under a pool .\n",
      "Predicting for image: 540\n",
      "3605061440_1d08c80a57.jpg : A man in a red shirt plays on the grass .\n",
      "Predicting for image: 541\n",
      "2358554995_54ed3baa83.jpg : A man in a red coat is wearing a red coat .\n",
      "Predicting for image: 542\n",
      "3138399980_d6ab8b2272.jpg : A man and a woman are getting ready to kick a ball .\n",
      "Predicting for image: 543\n",
      "2944836001_b38b516286.jpg : A black and white dog is playing with a tennis ball .\n",
      "Predicting for image: 544\n",
      "2949982320_c704b31626.jpg : A young boy wearing a brown shirt and shorts is climbing a couch .\n",
      "Predicting for image: 545\n",
      "2544426580_317b1f1f73.jpg : A little boy plays with another child on a slide .\n",
      "Predicting for image: 546\n",
      "3006093003_c211737232.jpg : A man in a red shirt is wearing a white shirt .\n",
      "Predicting for image: 547\n",
      "2370481277_a3085614c9.jpg : A group of people play in a grassy field .\n",
      "Predicting for image: 548\n",
      "2707873672_15e6b5d54b.jpg : A group of children sitting in front of a tree .\n",
      "Predicting for image: 549\n",
      "3427118504_93126c83e0.jpg : A man and a brown and white dog with his mouth open .\n",
      "Predicting for image: 550\n",
      "3203908917_53e53c03d1.jpg : A man wearing a black coat is standing next to a woman in black .\n",
      "Predicting for image: 551\n",
      "1415591512_a84644750c.jpg : A biker in the air .\n",
      "Predicting for image: 552\n",
      "2757803246_8aa3499d26.jpg : A group of people are jumping over a jump .\n",
      "Predicting for image: 553\n",
      "2061144717_5b3a1864f0.jpg : A boy wearing Rollerblades airborne in a skate pool .\n",
      "Predicting for image: 554\n",
      "3393343330_b13df4d8ec.jpg : A group of people in front of a family store .\n",
      "Predicting for image: 555\n",
      "3569406219_f37ebf7b92.jpg : A tan dog jumps over a window .\n",
      "Predicting for image: 556\n",
      "3353036763_4cbeba03b2.jpg : A group of people are playing in a marathon .\n",
      "Predicting for image: 557\n",
      "3498327617_d2e3db3ee3.jpg : A young boy in a red shirt is swimming in the water .\n",
      "Predicting for image: 558\n",
      "1343426964_cde3fb54e8.jpg : A little boy is taking a camera with a camera .\n",
      "Predicting for image: 559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3425851292_de92a072ee.jpg : A girl in a red shirt sits on a mat in the air .\n",
      "Predicting for image: 560\n",
      "3630641436_8f9ac5b9b2.jpg : A man is carrying a soccer ball in the water .\n",
      "Predicting for image: 561\n",
      "2901880865_3fd7b66a45.jpg : A surfer wearing a helmet is riding a large wave .\n",
      "Predicting for image: 562\n",
      "2445283938_ff477c7952.jpg : A man in a hat is pushing a picture in front of a crowd of people .\n",
      "Predicting for image: 563\n",
      "3315616181_15dd137e27.jpg : A little girl in a white shirt jumping off of a small player .\n",
      "Predicting for image: 564\n",
      "1572532018_64c030c974.jpg : A woman and a woman are sitting on some rocks .\n",
      "Predicting for image: 565\n",
      "2308271254_27fb466eb4.jpg : A black and black dog is running through the water .\n",
      "Predicting for image: 566\n",
      "2498897831_0bbb5d5b51.jpg : A little girl in a purple shirt and pink shorts is standing in front of a group of flowers .\n",
      "Predicting for image: 567\n",
      "2170222061_e8bce4a32d.jpg : A brown and black dog is playing with a tennis ball in its mouth .\n",
      "Predicting for image: 568\n",
      "2534502836_7a75305655.jpg : A brown and brown dog standing on the grass .\n",
      "Predicting for image: 569\n",
      "534875358_6ea30d3091.jpg : A man is riding a bicycle on a sandy street\n",
      "Predicting for image: 570\n",
      "370614351_98b8a166b9.jpg : A man wearing a purple shirt and black hat is standing in front of a brick wall .\n",
      "Predicting for image: 571\n",
      "3429956016_3c7e3096c2.jpg : A man sits on a snowy wall with his arms raised .\n",
      "Predicting for image: 572\n",
      "514990193_2d2422af2c.jpg : A group of people are sitting on a sidewalk near a lake .\n",
      "Predicting for image: 573\n",
      "1287475186_2dee85f1a5.jpg : A man in a pool .\n",
      "Predicting for image: 574\n",
      "2966552760_e65b22cd26.jpg : A little boy with a red shirt is sitting on the edge of a wall with his hand .\n",
      "Predicting for image: 575\n",
      "486712504_36be449055.jpg : A little girl slides down a playground slide .\n",
      "Predicting for image: 576\n",
      "3015863181_92ff43f4d8.jpg : A woman with a white shirt and a white shirt is running .\n",
      "Predicting for image: 577\n",
      "348380010_33bb0599ef.jpg : A brown and white dog is running through the grass .\n",
      "Predicting for image: 578\n",
      "3670907052_c827593564.jpg : A man is riding a motorcycle over a motorcycle .\n",
      "Predicting for image: 579\n",
      "1626754053_81126b67b6.jpg : A black and white dog is playing with a black and white dog .\n",
      "Predicting for image: 580\n",
      "3716244806_97d5a1fb61.jpg : A man in a red uniform is on a horse in a tree .\n",
      "Predicting for image: 581\n",
      "3641022607_e7a5455d6c.jpg : A man goes down a hill .\n",
      "Predicting for image: 582\n",
      "2950905787_f2017d3e49.jpg : A skier stands on a snowy mountain .\n",
      "Predicting for image: 583\n",
      "3482974845_db4f16befa.jpg : A man is doing a trick on a bike on the beach .\n",
      "Predicting for image: 584\n",
      "2883099128_0b056eed9e.jpg : A little boy with a life shirt runs down a dirt path .\n",
      "Predicting for image: 585\n",
      "2310126952_7dc86d88f6.jpg : A white dog is playing with a tennis ball .\n",
      "Predicting for image: 586\n",
      "2479162876_a5ce3306af.jpg : Two dogs run through the sand .\n",
      "Predicting for image: 587\n",
      "3498997518_c2b16f0a0e.jpg : A bunch of hockey players in red jerseys try for the ball .\n",
      "Predicting for image: 588\n",
      "3232470286_903a61ea16.jpg : The little boy is jumping over a hurdle .\n",
      "Predicting for image: 589\n",
      "2183227136_8bb657846b.jpg : Two people are sitting on a dirt ledge near water .\n",
      "Predicting for image: 590\n",
      "2120383553_5825333a3f.jpg : A little girl wearing a red shirt is playing with a ball .\n",
      "Predicting for image: 591\n",
      "3544793763_b38546a5e8.jpg : A group of people are standing in a match .\n",
      "Predicting for image: 592\n",
      "1404832008_68e432665b.jpg : A man in a green jacket is driving through a river .\n",
      "Predicting for image: 593\n",
      "3541474181_489f19fae7.jpg : A German Shephard Shephard in the snow .\n",
      "Predicting for image: 594\n",
      "3042380610_c5ea61eef8.jpg : A group of men dressed in black pants are walking together in a forest .\n",
      "Predicting for image: 595\n",
      "486917990_72bd4069af.jpg : A man and a girl are walking under a dock .\n",
      "Predicting for image: 596\n",
      "2599444370_9e40103027.jpg : A boy is jumping in a swimming pool .\n",
      "Predicting for image: 597\n",
      "3468694409_a51571d621.jpg : A young girl is standing next to a red toy in the air .\n",
      "Predicting for image: 598\n",
      "494921598_af73bda568.jpg : A boy wearing a white shirt is wearing a helmet .\n",
      "Predicting for image: 599\n",
      "197107117_4b438b1872.jpg : Two hikers are sitting on a mountain in front of a mountain range .\n",
      "Predicting for image: 600\n",
      "3019842612_8501c1791e.jpg : A black and white dog and a black and a dog on a fence .\n",
      "Predicting for image: 601\n",
      "909191414_1cf5d85821.jpg : A young boy is jumping over a slide .\n",
      "Predicting for image: 602\n",
      "2945036454_280fa5b29f.jpg : A man in a green coat is toy in a field .\n",
      "Predicting for image: 603\n",
      "2666179615_f05a9d8331.jpg : A woman wearing a red shirt is holding a book in front of a dog .\n",
      "Predicting for image: 604\n",
      "3030294889_78b2ccbe51.jpg : Three people are sitting on a slide .\n",
      "Predicting for image: 605\n",
      "509778093_21236bb64d.jpg : A white dog and a brown dog on the grass .\n",
      "Predicting for image: 606\n",
      "3245070961_8977fdd548.jpg : A little girl wearing a red shirt is on a green .\n",
      "Predicting for image: 607\n",
      "533713007_bf9f3e25b4.jpg : A group of people are standing in front of a fair .\n",
      "Predicting for image: 608\n",
      "2922222717_12195af92d.jpg : A dog playing with a small dog .\n",
      "Predicting for image: 609\n",
      "3191135894_2b4bdabb6d.jpg : A woman wearing a white shirt is standing in front of a group of trees .\n",
      "Predicting for image: 610\n",
      "700884207_d3ec546494.jpg : A man in a white jacket is sitting on a white dog .\n",
      "Predicting for image: 611\n",
      "2196846255_2c1635359a.jpg : A black and white dog is running through the water .\n",
      "Predicting for image: 612\n",
      "3474406285_01f3d24b71.jpg : A brown dog jumps over a hurdle .\n",
      "Predicting for image: 613\n",
      "448252603_7d928c900e.jpg : A person in a red shirt is wading through the snow .\n",
      "Predicting for image: 614\n",
      "2860872588_f2c7b30e1a.jpg : A woman and a woman are sitting on a red .\n",
      "Predicting for image: 615\n",
      "880220939_0ef1c37f1f.jpg : A man in a pink jacket and a purple jacket is standing in a pink jacket .\n",
      "Predicting for image: 616\n",
      "820169182_f5e78d7d19.jpg : A child in colorful blue overalls is playing with the blue blanket .\n",
      "Predicting for image: 617\n",
      "3436063693_15c8d377a2.jpg : A young boy and a child are playing with a ribbon in the grass .\n",
      "Predicting for image: 618\n",
      "1262583859_653f1469a9.jpg : A little boy in a blue shirt is walking along a track .\n",
      "Predicting for image: 619\n",
      "3185371756_ff4e9fa8a6.jpg : A young girl in a red snowsuit is jumping in the snow .\n",
      "Predicting for image: 620\n",
      "3591462960_86045906bd.jpg : A man in a life jacket is sitting in front of a group of people .\n",
      "Predicting for image: 621\n",
      "3619416477_9d18580a14.jpg : A man is driving through the water .\n",
      "Predicting for image: 622\n",
      "3459156091_c1879ebe28.jpg : A man and woman are sitting on a bench in front of a building .\n",
      "Predicting for image: 623\n",
      "537559285_29be110134.jpg : A young boy is jumping a skateboard through an obstacle course .\n",
      "Predicting for image: 624\n",
      "3052196390_c59dd24ca8.jpg : A dog is playing with a ball in his mouth .\n",
      "Predicting for image: 625\n",
      "2490768374_45d94fc658.jpg : A young boy in a blue shirt is holding a toy in its mouth .\n",
      "Predicting for image: 626\n",
      "150387174_24825cf871.jpg : A person in a red helmet is climbing a rock face .\n",
      "Predicting for image: 627\n",
      "1962729184_6996e128e7.jpg : A group of people stand on a city street .\n",
      "Predicting for image: 628\n",
      "2306674172_dc07c7f847.jpg : A man and a woman are standing next to a man in a black t-shirt .\n",
      "Predicting for image: 629\n",
      "2086513494_dbbcb583e7.jpg : A man with a brown hat is running in the snow .\n",
      "Predicting for image: 630\n",
      "2652522323_9218afd8c2.jpg : A little boy plays with a soccer ball on the grass .\n",
      "Predicting for image: 631\n",
      "3399284917_721aefe2a7.jpg : A man in a black and black shirt swings down a skateboard .\n",
      "Predicting for image: 632\n",
      "370713359_7560808550.jpg : A group of people sit in a basketball .\n",
      "Predicting for image: 633\n",
      "2843695880_eeea6c67db.jpg : A group of people are playing in a swimming pool .\n",
      "Predicting for image: 634\n",
      "2676764246_c58205a365.jpg : Two dogs in the snow .\n",
      "Predicting for image: 635\n",
      "3107513635_fe8a21f148.jpg : A woman in a red shirt is sitting on a bench overlooking a parking lot .\n",
      "Predicting for image: 636\n",
      "2885387575_9127ea10f1.jpg : A man in a purple shirt and blue shirt is sitting on a grassy field .\n",
      "Predicting for image: 637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3223224391_be50bf4f43.jpg : A black and white dog is running through the water .\n",
      "Predicting for image: 638\n",
      "1461667284_041c8a2475.jpg : A group of girls wearing hats stand in front of the street .\n",
      "Predicting for image: 639\n",
      "2196316998_3b2d63f01f.jpg : A man in a white shirt is riding a red bike .\n",
      "Predicting for image: 640\n",
      "1998457059_c9ac9a1e1a.jpg : A surfer is doing a leap on a surfboard .\n",
      "Predicting for image: 641\n",
      "3294209955_a1f1e2cc19.jpg : Two dogs stand in a field .\n",
      "Predicting for image: 642\n",
      "488408004_a1e26d4886.jpg : A person wearing a black hat is running through a field of grass .\n",
      "Predicting for image: 643\n",
      "3135504530_0f4130d8f8.jpg : A woman in a red shirt is wearing a red shirt .\n",
      "Predicting for image: 644\n",
      "3217910740_d1d61c08ab.jpg : A little boy wearing a green shirt is looking at the camera .\n",
      "Predicting for image: 645\n",
      "3602838407_bf13e49243.jpg : Three dogs are competing in the water .\n",
      "Predicting for image: 646\n",
      "2984174290_a915748d77.jpg : A young girl plays on a beach\n",
      "Predicting for image: 647\n",
      "424779662_568f9606d0.jpg : A group of young girls are playing in a backyard .\n",
      "Predicting for image: 648\n",
      "2431832075_00aa1a4457.jpg : The little boy in red rides on a red and red ball .\n",
      "Predicting for image: 649\n",
      "624742559_ff467d8ebc.jpg : A man is sitting in front of a group of people .\n",
      "Predicting for image: 650\n",
      "3157847991_463e006a28.jpg : A young girl wearing a blue shirt and a black jacket is walking down a sidewalk .\n",
      "Predicting for image: 651\n",
      "2893374123_087f98d58a.jpg : A man in a red shirt is riding his motorcycle on a racetrack .\n",
      "Predicting for image: 652\n",
      "3359551687_68f2f0212a.jpg : A group of football players try to get the ball .\n",
      "Predicting for image: 653\n",
      "3070031806_3d587c2a66.jpg : A brown dog is running down a sandy beach .\n",
      "Predicting for image: 654\n",
      "2480850054_de3433b54a.jpg : A man carries a stick in his mouth .\n",
      "Predicting for image: 655\n",
      "3216926094_bc975e84b9.jpg : A brown dog is wearing a yellow collar , is running .\n",
      "Predicting for image: 656\n",
      "3449114979_6cdc3e8da8.jpg : A man in a black shirt with a red bag .\n",
      "Predicting for image: 657\n",
      "2543589122_ec3e55f434.jpg : A young woman wearing a blue shirt and blue pants is laying on a beach .\n",
      "Predicting for image: 658\n",
      "3530843182_35af2c821c.jpg : An Asian boy stands next to a picture .\n",
      "Predicting for image: 659\n",
      "3472364264_dbde5a8d0a.jpg : Two dogs playing in the snow .\n",
      "Predicting for image: 660\n",
      "3715469645_6d1dc019b3.jpg : Two dogs are playing with a toy .\n",
      "Predicting for image: 661\n",
      "2196107384_361d73a170.jpg : A woman stands in front of a window in front of a building .\n",
      "Predicting for image: 662\n",
      "1561658940_a947f2446a.jpg : a young girl in a pink shirt and a red toy .\n",
      "Predicting for image: 663\n",
      "3655074079_7df3812bc5.jpg : A girl in a red shirt and blue hat is smiling .\n",
      "Predicting for image: 664\n",
      "3004823335_9b82cbd8a7.jpg : A young girl in a pink shirt is sitting on a green field near a grassy field .\n",
      "Predicting for image: 665\n",
      "2495931537_9b8d4474b6.jpg : Two girls are standing on a spinning .\n",
      "Predicting for image: 666\n",
      "293881927_ac62900fd4.jpg : A little girl in a yellow shirt is walking through the grass .\n",
      "Predicting for image: 667\n",
      "3162045919_c2decbb69b.jpg : A man in a black wetsuit is riding a wave .\n",
      "Predicting for image: 668\n",
      "505929313_7668f021ab.jpg : A black and white dog stands in the water .\n",
      "Predicting for image: 669\n",
      "3244470342_c08f6bb17e.jpg : A tan dog is jumping off the edge of the water .\n",
      "Predicting for image: 670\n",
      "3655964639_21e76383d0.jpg : A man in a red hat and a purple hat is riding up a bicycle .\n",
      "Predicting for image: 671\n",
      "3718964174_cb2dc1615e.jpg : A boy in a blue shirt is sliding down a slide .\n",
      "Predicting for image: 672\n",
      "3388330419_85d72f7cda.jpg : The little girl is playing with a red ball .\n",
      "Predicting for image: 673\n",
      "2128119486_4407061c40.jpg : A girl in a blue shirt is looking at a broken face .\n",
      "Predicting for image: 674\n",
      "917574521_74fab68514.jpg : A little girl is wearing a red shirt .\n",
      "Predicting for image: 675\n",
      "400851260_5911898657.jpg : A man in a red dress is making a slope .\n",
      "Predicting for image: 676\n",
      "270816949_ffad112278.jpg : A group of people are standing on a mountain .\n",
      "Predicting for image: 677\n",
      "421730441_6b2267fd31.jpg : A man in a denim shirt is in front of a large truck\n",
      "Predicting for image: 678\n",
      "429851331_b248ca01cd.jpg : A person with a helmet is standing in front of some trees .\n",
      "Predicting for image: 679\n",
      "241345905_5826a72da1.jpg : A man in a Sooners jersey is trying to tackle the ball .\n",
      "Predicting for image: 680\n",
      "2102360862_264452db8e.jpg : A group of people sit on a ramp with a camera in the background .\n",
      "Predicting for image: 681\n",
      "3051384385_c5c850c1f8.jpg : A man in a black shirt and black pants stands in front of a brick building .\n",
      "Predicting for image: 682\n",
      "3500136982_bf7a85531e.jpg : A group of children are sitting on a wall in a field .\n",
      "Predicting for image: 683\n",
      "416788726_5b4eb1466e.jpg : A group of people in a store .\n",
      "Predicting for image: 684\n",
      "245895500_a4eb97af02.jpg : A dog is about to catch a ball .\n",
      "Predicting for image: 685\n",
      "3259002340_707ce96858.jpg : A brown and white dog and a brown dog are jumping on a black and white dog .\n",
      "Predicting for image: 686\n",
      "2796801478_8ebd7e550b.jpg : A little boy in a red jacket is performing a jump in front of a fence .\n",
      "Predicting for image: 687\n",
      "57422853_b5f6366081.jpg : A man is doing a trick in the air on a mountain .\n",
      "Predicting for image: 688\n",
      "1311388430_4ab0cd1a1f.jpg : A skier in a red dress appears to equipment in the air .\n",
      "Predicting for image: 689\n",
      "522063319_33827f1627.jpg : A girl in a plaid t-shirt is holding a drink in a park .\n",
      "Predicting for image: 690\n",
      "384577800_fc325af410.jpg : Two dogs are running in snow .\n",
      "Predicting for image: 691\n",
      "3159995270_17334ccb5b.jpg : A man is doing a trick on a blue bike .\n",
      "Predicting for image: 692\n",
      "2229179070_dc8ea8582e.jpg : A little boy in a red shirt is fishing in a park .\n",
      "Predicting for image: 693\n",
      "1764955991_5e53a28c87.jpg : A brown dog is running through a wooded area .\n",
      "Predicting for image: 694\n",
      "670609997_5c7fdb3f0b.jpg : A little girl is carrying a stick in its mouth .\n",
      "Predicting for image: 695\n",
      "86412576_c53392ef80.jpg : A man is sitting on a dirt track .\n",
      "Predicting for image: 696\n",
      "260828892_7925d27865.jpg : A man is performing a ball into the air on the beach .\n",
      "Predicting for image: 697\n",
      "3737539561_d1dc161040.jpg : Three people jump on a wagon .\n",
      "Predicting for image: 698\n",
      "3262075846_5695021d84.jpg : Three men wearing brown and black and white uniforms holding a dog on the grass .\n",
      "Predicting for image: 699\n",
      "3227148358_f152303584.jpg : A white dog attempts to see a Frisbee in the air .\n",
      "Predicting for image: 700\n",
      "2373234213_4ebe9c4ee5.jpg : A little boy is riding a motorcycle down a motorcycle .\n",
      "Predicting for image: 701\n",
      "2914206497_5e36ac6324.jpg : A boy in a green shirt is sitting on a wet racetrack .\n",
      "Predicting for image: 702\n",
      "488356951_b3b77ad832.jpg : A closeup of a collie with a red wheelie in the air .\n",
      "Predicting for image: 703\n",
      "2105756457_a100d8434e.jpg : A little girl in an orange jacket is playing with a colorful ball .\n",
      "Predicting for image: 704\n",
      "3506560025_8d0f4f9ac4.jpg : A man wearing a green shirt and sunglasses is holding up a man in front of the camera .\n",
      "Predicting for image: 705\n",
      "3456362961_d8f7e347a8.jpg : A dog swimming in a lake .\n",
      "Predicting for image: 706\n",
      "3044500219_778f9f2b71.jpg : A girl in a black shirt is standing in front of a crowd of people .\n",
      "Predicting for image: 707\n",
      "2301525531_edde12d673.jpg : A person wearing a red jacket is walking in the snow .\n",
      "Predicting for image: 708\n",
      "3280052365_c4644bf0a5.jpg : A group of people posing for a picture in a crowd\n",
      "Predicting for image: 709\n",
      "3640422448_a0f42e4559.jpg : A person wearing a white t-shirt is riding a dirt bike on a trail .\n",
      "Predicting for image: 710\n",
      "2396025708_e4a72e2558.jpg : A man in a red shirt on a red wave .\n",
      "Predicting for image: 711\n",
      "1433142189_cda8652603.jpg : A person in a black hat is running in the snow .\n",
      "Predicting for image: 712\n",
      "3214573346_d3a57f0328.jpg : A small child is in the air .\n",
      "Predicting for image: 713\n",
      "3218480482_66af7587c8.jpg : A group of people are riding in a race .\n",
      "Predicting for image: 714\n",
      "2021613437_d99731f986.jpg : A little boy in an orange shirt holding a red shirt and orange skirt .\n",
      "Predicting for image: 715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2525270674_4ab536e7ec.jpg : A man with a pink hat is walking in a green pool .\n",
      "Predicting for image: 716\n",
      "3470951932_27ed74eb0b.jpg : Two soccer players playing in the grass .\n",
      "Predicting for image: 717\n",
      "2870875612_2cbb9e4a3c.jpg : A young boy wearing a cap is in the ocean on the beach .\n",
      "Predicting for image: 718\n",
      "2541104331_a2d65cfa54.jpg : A black dog is about to swim in the water .\n",
      "Predicting for image: 719\n",
      "444057017_f1e0fcaef7.jpg : A young boy in a yellow shirt with his arm inside a yellow nose .\n",
      "Predicting for image: 720\n",
      "3597326009_3678a98a43.jpg : A man is sitting on a stool in a crowded park .\n",
      "Predicting for image: 721\n",
      "3360930596_1e75164ce6.jpg : A soccer player in blue is ready to throw a ball .\n",
      "Predicting for image: 722\n",
      "247637795_fdf26a03cf.jpg : A man wearing a black shirt looks at a camera .\n",
      "Predicting for image: 723\n",
      "3696698390_989f1488e7.jpg : Four children are walking through a garden .\n",
      "Predicting for image: 724\n",
      "3421789737_f625dd17ed.jpg : A man in a striped jacket is standing on a busy street .\n",
      "Predicting for image: 725\n",
      "53043785_c468d6f931.jpg : A surfer wearing a black wetsuit is surfing a wave .\n",
      "Predicting for image: 726\n",
      "3058439373_9276a4702a.jpg : A group of people walking down the street .\n",
      "Predicting for image: 727\n",
      "2100816230_ff866fb352.jpg : A girl in an orange shirt stands next to a blue sky .\n",
      "Predicting for image: 728\n",
      "2729655904_1dd01922fb.jpg : A black dog is playing in the ocean .\n",
      "Predicting for image: 729\n",
      "3270691950_88583c3524.jpg : A young boy is standing in front of a body of water .\n",
      "Predicting for image: 730\n",
      "3729525173_7f984ed776.jpg : A young boy is sitting in the grass .\n",
      "Predicting for image: 731\n",
      "540721368_12ac732c6c.jpg : A closeup of a boy in a yellow shirt makes a instrument .\n",
      "Predicting for image: 732\n",
      "3686924335_3c51e8834a.jpg : A brown dog carries a yellow toy in its mouth .\n",
      "Predicting for image: 733\n",
      "2295216243_0712928988.jpg : A group of people are posing for a rock wall .\n",
      "Predicting for image: 734\n",
      "3450874870_c4dcf58fb3.jpg : A man on a red and white , white and white helmet on the snow .\n",
      "Predicting for image: 735\n",
      "3061481868_d1e00b1f2e.jpg : A race car is skateboarding on a racetrack .\n",
      "Predicting for image: 736\n",
      "308487515_7852928f90.jpg : A white dog is pulling on a yellow ball .\n",
      "Predicting for image: 737\n",
      "263854883_0f320c1562.jpg : A brown and brown dog is playing with a stick .\n",
      "Predicting for image: 738\n",
      "3549583146_3e8bb2f7e9.jpg : A boy in a green shirt is running with a Frisbee .\n",
      "Predicting for image: 739\n",
      "3542484764_77d8920ec9.jpg : A young boy in a red shirt is about to cross a swing .\n",
      "Predicting for image: 740\n",
      "3208074567_ac44aeb3f3.jpg : A man without a helmet is running through the dirt .\n",
      "Predicting for image: 741\n",
      "3167365436_c379bda282.jpg : A woman in a harness sits in a tube .\n",
      "Predicting for image: 742\n",
      "2693425189_47740c22ed.jpg : A dog jumps over a hurdle .\n",
      "Predicting for image: 743\n",
      "434792818_56375e203f.jpg : A young boy in a blue and white and white and white coat with a yellow ball .\n",
      "Predicting for image: 744\n",
      "3635577874_48ebaac734.jpg : A young skateboarder doing a trick on a ramp .\n",
      "Predicting for image: 745\n",
      "3413571342_b9855795e2.jpg : A person in a red bathing suit jumps through the water .\n",
      "Predicting for image: 746\n",
      "2475162978_2c51048dca.jpg : Kids playing in the field .\n",
      "Predicting for image: 747\n",
      "2160266952_a2ab39191b.jpg : A man in a blue shirt is sitting on a red slide .\n",
      "Predicting for image: 748\n",
      "463978865_c87c6ca84c.jpg : A group of people are racing in front of horses .\n",
      "Predicting for image: 749\n",
      "3585487286_ef9a8d4c56.jpg : A dog is running along a sandy beach .\n",
      "Predicting for image: 750\n",
      "3239021459_a6b71bb400.jpg : A snowboarder wearing a helmet riding a wave .\n",
      "Predicting for image: 751\n",
      "2662845514_8620aaee96.jpg : A little boy in an orange shirt sits in a plastic chair .\n",
      "Predicting for image: 752\n",
      "3044746136_8b89da5f40.jpg : A group of people wait for a picture .\n",
      "Predicting for image: 753\n",
      "343218198_1ca90e0734.jpg : A woman and a woman are sitting on a park bench .\n",
      "Predicting for image: 754\n",
      "2924259848_effb4dcb82.jpg : A man in a helmet riding a rope .\n",
      "Predicting for image: 755\n",
      "3720366614_dfa8fe1088.jpg : A little girl in a red shirt is holding a large wave .\n",
      "Predicting for image: 756\n",
      "1356796100_b265479721.jpg : A little child in a white shirt is playing in a swimming field .\n",
      "Predicting for image: 757\n",
      "2905942129_2b4bf59bc0.jpg : A man in a blue shirt is driving down a track .\n",
      "Predicting for image: 758\n",
      "2660008870_b672a4c76a.jpg : A little girl in a blue suit is in a body of water .\n",
      "Predicting for image: 759\n",
      "2274992140_bb9e868bb8.jpg : A man in a black shirt is standing next to a woman who is wearing a black hat .\n",
      "Predicting for image: 760\n",
      "3538213870_9856a76b2a.jpg : An Asian girl in a red shirt is sitting in front of a cellphone .\n",
      "Predicting for image: 761\n",
      "2206960564_325ed0c7ae.jpg : A brown and white dog is standing on a gravel floor .\n",
      "Predicting for image: 762\n",
      "2839038702_e168128665.jpg : A group of people are sitting on top of a snowy mountain .\n",
      "Predicting for image: 763\n",
      "424416723_19c56cb365.jpg : A grey dog holds a ball in his mouth .\n",
      "Predicting for image: 764\n",
      "2876993733_cb26107d18.jpg : A group of people on a city street .\n",
      "Predicting for image: 765\n",
      "223299142_521aedf9e7.jpg : A little girl wearing a blue shirt sits on a beach with his head in her mouth .\n",
      "Predicting for image: 766\n",
      "3347798761_5c5260b000.jpg : A snowboarder is running on a hill .\n",
      "Predicting for image: 767\n",
      "1220401002_3f44b1f3f7.jpg : A little boy is wearing a Spider-Man shirt .\n",
      "Predicting for image: 768\n",
      "3564543247_05cdbc31cf.jpg : A little boy wearing a red shirt and a yellow shirt sits in front of a building .\n",
      "Predicting for image: 769\n",
      "3385246141_a263d1053e.jpg : A group of people are sitting on a table at night .\n",
      "Predicting for image: 770\n",
      "3334537556_a2cf4e9b9a.jpg : A group of people walking through the air .\n",
      "Predicting for image: 771\n",
      "2909955251_4b326a46a7.jpg : A skier is doing a jump in the water .\n",
      "Predicting for image: 772\n",
      "2247889670_413db8094b.jpg : A group of dogs playing in a rocky beach .\n",
      "Predicting for image: 773\n",
      "3186073578_6e115f45f5.jpg : A woman in a red shirt and blue shirt is standing next to a red curtain .\n",
      "Predicting for image: 774\n",
      "3192069971_83c5a90b4c.jpg : A man in a black and white helmet running down the beach .\n",
      "Predicting for image: 775\n",
      "3422458549_f3f3878dbf.jpg : A boy in a red uniform is about to hit the camera .\n",
      "Predicting for image: 776\n",
      "2891617125_f939f604c7.jpg : A dirt biker is riding a dirt bike .\n",
      "Predicting for image: 777\n",
      "279728508_6bd7281f3c.jpg : A dog is running down a rock path .\n",
      "Predicting for image: 778\n",
      "2913965136_2d00136697.jpg : A man and a brown dog are running through a grassy field .\n",
      "Predicting for image: 779\n",
      "3692892751_f6574e2700.jpg : A young boy in a green dress is holding a stick in front of some flowers .\n",
      "Predicting for image: 780\n",
      "2288099178_41091aa00c.jpg : A group of colorfully men in uniforms are trying to make a marathon .\n",
      "Predicting for image: 781\n",
      "476233374_e1396998ef.jpg : A black dog standing on the shore of a lake .\n",
      "Predicting for image: 782\n",
      "2559921948_06af25d566.jpg : A man in a blue uniform is running with a ball in ice .\n",
      "Predicting for image: 783\n",
      "2189995738_352607a63b.jpg : A little boy is standing in the water next to a lake .\n",
      "Predicting for image: 784\n",
      "3359530430_249f51972c.jpg : A group of people are airborne .\n",
      "Predicting for image: 785\n",
      "317488612_70ac35493b.jpg : A dog is carrying a stick in its mouth .\n",
      "Predicting for image: 786\n",
      "2842865689_e37256d9ce.jpg : A boy doing a jump in a pool .\n",
      "Predicting for image: 787\n",
      "2225231022_1632d0a5aa.jpg : A man in a black shirt and a woman with a red shirt and a woman in a black shirt and cap and a woman .\n",
      "Predicting for image: 788\n",
      "327415627_6313d32a64.jpg : A brown dog walks in front of a grassy field .\n",
      "Predicting for image: 789\n",
      "2292406847_f366350600.jpg : A woman sits on a rocky hill .\n",
      "Predicting for image: 790\n",
      "3571147934_d1c8af1d6e.jpg : A man in a green shirt walks down the street .\n",
      "Predicting for image: 791\n",
      "2607462776_78e639d891.jpg : A large brown dog is running through the grass with a toy in its mouth .\n",
      "Predicting for image: 792\n",
      "801607443_f15956d1ce.jpg : A person in a yellow shirt and jeans is standing on the water overlooking the water .\n",
      "Predicting for image: 793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2176980976_7054c99621.jpg : A man wearing a blue shirt and blue shirt is running toward the camera .\n",
      "Predicting for image: 794\n",
      "3523559027_a65619a34b.jpg : A little boy is about to climb a curb in the park .\n",
      "Predicting for image: 795\n",
      "1329832826_432538d331.jpg : A man and a black and brown dog are in front of a fountain .\n",
      "Predicting for image: 796\n",
      "260520547_944f9f4c91.jpg : Two dogs play in front of a fence in front of a fence .\n",
      "Predicting for image: 797\n",
      "2473738924_eca928d12f.jpg : A man in a white shirt and jeans is jumping in the air .\n",
      "Predicting for image: 798\n",
      "1765164972_92dac06fa9.jpg : A man in a yellow shirt eats a clear book .\n",
      "Predicting for image: 799\n",
      "2806710650_e201acd913.jpg : A young boy in blue holds an arms trick in the air .\n",
      "Predicting for image: 800\n",
      "2501595799_6316001e89.jpg : A black and white dog is running through a field .\n",
      "Predicting for image: 801\n",
      "3697359692_8a5cdbe4fe.jpg : A man and a woman stand in front of a crowd .\n",
      "Predicting for image: 802\n",
      "3688858505_e8afd1475d.jpg : A young boy wearing a green shirt is playing on a green seat .\n",
      "Predicting for image: 803\n",
      "3396157719_6807d52a81.jpg : A bearded man in a plaid shirt dances in a sprinkler .\n",
      "Predicting for image: 804\n",
      "473220329_819a913bbb.jpg : A man wearing a dress is running on the grass .\n",
      "Predicting for image: 805\n",
      "3228069008_edb2961fc4.jpg : A little blond blond girl with black hair next to a red ball .\n",
      "Predicting for image: 806\n",
      "2861932486_52befd8592.jpg : A man wearing a blue shirt and a blue shirt is sitting in front of a metal couch .\n",
      "Predicting for image: 807\n",
      "758921886_55a351dd67.jpg : A man in a grey shirt and black hat is posing for a picture .\n",
      "Predicting for image: 808\n",
      "791338571_7f38510bf7.jpg : A girl in yellow and white and white and white and white shirt is sitting in front of a fence .\n",
      "Predicting for image: 809\n",
      "3435035138_af32890a4c.jpg : A black dog is jumping over some plants in front of some trees .\n",
      "Predicting for image: 810\n",
      "1339596997_8ac29c1841.jpg : Two women leaning on a swing .\n",
      "Predicting for image: 811\n",
      "3245460937_2710a82709.jpg : A boy in jeans and a black shirt sitting in front of a bus .\n",
      "Predicting for image: 812\n",
      "3256275785_9c3af57576.jpg : A girl is jumping into a lake .\n",
      "Predicting for image: 813\n",
      "2856080862_95d793fa9d.jpg : A young boy wearing a red shirt is sitting on a paved wall in front of a fence .\n",
      "Predicting for image: 814\n",
      "3179336562_c3d0c0a3bd.jpg : Two people are sitting on a boardwalk in the water .\n",
      "Predicting for image: 815\n",
      "430173345_86388d8822.jpg : A black and white dog is running through the grass .\n",
      "Predicting for image: 816\n",
      "1096395242_fc69f0ae5a.jpg : A man in a life outfit is riding on a bed .\n",
      "Predicting for image: 817\n",
      "2378149488_648e5deeac.jpg : A man in a blue shirt and blue shirt is leaping over a jump in the grass .\n",
      "Predicting for image: 818\n",
      "2358561039_e215a8d6cd.jpg : A woman in a red dress is wearing a purple shirt .\n",
      "Predicting for image: 819\n",
      "2667015110_1670324a33.jpg : A girl in a white shirt holding a yellow ball .\n",
      "Predicting for image: 820\n",
      "500446858_125702b296.jpg : A brown and white dog is running on the grass .\n",
      "Predicting for image: 821\n",
      "226607225_44d696db6b.jpg : A tan dog walks in the snow .\n",
      "Predicting for image: 822\n",
      "2496370758_a3fbc49837.jpg : A brown and white dog runs in a field .\n",
      "Predicting for image: 823\n",
      "3259991972_fce3ab18b2.jpg : A bunch of people walk down the street .\n",
      "Predicting for image: 824\n",
      "229862312_1a0ba19dab.jpg : A black dog plays with a toy in the green grass .\n",
      "Predicting for image: 825\n",
      "3333921867_6cc7d7c73d.jpg : A black dog is running through a field .\n",
      "Predicting for image: 826\n",
      "2248487950_c62d0c81a9.jpg : A man in a black shirt and black shorts is standing in front of a basketball sign .\n",
      "Predicting for image: 827\n",
      "3074842262_62b1b2168c.jpg : A black dog is running through the woods .\n",
      "Predicting for image: 828\n",
      "561417861_8e25d0c0e8.jpg : A man is doing a trick on a skateboard .\n",
      "Predicting for image: 829\n",
      "2646046871_c3a5dbb971.jpg : A man and a dog are walking through a field .\n",
      "Predicting for image: 830\n",
      "2944952557_8484f0da8f.jpg : A group of people are playing field .\n",
      "Predicting for image: 831\n",
      "3244747165_17028936e0.jpg : Two women are smiling at the camera .\n",
      "Predicting for image: 832\n",
      "2285570521_05015cbf4b.jpg : The skier is in the snow .\n",
      "Predicting for image: 833\n",
      "315880837_90db309bab.jpg : A black and black dog is running through the snow .\n",
      "Predicting for image: 834\n",
      "3375070563_3c290a7991.jpg : A man in a red dress sits on the water .\n",
      "Predicting for image: 835\n",
      "1298295313_db1f4c6522.jpg : A girl in a red shirt is playing in the water .\n",
      "Predicting for image: 836\n",
      "3585598356_8ce815bbb9.jpg : A young girl in a red jacket is sitting on a red slide .\n",
      "Predicting for image: 837\n",
      "2473689180_e9d8fd656a.jpg : A man with a pink helmet is standing on the beach .\n",
      "Predicting for image: 838\n",
      "3258874419_23fec1bdc1.jpg : The dog is racing in a race .\n",
      "Predicting for image: 839\n",
      "1237985362_dbafc59280.jpg : A group of people in swim trunks are walking .\n",
      "Predicting for image: 840\n",
      "3290105461_7590f23371.jpg : A woman wearing a dress is playing with a brown dog .\n",
      "Predicting for image: 841\n",
      "2644430445_47c985a2ee.jpg : A man in a red shirt is running down a track .\n",
      "Predicting for image: 842\n",
      "732468337_a37075225e.jpg : A little girl in a gray shirt is kneeling on the side of a wall .\n",
      "Predicting for image: 843\n",
      "113678030_87a6a6e42e.jpg : A man is flying down a snowy hill .\n",
      "Predicting for image: 844\n",
      "2120411340_104eb610b1.jpg : Two men posing on a rock .\n",
      "Predicting for image: 845\n",
      "2450453051_f1d4a78ab4.jpg : A black and white dog jumps on a bench on a track .\n",
      "Predicting for image: 846\n",
      "2831217847_555b2f95ca.jpg : There is a child in a grassy field\n",
      "Predicting for image: 847\n",
      "3192266178_f9bf5d3dba.jpg : A group of people stand on a country road .\n",
      "Predicting for image: 848\n",
      "326456451_effadbbe49.jpg : A small white dog is running through the snow .\n",
      "Predicting for image: 849\n",
      "2663794355_e726ec7e05.jpg : A dog is swimming in the water .\n",
      "Predicting for image: 850\n",
      "3364151356_eecd07a23e.jpg : The brown dog is playing with a red ball .\n",
      "Predicting for image: 851\n",
      "2251747182_6b67a3ab8b.jpg : A baby player in a white jersey is smiling .\n",
      "Predicting for image: 852\n",
      "3139160252_75109e9e05.jpg : A woman and a woman sit against a brick wall .\n",
      "Predicting for image: 853\n",
      "219070971_ae43410b9e.jpg : A person in a red and white helmet is riding a red bike .\n",
      "Predicting for image: 854\n",
      "1674612291_7154c5ab61.jpg : A little girl in a yellow jacket is running through a field .\n",
      "Predicting for image: 855\n",
      "136886677_6026c622eb.jpg : A rock climber is swimming in the water .\n",
      "Predicting for image: 856\n",
      "3398746625_5199beea71.jpg : A man in blue stands in the air into the sand .\n",
      "Predicting for image: 857\n",
      "3220650628_4ed964e5b4.jpg : A man wearing a black shirt and jeans is standing behind a window .\n",
      "Predicting for image: 858\n",
      "1082379191_ec1e53f996.jpg : A little girl wearing a yellow shirt walks through the water .\n",
      "Predicting for image: 859\n",
      "3741462565_cc35966b7a.jpg : A young boy with her hands over her face .\n",
      "Predicting for image: 860\n",
      "1174525839_7c1e6cfa86.jpg : Two people are playing on a beach .\n",
      "Predicting for image: 861\n",
      "3572267708_9d8a81d4a4.jpg : A group of women with nighttime photo of a church sign .\n",
      "Predicting for image: 862\n",
      "1509786421_f03158adfc.jpg : A little boy in a white shirt is laughing .\n",
      "Predicting for image: 863\n",
      "3155987659_b9ea318dd3.jpg : A brown dog is jumping over a grassy ramp .\n",
      "Predicting for image: 864\n",
      "925491651_57df3a5b36.jpg : A black and white dog is surfing through the water .\n",
      "Predicting for image: 865\n",
      "2735558076_0d7bbc18fc.jpg : A man in a white shirt is sitting on a swing .\n",
      "Predicting for image: 866\n",
      "300922408_05a4f9938c.jpg : A young boy is running through a pool .\n",
      "Predicting for image: 867\n",
      "1490670858_e122df2560.jpg : A crowd of people sit in a basketball game .\n",
      "Predicting for image: 868\n",
      "2953015871_cae796b6e7.jpg : A black dog is running through the dirt .\n",
      "Predicting for image: 869\n",
      "524282699_71e678a6bd.jpg : A dog is running in the grass .\n",
      "Predicting for image: 870\n",
      "2890113532_ab2003d74e.jpg : A little girl in a white dress walks down the grass .\n",
      "Predicting for image: 871\n",
      "1456393634_74022d9056.jpg : Two people are in front of a body of water .\n",
      "Predicting for image: 872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2813033949_e19fa08805.jpg : A boy in a red shirt runs through a field .\n",
      "Predicting for image: 873\n",
      "745880539_cd3f948837.jpg : A little boy in a striped shirt is looking out on a wooden ramp .\n",
      "Predicting for image: 874\n",
      "2480327661_fb69829f57.jpg : A boy in orange pitching a basketball .\n",
      "Predicting for image: 875\n",
      "3125309108_1011486589.jpg : A man in a white sweatshirt and a black sweatshirt stands in the air .\n",
      "Predicting for image: 876\n",
      "3287549827_04dec6fb6e.jpg : Two people playing in the woods .\n",
      "Predicting for image: 877\n",
      "391579205_c8373b5411.jpg : A man and a woman sit on the top of a brick building .\n",
      "Predicting for image: 878\n",
      "2610447973_89227ff978.jpg : A skateboarder in the dark .\n",
      "Predicting for image: 879\n",
      "2698666984_13e17236ae.jpg : A man wearing a blue helmet is wearing a helmet is jumping through a river .\n",
      "Predicting for image: 880\n",
      "339350939_6643bfb270.jpg : A white dog runs on the beach .\n",
      "Predicting for image: 881\n",
      "127490019_7c5c08cb11.jpg : Two people sitting on a dirt path in front of a body of water .\n",
      "Predicting for image: 882\n",
      "1714316707_8bbaa2a2ba.jpg : A dog is on a rocky shore .\n",
      "Predicting for image: 883\n",
      "3556598205_86c180769d.jpg : A man is climbing a dirt bike .\n",
      "Predicting for image: 884\n",
      "757046028_ff5999f91b.jpg : A boy sits on a sidewalk with a ball in its mouth .\n",
      "Predicting for image: 885\n",
      "132489044_3be606baf7.jpg : A man wearing a striped shirt sits in a gym .\n",
      "Predicting for image: 886\n",
      "3613800013_5a54968ab0.jpg : A tan dog is running through a yard .\n",
      "Predicting for image: 887\n",
      "2577972703_a22c5f2a87.jpg : A little girl in a pink shirt plays with a girl wearing a pink shirt .\n",
      "Predicting for image: 888\n",
      "2073964624_52da3a0fc4.jpg : A young girl in a black shirt camp clouds candles .\n",
      "Predicting for image: 889\n",
      "2194494220_bb2178832c.jpg : A man in a red suit is jumping off a snowy hill .\n",
      "Predicting for image: 890\n",
      "2215136723_960edfea49.jpg : a man in a blue and white and white helmet , is standing on a red slide .\n",
      "Predicting for image: 891\n",
      "2759860913_f75b39d783.jpg : A young boy in a yellow shirt is running through the dirt .\n",
      "Predicting for image: 892\n",
      "3225310099_d8e419ba56.jpg : A person in the air with a ball in the background .\n",
      "Predicting for image: 893\n",
      "2938120171_970564e3d8.jpg : A small black and white dog is holding a tennis ball in its mouth .\n",
      "Predicting for image: 894\n",
      "754852108_72f80d421f.jpg : A little girl wearing a green shirt is sitting on the beach .\n",
      "Predicting for image: 895\n",
      "3187395715_f2940c2b72.jpg : A boy jumps over a sidewalk .\n",
      "Predicting for image: 896\n",
      "3281078518_630a7a7f4f.jpg : A little girl in a red sweater is smiling .\n",
      "Predicting for image: 897\n",
      "3071676551_a65741e372.jpg : A man in a wetsuit rides a wave .\n",
      "Predicting for image: 898\n",
      "3106026005_473a7b1c8c.jpg : A man in a black shirt jumping up to do a harness .\n",
      "Predicting for image: 899\n",
      "3523874798_9ba2fa46e3.jpg : A man on a skateboard on a skateboard .\n",
      "Predicting for image: 900\n",
      "245252561_4f20f1c89e.jpg : A small man in a life life shirt is taking a large wave .\n",
      "Predicting for image: 901\n",
      "3685328542_ab999b83bb.jpg : A man in a denim shirt is playing a bike in progress .\n",
      "Predicting for image: 902\n",
      "3613424631_3ae537624f.jpg : A man in a red shirt is on a scooter in a neighborhood .\n",
      "Predicting for image: 903\n",
      "3584930205_a3f58a4b7c.jpg : A dog is jumping over an obstacle course .\n",
      "Predicting for image: 904\n",
      "127488876_f2d2a89588.jpg : A black and black dog is preparing to jump down a rail .\n",
      "Predicting for image: 905\n",
      "3578841731_f775cab089.jpg : A girl in a blue shirt is running through a large field .\n",
      "Predicting for image: 906\n",
      "2934359101_cdf57442dc.jpg : A man in a white jersey is playing basketball .\n",
      "Predicting for image: 907\n",
      "339658315_fbb178c252.jpg : A man and a woman wait for a book .\n",
      "Predicting for image: 908\n",
      "2991994415_504d1c0a03.jpg : A young boy wearing a red shirt is holding up a red dog .\n",
      "Predicting for image: 909\n",
      "3349451628_4249a21c8f.jpg : A black and white black dog is looking at the green ball .\n",
      "Predicting for image: 910\n",
      "3197917064_e679a44b8e.jpg : A black and white dog is walking through the snow .\n",
      "Predicting for image: 911\n",
      "2657484284_daa07a3a1b.jpg : A man in a green wetsuit is running down a grassy hill .\n",
      "Predicting for image: 912\n",
      "2894217628_f1a4153dca.jpg : a football player in a white jersey is about to tackle a player in white .\n",
      "Predicting for image: 913\n",
      "3424424006_98f9d1921c.jpg : A man walks for a ball .\n",
      "Predicting for image: 914\n",
      "2526585002_10987a63f3.jpg : A group of people sit on a racetrack .\n",
      "Predicting for image: 915\n",
      "1836335410_de8313a64e.jpg : A group of people are playing in a dark room at night .\n",
      "Predicting for image: 916\n",
      "2443380641_7b38d18f5b.jpg : A little boy in a red shirt stands on a swing set .\n",
      "Predicting for image: 917\n",
      "2208067635_39a03834ca.jpg : A little girl is running through a flock of dirt .\n",
      "Predicting for image: 918\n",
      "3427233064_6af01bfc5c.jpg : A woman in a white shirt is on a skateboard in a pool .\n",
      "Predicting for image: 919\n",
      "799486353_f665d7b0f0.jpg : A small dog with a colorful ball in its mouth .\n",
      "Predicting for image: 920\n",
      "3741827382_71e93298d0.jpg : A black and white dog in the snow .\n",
      "Predicting for image: 921\n",
      "3578914491_36019ba703.jpg : A girl is rolling in the grass .\n",
      "Predicting for image: 922\n",
      "3197981073_3156963446.jpg : A skateboarder is wearing a dark shirt .\n",
      "Predicting for image: 923\n",
      "416960865_048fd3f294.jpg : A girl in a red shirt is holding a little girl in the distance .\n",
      "Predicting for image: 924\n",
      "197504190_fd1fc3d4b7.jpg : The dog is running through the park .\n",
      "Predicting for image: 925\n",
      "2484190118_e89363c465.jpg : A man wearing a blue hat is holding a stick in the background .\n",
      "Predicting for image: 926\n",
      "2602258549_7401a3cdae.jpg : A group of people pose for a picture .\n",
      "Predicting for image: 927\n",
      "493621130_152bdd4e91.jpg : Brown dog with a stick in its mouth runs in the snow .\n",
      "Predicting for image: 928\n",
      "3332467180_d72f9b067d.jpg : A man is standing in front of a window .\n",
      "Predicting for image: 929\n",
      "2981702521_2459f2c1c4.jpg : A group of people are looking at the camera .\n",
      "Predicting for image: 930\n",
      "461505235_590102a5bf.jpg : A young girl in a red dress climbs a rock .\n",
      "Predicting for image: 931\n",
      "1490213660_9ea45550cf.jpg : A young girl in a yellow coat plays with a rope .\n",
      "Predicting for image: 932\n",
      "300577375_26cc2773a1.jpg : A red dog jumps over a Two park .\n",
      "Predicting for image: 933\n",
      "2549968784_39bfbe44f9.jpg : A boy in a blue shirt is looking at a green slide .\n",
      "Predicting for image: 934\n",
      "2075321027_c8fcbaf581.jpg : A little boy in a bikini sitting on a brick wall .\n",
      "Predicting for image: 935\n",
      "1547883892_e29b3db42e.jpg : A man and a woman are sitting by a white wheel .\n",
      "Predicting for image: 936\n",
      "2886411666_72d8b12ce4.jpg : The dog is carrying a ball in its mouth .\n",
      "Predicting for image: 937\n",
      "2239938351_43c73c887c.jpg : Two dogs play in the grass .\n",
      "Predicting for image: 938\n",
      "2918769188_565dd48060.jpg : a young boy in a blue shirt with a blue shirt is holding a blue ramp .\n",
      "Predicting for image: 939\n",
      "3610683688_bbe6d725ed.jpg : A brown dog is running through the water\n",
      "Predicting for image: 940\n",
      "3025549604_38b86198f5.jpg : A group of people in front of a building .\n",
      "Predicting for image: 941\n",
      "2073105823_6dacade004.jpg : A man is riding a bicycle in the air on a dirt hill .\n",
      "Predicting for image: 942\n",
      "2447284966_d6bbdb4b6e.jpg : A little girl in a blue shirt and goggles is in the air .\n",
      "Predicting for image: 943\n",
      "2600867924_cd502fc911.jpg : A black and brown dog is jumping over a tree .\n",
      "Predicting for image: 944\n",
      "2333288869_8c01e4c859.jpg : A group of people are standing on a snowy mountain .\n",
      "Predicting for image: 945\n",
      "3589367895_5d3729e3ea.jpg : A group of people on a sunny street\n",
      "Predicting for image: 946\n",
      "96420612_feb18fc6c6.jpg : A man in the air doing an aerial stunt in the air .\n",
      "Predicting for image: 947\n",
      "3375991133_87d7c40925.jpg : A man is doing a trick in the water .\n",
      "Predicting for image: 948\n",
      "3320032226_63390d74a6.jpg : A man and a dog are playing in a park .\n",
      "Predicting for image: 949\n",
      "2971431335_e192613db4.jpg : A man jumping into the air into the air on the beach .\n",
      "Predicting for image: 950\n",
      "219301555_17883a51bd.jpg : A young boy in a t-shirt is running in the snow .\n",
      "Predicting for image: 951\n",
      "3222041930_f642f49d28.jpg : A man sits next to a plate with her mouth open .\n",
      "Predicting for image: 952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3187492926_8aa85f80c6.jpg : A child is doing a swimming pool .\n",
      "Predicting for image: 953\n",
      "3673165148_67f217064f.jpg : A man is riding the top of a ramp .\n",
      "Predicting for image: 954\n",
      "270724499_107481c88f.jpg : A black dog with a red collar is running through a field .\n",
      "Predicting for image: 955\n",
      "2182488373_df73c7cc09.jpg : A group of girls are walking down the street .\n",
      "Predicting for image: 956\n",
      "2421446839_fe7d46c177.jpg : A man wearing a brown shirt and a white shirt is holding a brown dog on his nose .\n",
      "Predicting for image: 957\n",
      "2603792708_18a97bac97.jpg : A boy with a white hat is standing on the top of a body of water in the water .\n",
      "Predicting for image: 958\n",
      "2822290399_97c809d43b.jpg : A black and white dog is running through the grass .\n",
      "Predicting for image: 959\n",
      "1332722096_1e3de8ae70.jpg : A woman in a green shirt is walking along a bench .\n",
      "Predicting for image: 960\n",
      "3694064560_467683205b.jpg : A group of people sit on the floor in front of a store .\n",
      "Predicting for image: 961\n",
      "3263395801_5e4cee2b9e.jpg : A man on a bike is doing a trick on a bicycle .\n",
      "Predicting for image: 962\n",
      "3701291852_373ea46bb6.jpg : A boy in a dark suit is standing next to a brick wall at night .\n",
      "Predicting for image: 963\n",
      "2343525685_3eba3b6686.jpg : A man and a white dog are playing with a toy .\n",
      "Predicting for image: 964\n",
      "416106657_cab2a107a5.jpg : A brown dog running through shallow water .\n",
      "Predicting for image: 965\n",
      "387830531_e89c192b92.jpg : A black dog with a toy in its mouth is running .\n",
      "Predicting for image: 966\n",
      "2892995070_39f3c9a56e.jpg : A man in a red shirt is standing on a beach on the beach .\n",
      "Predicting for image: 967\n",
      "3432550415_e7b77232de.jpg : A man in a green shirt and blue shirt is jumping over a red rail .\n",
      "Predicting for image: 968\n",
      "3564312955_716e86c48b.jpg : A man with long hair and a necklace .\n",
      "Predicting for image: 969\n",
      "3238951136_2a99f1a1a8.jpg : A young girl in a pink shirt is walking down a path .\n",
      "Predicting for image: 970\n",
      "3595643050_d312e4b652.jpg : A man walks down the floor .\n",
      "Predicting for image: 971\n",
      "3139876823_859c7d7c23.jpg : Two dogs are running through the water .\n",
      "Predicting for image: 972\n",
      "3473264983_67917a931f.jpg : A group of people sit on a dirt track .\n",
      "Predicting for image: 973\n",
      "2994179598_a45c2732b5.jpg : A man in a white shirt is playing with a ball .\n",
      "Predicting for image: 974\n",
      "491405109_798222cfd0.jpg : An older woman in a flower hat smiles .\n",
      "Predicting for image: 975\n",
      "3115174046_9e96b9ce47.jpg : A man in black is standing in front of a window .\n",
      "Predicting for image: 976\n",
      "3631986552_944ea208fc.jpg : A group of people are surfing in the water .\n",
      "Predicting for image: 977\n",
      "3350786891_6d39b234e9.jpg : A group of people in matching outfits are gathered in front of a fence .\n",
      "Predicting for image: 978\n",
      "3062173277_bfb5ef4c45.jpg : A group of people sit in a race in a race\n",
      "Predicting for image: 979\n",
      "3108197858_441ff38565.jpg : A group of young girls are looking at a picture .\n",
      "Predicting for image: 980\n",
      "1224851143_33bcdd299c.jpg : Two people posing for a fountain .\n",
      "Predicting for image: 981\n",
      "3458559770_12cf9f134e.jpg : A group of people are on a motorcycle .\n",
      "Predicting for image: 982\n",
      "3425835357_204e620a66.jpg : A man in a black shirt is running .\n",
      "Predicting for image: 983\n",
      "3214885227_2be09e7cfb.jpg : A woman wearing a white shirt is standing in a rocky area .\n",
      "Predicting for image: 984\n",
      "2854207034_1f00555703.jpg : A young boy in a field is walking on a grassy field with a grassy field .\n",
      "Predicting for image: 985\n",
      "2167644298_100ca79f54.jpg : A boy in a purple shirt poses for a large book .\n",
      "Predicting for image: 986\n",
      "241346971_c100650320.jpg : A group of football players are running through the field .\n",
      "Predicting for image: 987\n",
      "1386964743_9e80d96b05.jpg : A dog is walking in a grassy field .\n",
      "Predicting for image: 988\n",
      "3397220683_4aca010f86.jpg : Two young girls play with something in the snow .\n",
      "Predicting for image: 989\n",
      "2473791980_805c819bd4.jpg : A man on the shore in the ocean .\n",
      "Predicting for image: 990\n",
      "241345844_69e1c22464.jpg : A bunch of football players try to get the ball .\n",
      "Predicting for image: 991\n",
      "3256043809_47258e0b3e.jpg : A black and black dog playing with a black dog .\n",
      "Predicting for image: 992\n",
      "2351479551_e8820a1ff3.jpg : A group of young people walking through the water .\n",
      "Predicting for image: 993\n",
      "3514179514_cbc3371b92.jpg : A girl wearing a white shirt and sunglasses is sleeping in the air .\n",
      "Predicting for image: 994\n",
      "1119015538_e8e796281e.jpg : A brown dog with a red collar running on a grassy field .\n",
      "Predicting for image: 995\n",
      "3727752439_907795603b.jpg : A man wearing a blue shirt is playing with a tattoo .\n",
      "Predicting for image: 996\n",
      "3430607596_7e4f74e3ff.jpg : A young boy walks across a grassy track .\n",
      "Predicting for image: 997\n",
      "3259666643_ae49524c81.jpg : A man in a black shirt and sunglasses wearing a black shirt and black jeans is wearing a black shirt and black helmet .\n",
      "Predicting for image: 998\n",
      "2623930900_b9df917b82.jpg : A woman in a pink dress holding a handle .\n",
      "Predicting for image: 999\n",
      "3490736665_38710f4b91.jpg : A young boy jumps a horse over a hurdle .\n",
      "0.500769703674\n"
     ]
    }
   ],
   "source": [
    "weight = 'weights-improvement-50.hdf5'\n",
    "#test_image = '3155451946_c0862c70cb.jpg'\n",
    "test_img_dir = 'Flickr8k_text/Flickr_8k.testImages.txt'\n",
    "#print test_model(weight, test_image)\n",
    "print (test_model_on_images(weight, test_img_dir, beam_size=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things that were focused on\n",
    "\n",
    "### Descriptions\n",
    "These are included in the above code\n",
    "\n",
    "### Different things I tried\n",
    "1. Changed the optimizer from RMSProp to Adam and ran 5 epcohs. Accuracy increased from  0.261079 to 0.2979. So retained the optimizer to be Adam.\n",
    "2. Instead of 'Concatenating' the image and language model, I tried to do a 'Sum' of these. But the accuracy did not improve meaningfully from the 1st to the 5th epoch. It improved from 0.0769 to 0.0775. So dropped this idea.\n",
    "3. Changed the optimizer from Adam to SGD and ran 5 epochs. accuracy did not improve meaningfully from the 1st to the 5th epoch. It improved from 0.0754 to 0.0792. So dropped this idea. Moreover the time it took to train 5 epochs was noticeably longer.\n",
    "4. Tried running for 10 epochs with Adam and noticed that RMSProp was marginally better at the end of the 10th epoch. So changed it back to RMSProp\n",
    "5. Tried dropouts with RMSProp. Added a 50% dropout for the image_model. The original model without the dropout was marginally better. So removed the dropouts from image_model.\n",
    "6. Added a 50% dropout for the lang_model. At the end of the 10th epoch, it did better than the model without the dropout. Accuracy with the dropout at the 10th epoch was 0.37888158 whereas without dropout it was 0.368187563\n",
    "7. Retained the 50% dropout for the lang_model and added the 50% drop_out  for the image_model and ran for 10 epochs. The accuracy was less by 2 basis points compared to the one I got with dropout at just the lang_model. Up until the 3rd epoch, the values were comparable to my earlier run with dropout at the lang_model.\n",
    "8. Retained the 50% dropout for the lang_model and reduced the dropout for the image_model to 20% and ran for 10 epochs. Until the 7th epoch this model was doing better but it tapered out for the remaining 3 epochs - finishing the 10th epoch with an accuracy of 0.377 when the model with just the dropout for the lang model finished with an accuracy of 0.37882. I think it is worth trying both the models for another 10 epochs.\n",
    "9. Trained the model with 50% dropout for the lang_model and 20% dropout for the image model. At the end of the 20th epoch this model was less accurate by more than 2 basis points when than the model with no dropouts. At the 20th epcoh this model produced an accuracy of 0.428760548 and the model without any dropouts produced an accuracy of 0.451811603. The dropouts made the network learn faster during the first 8 epochs but the learning slowed down during the subsequent runs. So I dropped this idea.\n",
    "10. Cleaned the captions, in the training set by converting all captions to lower case, removing apostrophes and removing all words with single characters such as 's' and 'a'. Ran for 10 epcohs with RMSProp and noticed that the learning was slow and completed the 10th epoch with an accuracy of 0.230183563. \n",
    "11. Tried the above setup with 20% drop out for the image model. Stopped it after 5 epochs because the learning was very slow. At the end of the 5th epoch the accuracy was 0.1632. With all my prior runs I use to be around 0.26 at the 5th epcoh. So stopped this. The takeaway from cleaning the description is that it slows down the learning.\n",
    "12. Tried Adam optimizer with 500 LSTM instead of the LSTSM cells. At the end of the 1st epoch the accuracy was 0.0774 but there was no meaningful uptick in the accuracy. I ran it for 5 epochs and stopped it. The best accuracy at the end of the 5th epcoh was 0.0782.\n",
    "13. I switched back to RMSProp and tried with variable learning rate. Got a reasonable uptick in the Bleu score, which is in this file.\n",
    "\n",
    "\n",
    "### Detailed analysis of results\n",
    "When the model gets stuck and does not improve the results, sometimes doubling the learning rate helps while other times reducing the learning rate helps. I would have typically thought reducing the learning rate will help during the later stages of the training but the reverse was true during my training. I noticed that earlier on (15th to the 25th epoch) I had to reduce the learning rate by half and then had to go back to my original learning rate for the next 15 epochs, then once again I had to double the learning rate for the last 10 epochs.\n",
    "\n",
    "\n",
    "### What else I would have done if I had more time\n",
    "1. Refactor the code. The code is not modularized and there is code repetitions. Also Keras provides built in support for converting word to index and vice-versa - probably make use of Keras.Tokenizer.\n",
    "2. Would have added a validation set to understand the validation accuracy during training.\n",
    "3. Convert it to Python 3.\n",
    "4. I would like to explore why when I cleaned the captions, the accuracy was not even comparable. Intuitively this should have given me better results. I would like to spend some time to understand this.\n",
    "5. Explore ensemble methods. Spent some time trying to understand to do this for deep learning but was unable to find concrete examples.\n",
    "6. I recently read that LSTSMs are stochastic, meaning different runs on the same dataset will give different results. One of the reasons, is the weight initialization. I will explore possibilities to make it predictable, may be check whether we could use any seed value.\n",
    "7. Analyze the ones that was captioned incorrectly to understand what type of sentences the network is having problems with.\n",
    "8. Analyze why some of the things that I tried did not work.\n",
    "\n",
    "### Comparison between my results and results from current state of art. \n",
    "The [reference](https://github.com/anuragmishracse/caption_generator) project using VGG16 architecture got a BLEU score of 0.57. I used Densenet architecture and got a BLEU score of 0.500769703674.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
